---
layout: post
title:  深度学习（五十）——深度推理, CNN进阶, AI前沿
category: DL 
---

* toc
{:toc}

# 深度推理

https://mp.weixin.qq.com/s/rE96BprEO1ZatVOQeO-4YA

因果推理学习算法资源大列表

https://mp.weixin.qq.com/s/RS39wqZDf6gEhOY6gcOVSA

74页教程融合逻辑推理和深度学习

https://mp.weixin.qq.com/s/NcUHJ89DPVdB7cJttsh-xw

基于神经网络的知识推理

https://mp.weixin.qq.com/s/ouHPvm4vQKga5sZfG_CHBw

DeepMind用深度学习模仿大脑推理，预测编码智能推进一大步！

https://zhuanlan.zhihu.com/p/28654835

视觉推理（Visual Reasoning），神经网络也可以有逻辑

https://mp.weixin.qq.com/s/HP8KLbo26W5UscCGavKDRw

IBM Watson提出人机推理网络HuMaINs，结合人机两者优势

https://mp.weixin.qq.com/s/210l9K94KMqtJtqbrZ-mgg

打开黑箱重要一步，MIT提出TbD-net，弥合视觉推理模型的性能与可解释性鸿沟

https://mp.weixin.qq.com/s/7NpJJn4k5oGPOB04S9Jyqw

DeepMind新论文，关联推理为什么是智能最重要的特征

http://mp.weixin.qq.com/s/6I0Z_yY7UT_7qOKOWcd7Mw

李飞飞发表研究新成果：视觉推理的推断和执行程序！

http://mp.weixin.qq.com/s/9mtgdNynv92FC2dA8-5KJA

VAE和Adam发明人博士论文：变分推理和深度学习

https://mp.weixin.qq.com/s/sbV5SL6fAGad5KlBoqUKFQ

斯坦福大学教授Christopher Manning提出全可微神经网络架构MAC：可用于机器推理

https://mp.weixin.qq.com/s/5vDSrWeUvlBuZgmX0R9pBQ

斯坦福“黑盒学习”研究：使用神经变分推理的无向图模型，可替代“采样”

https://mp.weixin.qq.com/s/XESTrLMERQPR9eXcFA56gg

神经符号系统：让机器善解人意

https://mp.weixin.qq.com/s/GYe1psxy1KMCbV7f3K8f4Q

神经规则引擎：让符号规则学会变通

https://mp.weixin.qq.com/s/-qc2MENppQmdClaIKV6Lww

深度推理学习中的图网络与关系表征

https://mp.weixin.qq.com/s/_FHXhfZ7TEpBzVf5kB0BsA

为思想“层次”建模，递归推理让AI更聪明

https://mp.weixin.qq.com/s/YkH3loJhdymo7AFTKt0fbg

结合符号主义和深度学习，DeepMind提出新型端到端神经网络架构PrediNet

https://mp.weixin.qq.com/s/u8U63i7zpcXA7iNsJP5vzQ

AlphaGo之父DeepMind再出神作，PrediNet原理详解

https://mp.weixin.qq.com/s/DSEEZ9bMe0g7zV7FB0nXpg

机器推理在常识问答任务中的应用

https://mp.weixin.qq.com/s/MX2R9KgG6tXWEeviRRgBqQ

机器推理在事实检测任务中的应用

https://mp.weixin.qq.com/s/PzUqtBJFykB839Ff7yafoA

机器推理系列文章概览：七大NLP任务最新方法与进展

https://mp.weixin.qq.com/s/JXMD8uGcVQImcZULWZiGkg

跨语言预训练，提高机器推理的迁移能力

https://mp.weixin.qq.com/s/3DPNC2bwmg8veH-XtVAGGA

腾讯提出NumNet+模型，超越谷歌登DROP排行榜第一名

https://mp.weixin.qq.com/s/_6AYWUpPmdABcO1pCIhIsw

李飞飞团队：将因果推理能力赋予代理，以完成目标导向任务

https://mp.weixin.qq.com/s/AwbW3K6cPwTjJ1qzURAbUg

基于推理的多轮语义分析和问答

# CNN进阶

http://mp.weixin.qq.com/s/ddTNr-967IahTZ2X1LNSEQ

盘点影响计算机视觉Top100论文：从ResNet到AlexNet

https://blog.csdn.net/WZZ18191171661/article/details/70161595

深度学习在CV领域的进展以及一些由深度学习演变的新技术

https://mp.weixin.qq.com/s/gwH9s1ggMTj2dJkad9wUuw

从VGG到NASNet，一文概览图像分类网络

https://mp.weixin.qq.com/s/byfdiCsrkwAQis8YX14iXQ

深度卷积神经网络演化历史及结构改进脉络

https://mp.weixin.qq.com/s/hIAIbpqItS09KDOSFxaeqg

从Inception v1到Inception-ResNet，一文概览Inception家族的“奋斗史”

https://mp.weixin.qq.com/s/r143qYj8bziu_N-27RWRRw

机器学习5年大跃进，可能是个错觉

https://mp.weixin.qq.com/s/pollD4LN_GHJckzJAjwPqg

侧抑制”卷积神经网络，了解一下？

https://mp.weixin.qq.com/s/gil2K-JKzfRqdzc-abnh6A

王井东：深度融合——一种神经网络结构设计模式

https://mp.weixin.qq.com/s/7l0J5LIAawlkCIrUEGG9aA

卷积神经网络“失陷”，CoordConv来填坑

https://mp.weixin.qq.com/s/4GPLeJiQoDfBZJzF4QmuAg

Excel再现人脸识别：CNN用于计算机视觉任务不再神秘

https://mp.weixin.qq.com/s/30_AwwHS0eqfmYwTvRQ85Q

pooling去哪儿了？

https://mp.weixin.qq.com/s/yTkAhje3A0dRSyTobjsm2A

Pervasive Attention：用于序列到序列预测的2D卷积神经网络

https://zhuanlan.zhihu.com/p/31595192

Deep Image Prior：深度卷积网络先天就理解自然图像

https://mp.weixin.qq.com/s/6KC1vhKcyqQ0eZEXJyPqVA

密集连接卷积网络

https://mp.weixin.qq.com/s/vUK2NneOs8OR0vcJEZNbrA

田渊栋等人论文：何时卷积滤波器容易学习？

https://mp.weixin.qq.com/s/PiQB2AvhtDceMJxYN8O8jA

通用卷积神经网络交错组卷积

https://mp.weixin.qq.com/s/2w_Bwqx9C9KwenK480sVMQ

如何可视化卷积网络分类图像时关注的焦点

https://mp.weixin.qq.com/s/yQG0983RjQHIkt9oBlkDqQ

瞎谈CNN：通过优化求解输入图像

https://zhuanlan.zhihu.com/p/33445638

传统不死：在CNN中学习和构建空间传播模块

https://mp.weixin.qq.com/s/W2DqCjmF3oyPLKeETAO5XA

CNN实现“读脑术”，成功解码人脑视觉活动，准确率超50%

https://mp.weixin.qq.com/s/t9ZHW8fkWtnvpM7ynJOTDw

从语义上理解卷积核行为，UCLA朱松纯等人使用决策树量化解释CNN

https://mp.weixin.qq.com/s/Fhge-Idk_adBjUuzaAtzyQ

7大类深度CNN架构创新综述

https://mp.weixin.qq.com/s/f1uOimoA3a37e1BK1l1rvw

从群等变卷积网络到球面卷积网络

https://mp.weixin.qq.com/s/DG4ofF78fIgiIMiJaxuIVA

AAAI 2019 论文解读：卷积神经网络继续进步

https://mp.weixin.qq.com/s/ro1VgHkPPYuGP0eO8TNg9g

图像分类任务中的tricks总结

https://mp.weixin.qq.com/s/MqbVXlkLeAu9afVvQmmeVQ

专门为卷积神经网络设计的训练方法：RePr

https://mp.weixin.qq.com/s/-6rKyPIFR7dq7eVQw5PzmA

用异构卷积训练深度CNN：提升效率而不损准确度

https://mp.weixin.qq.com/s/PbUp3hi_9d6e3gHF05EP0A

Decoupled Networks

https://mp.weixin.qq.com/s/Z_nOIKpL3osfX3ylIsJ4rA

最新高效卷积方式HetConv

https://mp.weixin.qq.com/s/Siy096-tkXZuv9Jsi4__ug

超越ResNet：南开提出Res2Net，不增计算负载，性能全面升级！

https://mp.weixin.qq.com/s/NthR9-iE2jqgufnBtToOHA

CNN更新换代！性能提升算力减半，还即插即用（OctConv）

https://mp.weixin.qq.com/s/UcLUir2UWibXw9lS8R0sXA

比CNN表现更好，CV领域全新卷积操作OctConv厉害在哪里？

https://mp.weixin.qq.com/s/wRLMEpGP2hyFdI0IwXWDPw

ICML 2019反锯齿下采样改进网络平移不变性

https://mp.weixin.qq.com/s/CFC7OoVQZyW4pO6p-pnf1g

一个高阶张量搞定整个全卷积网络

https://mp.weixin.qq.com/s/Z-ACpKmy20xdTAUC2XsLYQ

模块设计之SKNet, GCNet, GloRe, Octave

https://mp.weixin.qq.com/s/sF-1bV1UA1AyLMlvRRF8iQ

告别低分辨率网络，微软提出高分辨率深度神经网络HRNet

https://zhuanlan.zhihu.com/p/72901400

深度图像分类网络小结(上)

https://mp.weixin.qq.com/s/Ojah3bo8M0KTTk7iYODSpw

总有些骨骼轻奇，姿态妖娆的模型结构设计，不知道你知不知道，反正我知道一些

https://mp.weixin.qq.com/s/m5rUNy938cCNjD7L3J4h-Q

让CNN有了平移不变性，同时提升ImageNet成绩：Adobe开源新方法，登上ICML

https://mp.weixin.qq.com/s/LwBOK7J1tby4WecOiRoA6g

告诉我我在哪？——目标级别的场景上下文预测

https://zhuanlan.zhihu.com/p/79943361

Matrix Nets: A New Deep Architecture论文阅读

https://zhuanlan.zhihu.com/p/84205427

Adaptively Connected Neural Networks

https://www.zhihu.com/question/270245936

卷积层和分类层，哪个更重要？

https://mp.weixin.qq.com/s/UlEQ845-siCEIJ6JyBqkdw

CNN为什么要用3x3卷积？偶数卷积核其实表现更强！

https://zhuanlan.zhihu.com/p/62532887

双线性池化（Bilinear Pooling）详解、改进及应用

https://mp.weixin.qq.com/s/vQkb2-5D9T2ejUa2qrPlow

卷积神经网络中的即插即用模块

https://mp.weixin.qq.com/s/glQSmbuvRI6CV8EyfYLezw

盘点11种CNN网络设计中精巧通用的“小”插件

https://mp.weixin.qq.com/s/3-NEbE6aZHR6dgW6GCmldw

在频域中学习的DCTNet

https://mp.weixin.qq.com/s/a7GEOdPRWYCBh6XQslxX8w

CNN骨干网络新选择HS-ResNet

https://mp.weixin.qq.com/s/S5rNebrB8zpILZ1j_d-29Q

深度视觉模型设计，还有哪些新思路？

https://mp.weixin.qq.com/s/Yx0kc_Xy8Hb_2NZGBpkjEg

VoVNet：实时目标检测的新backbone网络

https://zhuanlan.zhihu.com/p/358183591

involution：超越convolution和self-attention的神经网络新算子

# AI前沿

人工智能前沿7大热点：

1.强化学习

2.元学习

3.模仿学习

4.机器人

5.概念与抽象

6.感知与意识

7.因果推理

最前沿 = good new idea

工业界 = proven idea in practice

---

从简单的样本到困难的样本，以一种有意义的顺序，使用课程学习可以提供比基于随机数据变换的标准训练方法更好的性能，而不需要额外的计算成本。

https://mp.weixin.qq.com/s/sG9qvElHchydNs1Wt6FJwg

课程学习（Curriculum Learning)2021综述论文

---

在传统的数学优化中，以目标和约束作为输入来生成最优决策。在逆优化中，决策是作为输入给出的，目标和/或约束是输出。具体地说，逆优化的目标是确定优化模型的参数，即“正演”模型，使一组决策相对于正演模型近似或确切地最优。

https://mp.weixin.qq.com/s/CTQEX4uyyrqVrHeCaC2SYg

反向优化？多伦多大学首篇《逆优化: 理论与应用》综述论文

---

参考：

https://mp.weixin.qq.com/s/QtO-4ARpAQf0kXfALqMKSQ

DeepMind-深度学习: AI革命及其前沿进展

https://mp.weixin.qq.com/s/sji2HVli-Y7am37YjTbq3w

谷歌Jeff Dean 64页 PPT 讲述《用深度学习解决挑战性问题》

https://mp.weixin.qq.com/s/AQrgvjFPXUpqfqQQgOFN9A

36页最新深度学习综述论文：算法、技术、应用，181篇参考文献

https://mp.weixin.qq.com/s/cGKsZYxrVP7hVnv7Jli9Zg

MIT课程全面解读2019深度学习最前沿

https://mp.weixin.qq.com/s/ugdF-Q-d8ngKTrHF2vPA3A

DeepMind科学家总结2021年的15个高能研究
