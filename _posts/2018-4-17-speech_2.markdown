---
layout: post
title:  语音识别（二）——声源定位, 声学模型
category: graphics 
---

# Microphone Array（续）

## Microphone Array技术难点

传统的阵列信号处理技术直接应用到麦克风阵列处理系统中往往效果不理想，其原因在于麦克风阵列处理有不同的处理特点：

### 阵列模型的建立

麦克风主要应用处理语音信号，拾音范围有限，且多用于近场模型，使得常规的阵列处理方法如雷达，声呐等平面波远场模型不再适用，在近场模型中，需要更加精准的球面波，需要考虑传播路径不同引起的幅度衰减不同。

### 宽带信号处理

通常的阵列信号处理多为窄带，即不同阵元在接受时延与相位差主要体现在载波频率，而语音信号未经过调制也没有载波，且高低频之比较大，不同阵元的相位延时与声源本身的特性关系很大—频率密切相关，使得传统的阵列信号处理方法不再完全适用。

### 非平稳信号处理

传统阵列处理中，多为平稳信号，而麦克风阵列的处理信号多是非平稳信号，或者短时平稳信号，因此麦克风阵列一般对信号做短时频域处理，每个频域均对应一个相位差，将宽带信号在频域上分成多个子带，每个子带做窄带处理，再合并成宽带谱。

### 混响

声音传播受空间影响较大，由于空间反射，衍射，麦克风收到的信号除了直达信号以外，还有多径信号叠加，使得信号被干扰，即为混响。在室内环境中，受房间边界或者障碍物衍射，反射导致声音延续，极大程度的影响语音的可懂度。

# 声源定位

## 近场模型和远场模型

![](/images/img2/far_field_near_field.jpg)

通常麦克风阵列的距离为1~3m，阵列处于近场模型，麦克风阵列接受的是球面波而不是平面波，声波在传播的过程中会发生衰减，而衰减因子与传播的距离成正比，因此声波从声源到达阵元时候的幅度也各不相同。而远场模型中，声源到阵元的距离差相对较小，可以忽略。通常，我们定义$$2L^2/\lambda$$为远近场临界值，L为阵列孔径，λ为声波波长，因此阵元接受信号不仅有相位延时还有幅度衰减。

参考：

https://www.zhihu.com/question/48537863

远场（far-field）语音识别的主流技术有哪些？

## 波束形成

声源定位的方法包括**波束形成，超分辨谱估计和TDOA**，分别将声源和阵列之间的关系转变为**空间波束，空间谱和到达时间差**，并通过相应的信息进行定位。

波束形成是通用的信号处理方法，这里是指将一定几何结构排列的麦克风阵列的各麦克风输出信号经过处理（例如加权、时延、求和等）形成空间指向性的方法。波束形成主要是抑制主瓣以外的声音干扰，这里也包括人声，比如几个人围绕Echo谈话的时候，Echo只会识别其中一个人的声音。

波束形成可分为常规的波束形成CBF（Conventional Beam Forming）、CBF+Adaptive Filter和自适应波束形成ABF（Adaptive Beam Forming）。

## 超分辨谱估计

如MUSIC，ESPRIT等，对其协方差矩阵（相关矩阵）进行特征分解，构造空间谱，关于方向的频谱，谱峰对应的方向即为声源方向。适合多个声源的情况，且声源的分辨率与阵列尺寸无关，突破了物理限制，因此成为超分辨谱方案。这类方法可以拓展到宽带处理，但是对误差十分敏感，如麦克风单体误差，通道误差，适合远场模型，矩阵运算量巨大。

## TDOA

TDOA（time difference of arrival）是先后估计声源到达不同麦克风的时延差，通过时延来计算距离差，再利用距离差和麦克风阵列的空间几何位置来确定声源的位置。分为TDOA估计和TDOA定位两步：

### TDOA估计

常用的有广义互相关GCC（Generalized Cross Correlation）和LMS自适应滤波。

### TDOA定位

TDOA估值进行声源定位，三颗麦克风阵列可以确定空间声源位置，增加麦克风会增高数据精度。定位的方法有MLE最大似然估计，最小方差，球形差值和线性相交等。

TDOA相对来讲应用广泛，定位精度高，且计算量最小，实时性好，可用于实时跟踪，在目前大部分的智能定位产品中均采用TDOA技术做为定位技术。

## 参考

https://wenku.baidu.com/view/903f907f31b765ce05081431.html

基于传声器阵列的声源定位

https://zhuanlan.zhihu.com/p/35590325

MIT提出像素级声源定位系统PixelPlayer：无监督地分离视频中的目标声源

https://zhuanlan.zhihu.com/p/27921878

揭秘武林绝学——“听声辨位”

# 其他前端问题

## 语音增强

语音增强是指当语音信号被各种各样的噪声(包括语音)干扰甚至淹没后，从含噪声的语音信号中提取出纯净语音的过程。

![](/images/img2/Speech_Enhancement.jpg)

## 去混响（Dereverberation）

一般我们听音乐时，希望有混响的效果，这是听觉上的一种享受。合适的混响会使得声音圆润动听、富有感染力。混响（Reverberation）现象指的是声波在室内传播时，要被墙壁、天花板、地板等障碍物形成反射声，并和直达声形成叠加，这种现象称为混响。

但是，混响现象对于识别就没有什么好处了。由于混响则会使得不同步的语音相互叠加，带来了音素的交叠掩蔽效应（Phoneme Overlap Effect），从而严重影响语音识别效果。

影响语音识别的部分一般是晚期混响部分，所以去混响的主要工作重点是放在如何去除晚期混响上面，多年来，去混响技术抑制是业界研究的热点和难点。利用麦克风阵列去混响的主要方法有以下几种：

(1)基于盲语音增强的方法（Blind signal enhancement approach），即将混响信号作为普通的加性噪声信号，在这个上面应用语音增强算法。

(2)基于波束形成的方法（Beamforming based approach），通过将多麦克风对收集的信号进行加权相加，在目标信号的方向形成一个拾音波束，同时衰减来自其他方向的反射声。

(3)基于逆滤波的方法（An inverse filtering approach），通过麦克风阵列估计房间的房间冲击响应（Room Impulse Response, RIR），设计重构滤波器来补偿来消除混响。

## 声源信号提取

家里人说话太多，DingDong听谁的呢。这个时候就需要DingDong聪明的辨别出哪个声音才是指令。而麦克风阵列可以实现声源信号提取，声源信号的提取就是从多个声音信号中提取出目标信号，声源信号分离技术则是将需要将多个混合声音全部提取出来。

利用麦克风阵列做信号的提取和分离主要有以下几种方式：

(1)基于波束形成的方法，即通过向不同方向的声源分别形成拾音波束，并且抑制其他方向的声音，来进行语音提取或分离；

(2)基于传统的盲源信号分离（Blind Source Separation）的方法进行，主要包括主成分分析（Principal Component Analysis，PCA）和基于独立成分分析（Independent Component Analysis，ICA）的方法。

## 回声抵消

严格来说，这里不应该叫回声，应该叫“自噪声”。回声是混响的延伸概念，这两者的区别就是回声的时延更长。一般来说，超过100毫秒时延的混响，人类能够明显区分出，似乎一个声音同时出现了两次，我们就叫做回声，比如天坛著名的回声壁。

实际上，这里所指的是语音交互设备自己发出的声音，比如Echo音箱，当播放歌曲的时候若叫Alexa，这时候麦克风阵列实际上采集了正在播放的音乐和用户所叫的Alexa声音，显然语音识别无法识别这两类声音。回声抵消就是要去掉其中的音乐信息而只保留用户的人声，之所以叫回声抵消，只是延续大家的习惯而已，其实是不恰当的。

## 参考

https://zhuanlan.zhihu.com/p/27977550

极限元：智能语音前端处理中的几个关键问题

https://zhuanlan.zhihu.com/p/24139910

远场语音交互中的麦克风阵列技术解读

https://zhuanlan.zhihu.com/p/22512377

自然的语音交互——麦克风阵列

# 声学模型

声学模型主要有两个问题，分别是特征向量序列的可变长和音频信号的丰富变化性。

**可变长特征向量序列**问题在学术上通常有动态时间规划（Dynamic Time Warping, DTW）和隐马尔科夫模型（Hidden Markov Model, HMM）方法来解决。

**音频信号的丰富变化性**是由说话人的各种复杂特性或者说话风格与语速、环境噪声、信道干扰、方言差异等因素引起的。声学模型需要足够的鲁棒性来处理以上的情况。

在过去，主流的语音识别系统通常使用梅尔倒谱系数（Mel-Frequency Cepstral Coefficient, MFCC）或者线性感知预测（Perceptual Linear Prediction, PLP）作为特征，使用混合高斯模型-隐马尔科夫模型（GMM-HMM）作为声学模型。

在近些年，区分性模型，比如深度神经网络（Deep Neural Network, DNN）在对声学特征建模上表现出更好的效果。基于深度神经网络的声学模型，比如上下文相关的深度神经网络-隐马尔科夫模型（CD-DNN-HMM）在语音识别领域已经大幅度超越了过去的GMM-HMM模型。

