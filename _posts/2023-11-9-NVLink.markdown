---
layout: post
title: NVLink, AMD
category: Chip 
---

* toc
{:toc}

# NVLink

## 算力 vs 带宽

![](/images/img5/bandwidth_compute_bound.png)

在过去十年的竞争中，核心竞争指标是算力，现在变成了内存带宽和容量。

https://blog.csdn.net/tugouxp/article/details/126479276

利用roofline模型分析异构系统算力VS带宽

https://mp.weixin.qq.com/s/y9dVg9YtfWxu6NcW-fxi6Q

内存带宽与计算能力，谁才是决定深度学习执行性能的关键？

## NVLink

NVLink技术提供比PCIe 3更高的带宽与更多的链路，并可提升多GPU和多GPU/CPU系统配置的可扩展性。

SXM是Nvidia的双插槽卡设计，与PCIe卡不同，它不需要连接电源。

---

![](/images/img4/PCIE.jpg)

官网：

https://www.nvidia.cn/data-center/nvlink/

![](/images/img3/nvlink.png)

Tesla V100中以NVLink连接的GPU至GPU和GPU至CPU通信。

![](/images/img3/nvlink_2.png)

在DGX-1V服务器中，混合立体网络拓扑使用NVLink连接8个Tesla V100加速器。每个GPU有6条nvlink通道，总带宽高达300GB/s。

从上图可以看到，即使每个GPU拥有6条nvlink通道，仍然无法做到“全连接”（即任意两个GPU之间存在双向通道）。这就引出了下一个更加疯狂的技术：nvswitch。

![](/images/img3/nvswitch.png)

NV Switch是首款节点交换架构，可支持单个服务器节点中16个全互联的GPU，并可使全部8个GPU对分别以300GB/s的惊人速度进行同时通信。这16个全互联的GPU还可作为单个大型加速器，拥有0.5 TB统一显存空间和2 PetaFLOPS计算性能。

https://zhuanlan.zhihu.com/p/35470532

全球最大GPU背后的秘密：NVSwitch如何实现NVIDIA DGX-2的超强功力？

---

NVLink和NV Switch的关系：

NVLink是一种协议。

NV Switch是NVLink协议的芯片化实现。

GPU core和NV Switch如果都实现了NVLink协议的话，则它们之间可以通过NVLink协议进行通信。

未来解决带宽问题的两大法宝，一个靠内存厂给提供的牙膏继续叠单GPU芯片的带宽，另一个就是目前这些形态更高密度的通过nvlink组合起来，从而创造一个大的“一个GPU”。

就这个搞一个大的“一个GPU”而言，又有很多种可能的扩展形态

- 双GPU卡
- 主板堆8卡
- 垂直堆8个刀片
- 网络组更多机柜

其实也就对应了nvlink的多种形态

- nvlink c2c
- nvlink switch
- nvlink bridge
- nvlink network

---

![](/images/img5/Nvidia_Grace_Hopper.jpg)

https://zhuanlan.zhihu.com/p/600638633

Nvidia Grace Hopper超级芯片架构解读（一）

https://zhuanlan.zhihu.com/p/601072219

Nvidia Grace Hopper超级芯片架构解读（二）

---

单单从信号线路数量来说，x16的PCIe和x2的NVLink是相同的，都是32对差分线。x2的NVLink 3.0双向带宽是100 GB/s，比PCIe 5.0 x16的126 GB/s要低。

这么高的带宽，数据传输功耗是一个不可忽略的重要因素，NV能做到x18的NVLink，不代表其它厂家可以轻松实现x144的PCIe。

大概在2017年的hotchips上，Intel给出的一份PPT上，PCB上每传输1bit数据的参考功耗是20 pJ（1e-12焦耳），按这个功耗计算，NVLink 3.0 x18的7200 Gbit/s意味着单单是信号传输就要消耗144W功耗，这显然是难以接受的。2019年NV发表过一份1.17 pJ/bit的论文，虽然因为应用环境不同，不能直接对比说NV的技术使得传输功耗不到6%，但还是可以从侧面猜测一下NV的技术水平。

https://www.zhihu.com/question/546809864

为什么NVlink能够实现比PCIe更高的传输带宽？

---

https://zhuanlan.zhihu.com/p/623060064

什么是NVLink？

https://zhuanlan.zhihu.com/p/672749098

Nvidia GPU互联技术全景图

## 存储体系

![](/images/img5/GPU_2.png)

Registers -> Caches -> Shared Memory -> Gloabl Memory（Local Memory）

https://blog.csdn.net/qq_41554005/article/details/119765334

GPU存储资源：寄存器，本地内存，共享内存，缓存，显存等存储器细节

---

通信的问题，其本质是数据的共享。因此，质不够量来凑，也是一个不错的方法。

由于没有NVLink这样的杀手锏，AMD的AI方案更倾向于增加单卡内存，来减少卡/机的数量。

比如AMD发布的Instinct MI300X GPU，单卡内存192GB，8卡服务器就是1.5TB HBM3内存。

当然，单纯堆料这种没有技术含量的活，对于老黄没有任何难度。老黄反手推出H200，单卡141GB HBM3e。

## NCCL

NCCL是Nvidia Collective multi-GPU Communication Library的简称，它是一个实现多GPU的collective communication通信库，可以在PCIe、Nvlink、InfiniBand上实现较高的通信速度。

官方文档：

https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/index.html

nccl v1：支持单机多卡通信，不支持多机通信。

nccl v2：支持多机通信。

参考：

https://www.zhihu.com/question/63219175

如何理解Nvidia英伟达的Multi-GPU多卡通信框架NCCL？

https://zhuanlan.zhihu.com/p/364816069

NCCL--GPU的collective communication通信技术

https://blog.csdn.net/TH_NUM/article/details/81479317

nvidia-nccl学习笔记

https://developer.nvidia.com/blog/fast-multi-gpu-collectives-nccl/

Fast Multi-GPU collectives with NCCL

## 参考

https://www.infoq.cn/article/3D4MsRVS8ZOtGCj7*krT

GPU通信技术初探

https://zhuanlan.zhihu.com/p/67785062

不止显卡！这些硬件因素也影响着你的深度学习模型性能

# AMD

## Matrix Core

对标英伟达Tensor Core，AMD推出Matrix Core。

## 高速互联

对标NVLink，AMD推出了：

GMI：Global Memory Interconnect

AMD Infinity Fabric Link

其实Intel也有一个叫做Xelink的东西。

IBM BlueLink

---

HCCS，即Huawei Cache Coherence System，华为自研，叫“华为Cache一致性总线”。

英伟达的NVLink可以实现8颗芯片互联，而HCCS目前仅支持4路互联。

## HIP

![](/images/img4/latestGPU.png)

HIP：Heterogeneous Interface for Portability。

HIP是AMD提出的C++接口，号称能兼容CUDA和自家的ROCm。

https://zhuanlan.zhihu.com/p/545296023

写给CUDA开发者AMD ROCm & Intel oneAPI开发贴士

https://streamhpc.com/blog/2016-04-05/comparing-syntax-cuda-opencl-hip/

Comparing Syntax for CUDA, OpenCL and HiP

## Composable Kernel

Composable Kernel（CK）库旨在提供一套在AMD GPU上算子融合的后端方案。

https://www.sohu.com/a/603796560_129720

AMD Composable Kernel: 定制化算子融合，大幅提升AI端到端性能

## AITemplate

AITemplate首先在Python层寻找最优的kernel配置，生成Jinja2 template，再生成C++ template：

- NVIDIA GPU：基于CUTLASS的GPU Tensor Core C++ template；

- AMD GPU：基于CK（Composable Kernel）的Matrix Core C++ Template。

官网：

https://github.com/facebookincubator/AITemplate

参考：

https://www.zhihu.com/question/557608132

如何看待Meta发布的全新推理引擎AITemplate？

## AI服务器

AMD Instinct系列，大致对标NVIDIA DGX。

官网：

https://www.amd.com/zh-hans/graphics/instinct-server-accelerators

![](/images/img5/AMD.jpg)

---

https://zhuanlan.zhihu.com/p/434686566

AMD CDNA2架构（MI200）

https://www.zhihu.com/question/606505567

如何看待AMD发布Instinct MI300X GPU芯片？是否在大模型时代威胁Nvidia地位?

## 其他对标术语

| AMD | NVIDIA |
|:--:|:--:|
| GCN wavefront(64 threads wide) | CUDA warp(32 threads wide) |

## 参考

![](/images/img5/AMD.png)

罗家是台南水仙宫一带的世家。

---

以前的算法比较简单，数据吞吐量小，AMD的短流水线渲染单元数量多所以效率高。到了Ethash这类重IO算法主流的年代，其实A卡效率还略有优势，但是没以前那么夸张，所以N卡也被拉出来挖。

---

A卡的新驱动对于老游戏的支持有些差，解决办法：删除游戏目录下的dbghelp.dll文件。

---

https://www.zhihu.com/question/593343983

截至2023年4月，用AMD显卡做机器学习怎么样？

https://zhuanlan.zhihu.com/p/651797296

通过“最差实践”实验探索AMD GPU调度细节

# 国产半导体+

飞腾找台湾世芯代理设计，但因飞腾参与超算建设上了美国黑名单，台湾世芯宁可承受损失也不再继续提供设计服务。

飞腾的通用CPU单核性能变化像是过山车，因为它的FT-1000和FT-1500是基于SUN开源的UltraSPARC T2核心，2007年时的UltraSPARC T2可与Intel至强一较高下。飞腾在投靠ARM之后，CPU性能反而降低了。

飞腾多核互联和多路互联的技术较强，只是在ARM推出原生的互联方案之后，飞腾的研究成果也成了鸡肋。
