---
layout: post
title:  并行 & 框架 & 优化（四）——参考资料
category: DL acceleration 
---

* toc
{:toc}

# 并行 & 框架 & 优化

## FSDP

Fully Sharded Data Parallel是Facebook深度借鉴微软ZeRO之后提出的PyTorch DDP升级版本，可以认为是对标微软ZeRO，其本质是parameter sharding。Parameter sharding就是把模型参数等切分到各个GPU之上。

![](/images/img5/FSDP.png)

参考：

https://www.cnblogs.com/rossiXYZ/p/15815013.html

Facebook如何训练超大模型---(1)

https://www.cnblogs.com/rossiXYZ/p/15819817.html

Facebook如何训练超大模型---(2)

https://zhuanlan.zhihu.com/p/485208899

数据并行Deep-dive: 从DP到Fully Sharded Data Parallel（FSDP）完全分片数据并行

## Megatron

论文：

《Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism》

目前训练超大规模语言模型主要有两条技术路线：TPU + XLA + TensorFlow/JAX和GPU + PyTorch + Megatron-LM + DeepSpeed。前者由Google主导，后者背后则有NVIDIA、Meta、MS大厂加持。

![](/images/img5/Model_Parallel.jpg)

![](/images/img5/Model_Parallel.png)

## 工具

https://zhuanlan.zhihu.com/p/412118353

Kokkos:一个异构并行计算通用平台

## 参考

https://mp.weixin.qq.com/s/F10UaaoxGPOE4pc59LBCRw

数据并行化对神经网络训练有何影响？谷歌大脑进行了实证研究

https://mp.weixin.qq.com/s/UF7DDenUQJ3bL83IHxOkIw

分布式优化算法及其在多智能体系统与机器学习中的应用

https://mp.weixin.qq.com/s/6h9MeBs89hTtWsYSZ4pZ5g

蚂蚁金服核心技术：百亿特征实时推荐算法揭秘

https://mp.weixin.qq.com/s/xV5cLbCPb7Nh6i4i7DxJIQ

没人告诉你的大规模部署AI高效流程！

https://mp.weixin.qq.com/s/8R7YhcZ_Dt0oFIF3bQovxw

为了提升DL模型性能，阿里工程师打造了流式编程框架

https://mp.weixin.qq.com/s/z6gXp-EeDID1ed8_DsUbOg

90秒训练AlexNet！商汤刷新纪录

https://mp.weixin.qq.com/s/HY2yPZ--Zm5_m3B70baWjQ

谷歌开源效率怪兽GPipe，速度提升25倍，CIFAR-10精度达到99%

https://mp.weixin.qq.com/s/HQW2bPyDY_3ecZWP6NYr-w

大规模机器学习在LinkedIn预测模型中的应用实践

https://mp.weixin.qq.com/s/i1PLA1xr3CefKx1EcVUVIg

谷歌破世界纪录！圆周率计算到小数点后31.4万亿位

https://mp.weixin.qq.com/s/rX8L63-jDGJT6lCAj04I3Q

独家解读！阿里重磅发布机器学习平台PAI 3.0

https://mp.weixin.qq.com/s/Ye2GVTFIrX3SbU1-4cDLoQ

你天天叫的外卖，你知道这里面深度学习的水有多深吗

https://mp.weixin.qq.com/s/FIWfbCLgckVzeNvfThIl4Q

阿里线下智能方案进化史

https://mp.weixin.qq.com/s/pqxiF6yEZzrw8qXu2hEsaA

单机训练速度提升640倍！独家解读快手商业广告模型GPU训练平台Persia

https://mp.weixin.qq.com/s/Jcz4XWDjMmbhmAiI_zBQXQ

流式计算优化：时效性

https://mp.weixin.qq.com/s/iAHvfgn54zIwfM9K8KFJnw

DLM：微信大规模分布式n-gram语言模型系统

https://mp.weixin.qq.com/s/s7sHzzLANOp8-1LxgXQskA

谷歌开发者大会上，蚂蚁金服开源ElasticDL分布式深度学习系统

https://mp.weixin.qq.com/s/IQMXg6nIJO-9-IG3mJpvRg

ElasticDL：同时提升集群利用率和研发效率的分布式深度学习框架

https://mp.weixin.qq.com/s/sn8fMAbJbeT6JUbCpBpN6A

Jeff Dean与David Patterson：不思考体系结构的深度学习研究者不是好工程师

https://mp.weixin.qq.com/s/6zLrWJ4nE0bHFlVe5dMxHw

分布式深度学习新进展：让“分布式”和“深度学习”真正深度融合

https://mp.weixin.qq.com/s/hjC-WTMIpbWWpmXoLBfD2g

腾讯大规模分布式机器学习系统无量是如何进行技术选型的？

https://mp.weixin.qq.com/s/mg-d1W5i9rzaLMNrvq0tSQ

32分钟训练神经机器翻译，速度提升45倍

https://mp.weixin.qq.com/s/iW0k80TUPuWDE9xwHvX91g

为什么你需要Raven：全球首个真正分布式深度学习训练协议

https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650750181&idx=1&sn=156dac3c5646143fc2577972f1506836

GPU捉襟见肘还想训练大批量模型？谁说不可以

https://mp.weixin.qq.com/s/-CTVyKWtdTK0RIfzzPVyNQ

分布式与高效深度学习，140页ppt详述深度学习压缩与联邦学习训练技术进展

https://mp.weixin.qq.com/s/nTBuYuW7h9wZYuo3w1xGmQ

分布式训练的方案和效率对比

https://mp.weixin.qq.com/s/LOTQfD9KKtAq0zz4rObCGA

EB级系统空中换引擎：阿里调度执行框架如何全面升级？（DAG 2.0）

https://mp.weixin.qq.com/s/uQzwqcGwC9ZveuW64Lzkmg

分布式训练怎么还减速了呢？

https://zhuanlan.zhihu.com/p/294698838

DLPerf—分布式深度学习最佳入门(踩坑)指南

https://zhuanlan.zhihu.com/p/76638962

Pytorch分布式训练

https://zhuanlan.zhihu.com/p/360405558

PyTorch分布式训练

https://mp.weixin.qq.com/s/0aSBHvscloEnPMRLyNjQsg

PyTorch分布式训练简明教程

https://blog.csdn.net/orangerfun/article/details/123887725

torch分布式训练

https://mp.weixin.qq.com/s/r7kt1k7D1wurWs_uxdLCtg

PyTorch源码解读之分布式训练

https://mp.weixin.qq.com/s/_85oWK2plv2QOX5Qfg_-ZA

大规模机器学习优化，195页ppt与视频

https://mp.weixin.qq.com/s/soruo90Dbtzi6d1kA63Akg

阿里提出智能算力引擎DCAF，节省20%GPU算力

https://mp.weixin.qq.com/s/oDak7peTT5ynNYrH7LSWTg

分布式层次GPU参数服务器架构

https://zhuanlan.zhihu.com/p/28226956

浮点峰值那些事儿

https://zhuanlan.zhihu.com/p/285994980

针对深度学习的GPU共享

https://mp.weixin.qq.com/s/Np4w7RC2JFlB7ZGIduu71w

爱奇艺机器学习平台的建设实践

https://mp.weixin.qq.com/s/9k6PDusoDHjmz58HAZxZcw

GPipe: 小批量流水线带来的大模型训练

https://mp.weixin.qq.com/s/DwjvEn04lGzKU8mDu-5q4g

大幅提升训练性能，字节跳动与清华提出新型分布式DNN训练架构

https://mp.weixin.qq.com/s/dJa5zOXgJJQOM5uWog3JZA

Local Parallesim：一种新并行训练方法

https://zhuanlan.zhihu.com/p/335116835

推荐系统Serving架构分析

https://mp.weixin.qq.com/s/DdsJ-ZB_cX9UhbQNK6dCag

分布式深度学习训练网络综述

https://mp.weixin.qq.com/s/qpwBGlTtTLEAhYAUpPyXTQ

CMU：分布式机器学习原理与策略 AAAI2021教程，附221页ppt

https://mp.weixin.qq.com/s/nK-9ck5S6noIETOb8b2dJw

vivo AI计算平台弹性分布式训练的探索和实践

https://mp.weixin.qq.com/s/IzLtn1SR-aFuxXM3GNZbFw

蘑菇街自研服务框架如何提升在线推理效率？

https://mp.weixin.qq.com/s/GheEA0Ag0vbhZeyzqpTl0A

分布式优化：在大数据时代应运而生

https://mp.weixin.qq.com/s/3uu50NWFJqA_MTb8wSxIKA

如何优雅地训练大型模型？

https://mp.weixin.qq.com/s/RMDEvy-3-L-Rag1OrZLYhg

深度学习模型的训练时内存次线性优化

https://mp.weixin.qq.com/s/8PUIJykzoNe-fYht5ozrcQ

新一代CTR预测服务的GPU优化实践

https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650771181&idx=1&sn=30b2a5abc7261b4f2ea122e8e96fdabf

世界第一超算跑深度学习模型，2.76万块V100 GPU将分布式训练扩展到极致

https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650771231&idx=2&sn=6907d6d7a98eab353a076ed48352aadc

15分钟完成Kinetics视频识别训练，除了超级计算机你还需要TSM

https://www.zhihu.com/question/404721763

如何评价Google的GShard论文？

https://mp.weixin.qq.com/s/eTwSo3GnxSnK-BwwZeWmKA

Jeff Dean等提出自动化分层模型，优化CPU、GPU等异构环境，性能提升超60%

https://mp.weixin.qq.com/s/q0VENBNgolpeWmDapF5q_g

在有池化层、1步幅的CNN上减少冗余计算，一种广泛适用的架构转换方法

https://mp.weixin.qq.com/s/YusIuUtvTwoskNRV_OV7iw

100万帧数据仅1秒！AI大牛颜水成团队强化学习新作，代码已开源

https://www.zhihu.com/answer/2259890109

资源受限的人工智能

https://zhuanlan.zhihu.com/p/371499074

OneFlow——让每一位算法工程师都有能力训练GPT

https://mp.weixin.qq.com/s/LjdHBEyQhJq3ptMj8XVT-w

TensorFlow在推荐系统中的分布式训练优化实践

https://mp.weixin.qq.com/s/rEHhf32L09KXGJ9bbB2LEA

TensorFlow在美团外卖推荐场景的GPU训练优化实践

https://zhuanlan.zhihu.com/p/522759214

手把手推导分布式矩阵乘的最优并行策略

https://mp.weixin.qq.com/s/_o7fzCOeuZE6qFc5gHb26g

美团视觉GPU推理服务部署架构优化实践

https://zhuanlan.zhihu.com/p/619596323

LLM Inference CookBook

https://zhuanlan.zhihu.com/p/611325149

大型语言模型(LLM)训练指南

https://zhuanlan.zhihu.com/p/629589593

LLM应用开发全栈指南
