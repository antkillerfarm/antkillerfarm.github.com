---
layout: post
title:  并行 & 框架 & 优化（四）——大模型训练, Horovod, DeepSpeed, Sequence Parallel
category: DL acceleration 
---

* toc
{:toc}

# Pipeline Parallel

## pytorch（续）

`torch.distributed.pipeline`关键代码：

```
torch/distributed/pipeline/sync/pipeline.py: _clock_cycles
torch/distributed/pipeline/sync/pipe.py: _split_module
```

# 其他概念

## 分布式数据集

大模型不光模型的训练是分布式的，数据集也是分布式的。

https://www.alanshawn.com/tech/2022/02/27/tensorflow-big-dataset.html

Using Huge, Heterogenous Datasets in TensorFlow

https://tensorflow.google.cn/datasets/beam_datasets?hl=zh-cn

使用Apache Beam生成大型数据集

https://www.tensorflow.org/tutorials/distribute/input?hl=zh-cn

分布式输入

## Pathways

https://blog.csdn.net/OneFlow_Official/article/details/124054450

解读谷歌Pathways架构（一）：Single-controller与Multi-controller

https://blog.csdn.net/OneFlow_Official/article/details/124113864

解读谷歌Pathways架构（二）：向前一步是OneFlow

## 框架设计

![](/images/img4/mindspore.jpg)

https://zhuanlan.zhihu.com/p/547878945

五谈AI软件栈--无责乱弹AI软件栈研发方法论

## 数据下沉

数据下沉是将数据一次性传输到端侧，减少频繁的Host-Device数据传输来加速的技术。因为数据在Device上通过通道传输，Host侧和Device侧之间每个epoch进行一次数据交互，所以每个epoch只返回一次结果。

https://zhuanlan.zhihu.com/p/397481167

MindSpore的桎梏和破局

https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/63RC2alpha002/tfmoddevg/tfmigr1/atlasmprtg_13_9048.html

训练迭代循环下沉

# 大模型训练

目前部分深度学习框架，例如Pytorch和Tensorflow，没有办法满足超大规模模型训练的需求，于是微软基于Pytroch开发了DeepSpeed，腾讯基于Pytroch开发了派大星PatricStar，达摩院基于Tensoflow开发的分布式框架Whale。像是华为昇腾的MindSpore、百度的PaddlePaddle，还有国内的一流科技OneFlow等厂商，对超大模型训练进行了深度的跟进与探索，基于原生的AI框架支持超大模型训练。

https://zhuanlan.zhihu.com/p/432813821

大模型的发展与解决的问题

https://zhuanlan.zhihu.com/p/432289008

从分布式训练到大模型训练

https://www.zhihu.com/question/498271491

为什么说大模型训练很难？

https://zhuanlan.zhihu.com/p/611325149

大型语言模型(LLM)训练指南

https://zhuanlan.zhihu.com/p/629589593

LLM应用开发全栈指南

## 实战经验

https://pytorch.org/blog/high-performance-llama-2/

https://huggingface.co/blog/zh/bloom-inference-optimization

https://huggingface.co/blog/zh/bloom-megatron-deepspeed

---

![](/images/img5/Spike.webp)

训练过程中，损失偶尔会出现毛刺的情况。针对这种情况，Falcon作者会恢复到上一个最新的 Checkpoint，并跳过1B Token数据继续训练。作者训练Falcon-180B时出现了9次毛刺。

Google训练PaLM模型遇到了同样的问题。针对此种情况，作者会重启训练，并从毛刺之前的100个step开始，跳过200-500个Batch的数据。作者也做了消融实验，发现并不是单个数据的问题，而可能是这连续的一系列Batch数据引起的。

https://mp.weixin.qq.com/s/rLJlaqI2RL7TGUEQyx-QaA

万卡GPU集群实战：探索LLM预训练的挑战

## 内存墙

从GPT-1到GPT-3，两年时间内模型参数0.1B增加到175B，而同期，NVIDIA交出的成绩单是从V100的32GB显存增加A100的80GB，显然，显存的提升速度远远赶不上模型模型增长的速度，这就是内存墙问题。

https://mp.weixin.qq.com/s/kuIsyX0QEIeFHn8tvFE8vw

AI训练的最大障碍不是算力，而是“内存墙”

## activation checkpointing

![](/images/img5/activation_checkpointing.png)

在每个mini-batch的前向过程中删除一些暂时用不到的中间激活特征以降低内存占用，并在后向过程中需要时借助额外的前向计算恢复它们。

https://zhuanlan.zhihu.com/p/373662730

亚线性内存优化—activation checkpointing在oneflow中的实现

## bucket

Bucketing是一种训练多个不同但又相似的结构的网络的方法，这些网络共享相同的参数集。

一个典型的应用是循环神经网络（RNNs）。实现RNNs通常会沿时间轴将网络显式地展开。为了处理序列中的所有元素，我们需要将网络展开成最大可能的序列长度。然而这很浪费资源，因为对于较短的序列，大部分计算都浪费在填充的数据的执行上了。

Bucketing不再将网络展开成最大可能长度，而是展开成多个不同长度的实例（比如，长度为5, 10, 20, 30）。在训练过程中，对于不同长度的最小批数据，使用最恰当的展开模型。

https://blog.csdn.net/xuezhisdc/article/details/54927869

how_to——bucketing

---

在训练各个部分耗时中，backward(BWD)反向传播部分，通常占比比较大，相比之下，参数更新的部分（OPT）则通常是耗时比重小的部分。

所以为了能够overlap通讯的耗时，Pytorch DDP选择在backward的时候进行梯度更新，并且为此引入bucket的概念。一个bucket里通常有不超过一定大小的几个layer的参数组成（默认是25MB），当一个bucket内部的梯度准备好了之后，则这个bucket就可以开始进行ring-all-reduce取平均操作，而不需要等到计算完整个模型的反向传播过后才进行一次统一的ring-all-reduce操作，相当与把多卡通讯的时间隐藏在了backward计算的耗时中，大大提升了资源利用效率。

# Horovod

Horovod是Uber开源的一套分布式深度学习框架。Horovod支持TensorFlow、Keras、PyTorch和Apache MXNet等后端框架。

官网：

https://eng.uber.com/horovod/

代码：

https://github.com/horovod/horovod

Horovod主打Data Parallel。这在前LLM时代用的比较多，但对于LLM而言，单卡根本放不下所有的参数，Data Parallel也就用不起来了。

参考：

https://www.cnblogs.com/rossiXYZ/p/14856464.html

深度学习分布式训练框架Horovod

https://zhuanlan.zhihu.com/p/40578792

Horovod-基于TensorFlow分布式深度学习框架

https://zhuanlan.zhihu.com/p/158375055

PyTorch单机多卡操作(分布式DataParallel，混合精度，Horovod)

https://mp.weixin.qq.com/s/iQIRj7ifsOEnupYZuQsVwQ

是时候放弃TensorFlow集群，拥抱Horovod了

https://mp.weixin.qq.com/s/qOjGrR59Mf0Mzgh4bpDhrA

详解Horovod：Uber开源的TensorFlow分布式深度学习框架

https://mp.weixin.qq.com/s/yNxjJHpGns6utpBpI-0XDA

分布式训练框架Horovod初步学习

https://zhuanlan.zhihu.com/p/374575049

一文看懂Horovod源码

https://mp.weixin.qq.com/s/7c7Q0P3g3IEL_r4BU2ZxRg

Horovod架构剖析——解密最成功的第三方DL分布式训练框架

https://horovod.readthedocs.io/en/stable/xla.html

Horovod with XLA in Tensorflow

# DeepSpeed

显存内容可分为两类：

- 模型状态（model states）: 模型参数（fp16）、模型梯度（fp16）和Adam状态（fp32的模型参数备份，fp32的momentum和fp32的variance）。假设模型参数量为$$\Phi$$，则共需要$$2\Phi+2\Phi+(4\Phi+4\Phi+4\Phi)=16\Phi$$字节存储，可以看到，Adam状态占比75%。

![](/images/img5/ZeRO_offload.jpg)

- 剩余状态（residual states）: 除了模型状态之外的显存占用，包括激活值（activation）、各种临时缓冲区（buffer）以及无法使用的显存碎片（fragmentation）。

![](/images/img5/ZeRO.png)

ZeRO使用分片（partition）方法，即每张卡只存1/N的模型状态量。

![](/images/img5/ZeRO_2.png)

除了模型参数必须广播到各节点之外，模型梯度可以由各节点自己生成，然后再将之Reduce到保存数据的节点（即上图中的GPU 3）中。

只有模型梯度，由于来自不同的Data，需要各节点的同步，其他的Adam状态数据均与Data无关，由各节点自行计算更新即可。

代码：

https://github.com/microsoft/DeepSpeed

示例：

https://github.com/microsoft/DeepSpeedExamples

stage 1 & 2的代码在：

deepspeed/runtime/zero/stage_1_and_2.py

官网：

https://www.deepspeed.ai

DeepSpeed提供了PDSH、OpenMPI、MVAPICH三种方式在多机多卡模式下运行模型。

PDSH：Parallel Distributed Shell

添加backend：

accelerator/cuda_accelerator.py

参考：

https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters

ZeRO & DeepSpeed

https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/

DeepSpeed: Extreme-scale model training for everyone

https://mp.weixin.qq.com/s/Vb3AkoWHQY7WWBMZaVnf4g

微软发布DeepSpeed开源库，支持1000亿个参数模型的训练

https://zhuanlan.zhihu.com/p/621379646

人手一个ChatGPT！微软DeepSpeed Chat震撼发布，一键RLHF训练千亿级大模型

https://zhuanlan.zhihu.com/p/513571706

DeepSpeed之ZeRO系列：将显存优化进行到底

https://zhuanlan.zhihu.com/p/630734624

deepspeed入门教程

https://zhuanlan.zhihu.com/p/576673548

深度学习大模型训练--DeepSpeed源码解读

https://zhuanlan.zhihu.com/p/626420999

deepspeed chat代码解读

## GSPMD

GSPMD是在GShard基础上发展而来的并行算法。

《GSPMD:General and Scalable Parallelization for ML Computation Graphs》

# Sequence Parallel

![](/images/img5/TP_SP.png)

MegatronLM提出的Sequence Parallel算法，由于TP和SP交替进行，又被称为TP-SP算法。

对于Attention+MLP采用TP，对于其他部分采用SP。

推理阶段由于weight固定，所以每次生成token的时候，之前的计算大部分可以复用，只需要计算新token引入的那部分计算即可。

然而训练阶段，由于weight可变，即使是input+已生成token不变，也需要重新参与前后向计算。这时就需要SP了。

https://blog.csdn.net/qinduohao333/article/details/131629428

详解MegatronLM序列模型并行训练(Sequence Parallel)

---

通用性较强的Ulysses，在小规模或长序列上表现更好。

《DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models》

![](/images/img5/DS-Ulysses.png)

图中N表示序列长度，d表示`hidden_size=(hc * hs)，hc = head_cnt，hs=head_size`，P表示GPU数目（图中 P=4）。红色虚线表示通信，黑色虚线表示计算。

DS-Ulysses 对Q、K、V沿着N维度切分成P份，三个分布式矩阵通过All2All变成沿d维度切分了。All2All等价于一个分布式转置操作。之后就是正常的$$softmax(QK^T)V$$计算，可以用 FlashAttention加速，得到结果再通过All2All转置回来。

![](/images/img5/SP.jpg)

https://zhuanlan.zhihu.com/p/689067888

大模型训练之序列并行双雄：DeepSpeed Ulysses和Ring-Attention

https://zhuanlan.zhihu.com/p/703669087

我爱DeepSpeed-Ulysses：重新审视大模型序列并行技术

---

FastSeq，它能将qkv projection的计算和all-gather通信重叠，只需多占用一点内存就可更进一步提升训练效率。

《FastSeq: Make Sequence Generation Faster》
