---
layout: post
title:  并行 & 框架 & 优化（三）——tf.distribute & MultiDevice, 其他概念, 大模型训练
category: DL acceleration 
---

* toc
{:toc}

# tf.distribute & MultiDevice

MirroredStrategy：单机多卡训练

MultiWorkerMirroredStrategy：多机训练

CentralStorageStrategy也执行同步训练，但是变量不会被镜像，而是放在CPU上。各操作(operation)在本地GPU之间复制进行。如果只有一个GPU，变量和操作都会放在GPU上。在对CPU上的变量进行更新前，该策略会先将所有 GPU副本的上的变量梯度进行聚合，然后应用到CPU变量更新中。

---

tensorflow::ProcessFunctionLibraryRuntime::RunMultiDevice

https://www.cnblogs.com/rossiXYZ/p/16142677.html

TensorFlow之分布式变量（该作者写了一系列的TF分布式文章）

示例：

https://github.com/antkillerfarm/antkillerfarm_crazy/tree/master/python/ml/tensorflow/xla/multi_device_lenet_xla.py

## Rendezvous

Rendezvous是一个法语单词，发音也比较特殊，一般直译为“约会、相会、会和”，而在TensorFlow中，Rendezvous是用来完成消息传输的通信组件。

消息传输的唯一标识符——ParsedKey

Send和RecvAsync二者的相对顺序是不能保证先后的，经常出现需求比供给在时间片上先到的情况，总是迟到的一方执行waiter函数。

Send方——将Ready的Tensor挂入本地Table

Recv方——向Send方主动发出请求，触发通信过程

所以，真正的通信过程由Recv方触发，而不是Send方。

TensorFlow已经支持包括gRPC，RDMA（Remote Direct Memroy Access），GDR（GPU Direct）和MPI四种通信协议。

BFC（Best-Fit with Coalescing）是dlmalloc的一个简单实现版本。

https://www.cnblogs.com/deep-learning-stacks/p/10354258.html

TensorFlow中的通信机制——Rendezvous（一）本地传输

https://www.cnblogs.com/deep-learning-stacks/p/10355770.html

TensorFlow中的通信机制——Rendezvous（二）gRPC传输

https://blog.csdn.net/gaofeipaopaotang/article/details/80736452

模型优化之分布式执行

https://xieyu.github.io/blog/tensorflow/rendezvous.html

Tensorflow Rendezvous

---

Host to Device：

SameWorkerRecvDone -> CopyTensor::ViaDMA -> CopyHostToDevice -> XlaDeviceContext::CopyCPUTensorToDevice ->

GenericTransferManager::TransferLiteralToDeviceAsync -> TransferManager::TransferBufferToDevice -> Stream::ThenMemcpy

## StreamExecutor

StreamExecutor是Google内部为并行编程模型开发的库。TensorFlow中的StreamExecutor是StreamExecutor的开源简版。

https://www.cnblogs.com/deep-learning-stacks/p/9386188.html

TensorFlow中的并行执行引擎——StreamExecutor框架

TF使用`stream_executor::DeviceMemoryBase`作为设备内存的抽象。用`DeviceMemoryBase::opaque`作为对于不可直接访问的设备地址的指针。

`class GpuExecutor : public internal::StreamExecutorInterface`

所以上面提到的Memcpy的调用路径，还有设备相关的后半部分：

Stream::ThenMemcpy -> StreamExecutor::Memcpy -> GpuExecutor::Memcpy -> GpuDriver::AsynchronousMemcpyH2D -> cuMemcpyHtoDAsync

## TransferManager

`TransferManager`类使后端能够提供特定于平台的机制，用于通过给定的设备内存句柄构造XLA literal data。换言之，它可以帮助封装主机与设备之间的双向数据传输。

`TransferManager`类已经有了一个通用实现：`GenericTransferManager`，设备只需要派生该类，做一些定制化的修改。所以`xxx_transfer_manager.h`是关注的重点。

TPU和GPU的修改主要集中在`TransferLiteralToInfeed`和`TransferLiteralFromOutfeed`两个函数。

这两个函数的GPU实现在`InfeedManager`类中。

`TransferLiteralToInfeed`关键函数调用：

gpu::CopyBufferToDevice -> Stream::ThenMemcpy

如果不对`GenericTransferManager`做修改，则该类会用Host上的mem buffer，虚拟一个`DeviceMemoryBase`来处理Feed。

graphcore的实现没有动`GenericTransferManager`，而是自己单独弄了一套基于`TranslatedFeedInfo`类的cache机制。

tensorflow/compiler/plugin/poplar/driver/poplar_executable_cache.cc

# 其他概念

## 分布式数据集

大模型不光模型的训练是分布式的，数据集也是分布式的。

https://www.alanshawn.com/tech/2022/02/27/tensorflow-big-dataset.html

Using Huge, Heterogenous Datasets in TensorFlow

https://tensorflow.google.cn/datasets/beam_datasets?hl=zh-cn

使用Apache Beam生成大型数据集

https://www.tensorflow.org/tutorials/distribute/input?hl=zh-cn

分布式输入

## Pathways

https://blog.csdn.net/OneFlow_Official/article/details/124054450

解读谷歌Pathways架构（一）：Single-controller与Multi-controller

https://blog.csdn.net/OneFlow_Official/article/details/124113864

解读谷歌Pathways架构（二）：向前一步是OneFlow

## Bucketing

Bucketing是一种训练多个不同但又相似的结构的网络的方法，这些网络共享相同的参数集。

一个典型的应用是循环神经网络（RNNs）。实现RNNs通常会沿时间轴将网络显式地展开。为了处理序列中的所有元素，我们需要将网络展开成最大可能的序列长度。然而这很浪费资源，因为对于较短的序列，大部分计算都浪费在填充的数据的执行上了。

Bucketing不再将网络展开成最大可能长度，而是展开成多个不同长度的实例（比如，长度为5, 10, 20, 30）。在训练过程中，对于不同长度的最小批数据，使用最恰当的展开模型。

https://blog.csdn.net/xuezhisdc/article/details/54927869

how_to——bucketing

## 框架设计

![](/images/img4/mindspore.jpg)

https://zhuanlan.zhihu.com/p/547878945

五谈AI软件栈--无责乱弹AI软件栈研发方法论

## 数据下沉

数据下沉是将数据一次性传输到端侧，减少频繁的Host-Device数据传输来加速的技术。因为数据在Device上通过通道传输，Host侧和Device侧之间每个epoch进行一次数据交互，所以每个epoch只返回一次结果。

https://zhuanlan.zhihu.com/p/397481167

MindSpore的桎梏和破局

https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/63RC2alpha002/tfmoddevg/tfmigr1/atlasmprtg_13_9048.html

训练迭代循环下沉

# 大模型训练

目前部分深度学习框架，例如Pytorch和Tensorflow，没有办法满足超大规模模型训练的需求，于是微软基于Pytroch开发了DeepSpeed，腾讯基于Pytroch开发了派大星PatricStar，达摩院基于Tensoflow开发的分布式框架Whale。像是华为昇腾的MindSpore、百度的PaddlePaddle，还有国内的一流科技OneFlow等厂商，对超大模型训练进行了深度的跟进与探索，基于原生的AI框架支持超大模型训练。

https://zhuanlan.zhihu.com/p/432813821

大模型的发展与解决的问题

https://zhuanlan.zhihu.com/p/432289008

从分布式训练到大模型训练

https://www.zhihu.com/question/498271491

为什么说大模型训练很难？

## TF-Replicator, GPipe, Mesh-Tensorflow

TF-Replicator主要侧重于Data parallelism的库。

GPipe是一个纯model-parallelism的库。

Mesh-TensorFlow是一个DSL语言，既支持Data parallelism，又支持Model parallelism，但是侵入性很强。

参考：

https://zhuanlan.zhihu.com/p/113233933

谷歌GPipe训练超大规模神经网络

https://zhuanlan.zhihu.com/p/342223356

Mesh-Tensorflow: 广义分布式

https://zhuanlan.zhihu.com/p/63211072

TF-Replicator, GPipe, Mesh-Tensorflow 三个库对比

## activation checkpointing

![](/images/img5/activation_checkpointing.png)

在每个mini-batch的前向过程中删除一些暂时用不到的中间激活特征以降低内存占用，并在后向过程中需要时借助额外的前向计算恢复它们。

https://zhuanlan.zhihu.com/p/373662730

亚线性内存优化—activation checkpointing在oneflow中的实现

## DeepSpeed

显存内容可分为两类：

- 模型状态（model states）: 模型参数（fp16）、模型梯度（fp16）和Adam状态（fp32的模型参数备份，fp32的momentum和fp32的variance）。假设模型参数量为$$\Phi$$，则共需要$$2\Phi+2\Phi+(4\Phi+4\Phi+4\Phi)=16\Phi$$字节存储，可以看到，Adam状态占比75%。

- 剩余状态（residual states）: 除了模型状态之外的显存占用，包括激活值（activation）、各种临时缓冲区（buffer）以及无法使用的显存碎片（fragmentation）。

![](/images/img5/ZeRO.png)

ZeRO使用分片（partition）方法，即每张卡只存1/N的模型状态量。

![](/images/img5/ZeRO_2.png)

除了模型参数必须广播到各节点之外，模型梯度可以由各节点自己生成，然后再将之Reduce到保存数据的节点（即上图中的GPU 3）中。

只有模型梯度，由于来自不同的Data，需要各节点的同步，其他的Adam状态数据均与Data无关，由各节点自行计算更新即可。

代码：

https://github.com/microsoft/DeepSpeed

参考：

https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters

ZeRO & DeepSpeed

https://mp.weixin.qq.com/s/Vb3AkoWHQY7WWBMZaVnf4g

微软发布DeepSpeed开源库，支持1000亿个参数模型的训练

https://zhuanlan.zhihu.com/p/621379646

人手一个ChatGPT！微软DeepSpeed Chat震撼发布，一键RLHF训练千亿级大模型

https://zhuanlan.zhihu.com/p/513571706

DeepSpeed之ZeRO系列：将显存优化进行到底

https://zhuanlan.zhihu.com/p/630734624

deepspeed入门教程

https://zhuanlan.zhihu.com/p/576673548

深度学习大模型训练--DeepSpeed源码解读

https://zhuanlan.zhihu.com/p/626420999

deepspeed chat代码解读

## LoRA

LoRA: Low-Rank Adaptation of Large Language Models是微软研究院引入的一项新技术，主要用于处理大模型微调的问题。

lora模型可以简单理解为在基础模型之上的一个补丁模型，用来训练特定风格、特定人物、特定动作等效果。因为基础模型提供了强大的通用能力，但对于指定人物、或者特定的一种风格掌握的并不精，所以需要lora模型来针对性学习下特定领域的效果。

https://huggingface.co/datasets/HuggingFace-CN-community/translation/blob/main/lora_cn.md

使用LoRA进行Stable Diffusion的高效参数微调

https://zhuanlan.zhihu.com/p/631411685

微软LoRA：使用万分之一的参数微调你的GPT3模型
