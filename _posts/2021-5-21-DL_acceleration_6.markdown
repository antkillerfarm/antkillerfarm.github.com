---
layout: post
title:  深度加速（六）——模型压缩与加速进阶（1）
category: DL acceleration 
---

* toc
{:toc}

# 模型压缩与加速进阶

https://mp.weixin.qq.com/s/nys9R6xCJXt0vG06gnQzFQ

模型剪枝，不可忽视的推断效率提升方法

https://mp.weixin.qq.com/s/EuT-4_eEtIVKh6QdLDbohg

解读小米MoGA：超过MobileNetV3的移动端GPU敏感型搜索

https://mp.weixin.qq.com/s/L49cqZ2PXP-x4Y6xBJG5cQ

旷视研究院提出MetaPruning：基于元学习和AutoML的模型压缩新方法

https://mp.weixin.qq.com/s/F_p414ezQ0RDhPnZj36SUA

网络剪枝中的AutoML方法

https://zhuanlan.zhihu.com/c_151876233

如何Finetune一个小网络到移动端（时空性能分析篇）

https://mp.weixin.qq.com/s/kU0_BuQW8VQihUwBuZ90cA

发布可伸缩超网SCARLET，小米AutoML团队NAS三部曲杀青

https://mp.weixin.qq.com/s/ZfW-jDSo6uaaqdmJtBizOA

从模型精简，硬件实现，到模型剪枝

https://mp.weixin.qq.com/s/5ywMyedmplCSLzWlnoFDSQ

模型剪枝技术原理及其发展现状和展望

https://mp.weixin.qq.com/s/8jyQ_7DYn7lHMcAWokKbcA

超Mask RCNN速度4倍，仅在单个GPU训练的实时实例分割算法

https://mp.weixin.qq.com/s/TC_Ju2vuKDP6d538v2F8CQ

剪枝需有的放矢，快手&罗切斯特大学提出基于能耗建模的模型压缩

https://mp.weixin.qq.com/s/UkqwPBYgYQuIB9_jGMt2QQ

Rocket Training: 一种提升轻量网络性能的训练方法

https://mp.weixin.qq.com/s/xCzS7sYMFmk5K4ClB1I2YQ

Uber提出SBNet：利用激活的稀疏性加速卷积网络

https://mp.weixin.qq.com/s/6Wj0Y4y30BVA75WrU4oZbQ

SBNet: 提高自动驾驶系统的感知效率

https://mp.weixin.qq.com/s/HXxnhMjAchxKSidu45kOeg

网络压缩最新进展：2019年最新文章概览

https://mp.weixin.qq.com/s/Bl7-hGIxZMsHxscqb7DnMA

200～1000+fps！谷歌公布亚毫秒级人脸检测算法BlazeFace，面向移动GPU

https://mp.weixin.qq.com/s/l2_N-PXjDMCqSRwYxU4BEA

模型加速概述与模型裁剪算法技术解析

https://mp.weixin.qq.com/s/af-z73asc-PmpEsI_yEulA

北邮提出新AI模型压缩算法，显著降低计算复杂度

https://mp.weixin.qq.com/s/AOI2LUjiKPUJFE0D7zX0Hw

谷歌新研究：基于数据共享的神经网络快速训练方法

https://mp.weixin.qq.com/s/Q0XyKIrbOIrA3YsYHmwK1Q

移动端高效率的分组网络都发展到什么程度了？

https://mp.weixin.qq.com/s/l3790PuutrOF27RRmVqJhQ

面对千万级推荐，如何压缩模型最高效？这是腾讯看点新框架

https://mp.weixin.qq.com/s/n_LY6mmJRH5k_cubYOTq1A

模型剪枝有哪些关键技术，如何对其进行长期深入学习

https://mp.weixin.qq.com/s/NsvjADgQZrYkUGNN6fzXVg

驭势科技推出“东风网络”：如何找到速度-精度的最优解？

https://mp.weixin.qq.com/s/HzgRHtVwdmW6_m7OJwK-ew

SysML 2019论文解读：Accurate and Efficient 2-Bit Quantized Neural Netowrks

https://mp.weixin.qq.com/s/oah61YozMB2fMfpDqPwHjw

Deep Compression神经网络压缩经典之作

https://mp.weixin.qq.com/s/ulrPhfsPunKAWYohBhkh9w

寻找最佳的神经网络架构，韩松组两篇论文解读

https://mp.weixin.qq.com/s/oDwvMtET0moHVGgtQLfCow

5个可以让你的模型在边缘设备上高效推理的算法

https://mp.weixin.qq.com/s/nbEa0csbaMvEM3TCI3fn0Q

当前模型剪枝有哪些可用的开源工具？

https://mp.weixin.qq.com/s/0_66CScEk0qhGlTvfpmqBA

2019年的最后一个月，这里有6种你必须要知道的最新剪枝技术

https://mp.weixin.qq.com/s/u94NZVwb_ywqjTMla2upbQ

模型压缩究竟在做什么？我们真的需要模型压缩么？

https://mp.weixin.qq.com/s/Qr2Q2ARht0pEP3F8l3k98g

滴滴&东北大学提出自动结构化剪枝压缩算法框架，性能提升高达120倍

https://zhuanlan.zhihu.com/p/104447447

剪枝实践：图像检索如何加速和省显存？

https://zhuanlan.zhihu.com/p/105064255

Slimmable Networks

https://mp.weixin.qq.com/s/EBCcBWob_iFa51-gOVPYQA

揭秘微信“扫一扫”识物为什么这么快？

https://mp.weixin.qq.com/s/GFE2XYHZXPP0doQ5nd0JNQ

当前深度神经网络模型压缩和加速方法速览

https://mp.weixin.qq.com/s/JnW7RnOQKG-dPOOAQeOmSA

当前深度神经网络模型压缩和加速都有哪些方法？

https://mp.weixin.qq.com/s/YUg2dZZhDSsRpSftdNfiIQ

极致的优化：智能手机是如何处理大型神经网络的

https://mp.weixin.qq.com/s/vswtn3D1-VZZlyKLJmHc7A

纪荣嵘：深度神经网络压缩及应用

https://mp.weixin.qq.com/s/mWfZ4jfuby4myGfi6TW3wQ

从超参数到架构，一文简述模型优化策略

https://mp.weixin.qq.com/s/fU-AeaPz-lHlg0CBgqnpZQ

轻量化神经网络综述

https://mp.weixin.qq.com/s/n7neAptKozRz5p5ctvKZrQ

模型压缩——结构篇

https://mp.weixin.qq.com/s/MGR36sC581WuQ-2WMnf5vA

深度压缩网络总结

https://mp.weixin.qq.com/s/1EnPWdJk8vGzxxdzAwPO4A

剪枝乱炖

https://mp.weixin.qq.com/s/UmtCq6WzIDQs3IAxhRFgNw

浅谈模型压缩之量化、剪枝、权重共享

https://mp.weixin.qq.com/s/H6OTkpdIgSdugDrEMBLybw

超越MobileNetV3的轻量级网络（GhostNet）

https://mp.weixin.qq.com/s/Vh5Y9Ru_hbN0CzM7_xGg6A

超越GhostNet！吊打MobileNetV3！MicroNet通过极低FLOPs实现图像识别

https://mp.weixin.qq.com/s/DLNyb-GtzmSYuXcn6VQz4Q

高效轻量级深度模型的研究和实践

https://mp.weixin.qq.com/s/3SWtxtV9b0dFpvqfTNlqIg

Slimmable Neural Networks

https://mp.weixin.qq.com/s/lc7IoOV6S2Uz5xi7cPQUqg

基于元学习和AutoML的模型压缩新方法

https://zhuanlan.zhihu.com/p/64400678

轻量卷积神经网络的设计

https://mp.weixin.qq.com/s/pJk84bNzRn7LZZfQfSjs5A

VarGFaceNet：地平线提出轻量级、有效可变组卷积的人脸识别网络

https://mp.weixin.qq.com/s/cYimAphdyFO_XqKfT2Hbeg

如何使用强化学习进行模型剪枝

https://mp.weixin.qq.com/s/SgELZgoHzIvbg2-jzJw6Tw

港科大、清华与旷视提出基于元学习的自动化神经网络通道剪枝网络

https://mp.weixin.qq.com/s/q5-91AAKwBiYzTMmqadEcg

RefineDetLite：腾讯提出轻量级高精度目标检测网络

https://mp.weixin.qq.com/s/Vh5Y9Ru_hbN0CzM7_xGg6A

MicroNet通过极低FLOPs实现图像识别

https://mp.weixin.qq.com/s/Ck_GDv1Xo-YMZcu-00gTOA

中星微夺冠国际人工智能算法竞赛，目标检测一步法精度速度双赢

https://mp.weixin.qq.com/s/qWJarPrjOrwxSX77xQ9rCw

面向卷积神经网络的卷积核冗余消除策略

https://mp.weixin.qq.com/s/4aVY9vUBX_Bxht953r00sA

在Keras中利用TensorNetwork加速神经网络

https://mp.weixin.qq.com/s/5NM9M1oY8bwsEqdBRVYpMg

网络规模更小、速度更快，这是谷歌提出的MorphNet

https://mp.weixin.qq.com/s/SC3ebx-C4N4H8B_R6K09cg

分段的人脸检测在移动端的应用

https://mp.weixin.qq.com/s/_C5AvD3YmRH2dmBjbEZFrQ

神经网络子网络压缩10倍，精确度保持不变

https://zhuanlan.zhihu.com/p/65348860

南邮提出实时语义分割的轻量级网络：LEDNET

https://zhuanlan.zhihu.com/p/67272163

百度提出关于网络压缩和加速的新剪枝算法

https://mp.weixin.qq.com/s/jHv3Amti1YZq51Df2mNFtg

network sliming:加快模型速度同时不损失精度

https://mp.weixin.qq.com/s/gwXXkWumGWy24oWuZKSyAQ

MIT韩松组推出升级版AutoML方法，一个网络适配所有硬件

https://zhuanlan.zhihu.com/p/76909380

轻量型网络：MoGA简介

https://mp.weixin.qq.com/s/kgl7mz4bK7SywkbViY_qhQ

利用LSTM思想来做CNN剪枝，北大提出Gate Decorator

https://mp.weixin.qq.com/s/3_famaAmkAN-4xVEupSXSA

华为、北大等首创GAN剪枝算法，线上加速3倍以上

https://mp.weixin.qq.com/s/KuZ-mZKt7bTWhzygK1lmSg

加速目标检测

https://zhuanlan.zhihu.com/p/261146248

原生模型上的战斗

https://mp.weixin.qq.com/s/jqRBrs9Y_-3qvemL0RTflA

支付宝如何优化移动端深度学习引擎？

https://mp.weixin.qq.com/s/NJzGR-tY_WWeccbdshHckA

基于交错组卷积的高效深度神经网络

https://mp.weixin.qq.com/s/6eyEMW9dVBR5cZrHxn8iqA

腾讯AI Lab详解3大热点：模型压缩、自动机器学习及最优化算法

https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/

论文-Learning Structured Sparsity in Deep Neural Networks

https://mp.weixin.qq.com/s/d6HFVbbHwkxPGdnbyVuMyQ

密歇根州立大学提出NestDNN：动态分配多任务资源的移动端深度学习框架

https://mp.weixin.qq.com/s/lUTusig94Htf7_4Z3X1fTQ

清华&伯克利ICLR论文：重新思考6大剪枝方法

https://mp.weixin.qq.com/s/g3y9mRhkFtzSuSMAornnDQ

韩松博士论文：面向深度学习的高效方法与硬件

https://mp.weixin.qq.com/s/aH1zQ7we8OE59-O9n4IXhw

应对未来物联网大潮：如何在内存有限的情况下部署深度学习？

https://mp.weixin.qq.com/s/GJ7JMtWiKBku7dVJWOfLOA

CNN能同时兼顾速度与准确度吗？CMU提出AdaScale

https://mp.weixin.qq.com/s/pmel2k2J159zQi87ib3q8A

如何让CNN高效地在移动端运行

https://mp.weixin.qq.com/s/m-wQRm3VpfQkEOoUAxEdoA

论文解读: Quantized Convolutional Neural Networks for Mobile Devices

https://mp.weixin.qq.com/s/w7O2JxDH2ECqPn50sLfxpg

不用重新训练，直接将现有模型转换为MobileNet

https://mp.weixin.qq.com/s/EW6jvf98ifBucVz74SfSIA

文档扫描：深度神经网络在移动端的实践

https://mp.weixin.qq.com/s/3oL0Bso3mwbsfaG8X5-xoA

英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络

https://mp.weixin.qq.com/s/LGCGYSoMpPfojEi2WcmjnQ

TinyML：下一轮人工智能革命

https://mp.weixin.qq.com/s/B-OJ_oW_uJufqIfIZSA7Ww

专家从7个维度全面评测轻量级网络

https://mp.weixin.qq.com/s/UDUOIIyGJtXHdc3xcyfOIg

万字综述：用于深度神经网络加速的Shift操作

https://zhuanlan.zhihu.com/p/301162618

深度学习模型压缩与加速

https://mp.weixin.qq.com/s/Lv1JuwNohAsIAB1SKT7Lkg

深度卷积网络的剪枝和加速

https://mp.weixin.qq.com/s/VEnX3YKQ02mRg2qbqMbXcg

轻量级网络综述—主干网络篇

https://mp.weixin.qq.com/s/s9Bp3s-Ep3QPDpo1mmwgWw

模型压缩系列一：模型替换

https://mp.weixin.qq.com/s/CNaQbeLbN4J3CsUIMaezFw

模型压缩系列二：模型蒸馏

https://mp.weixin.qq.com/s/WVwB-ldc8Yoin6I_m6RT5g

CNN轻量化模型及其设计原则综述

https://mp.weixin.qq.com/s/IfvXrsUq8-cBDC4_3O5v_w

Facebook新研究优化硬件浮点运算，强化AI模型运行速率

https://mp.weixin.qq.com/s/Jsxiha_BFtWVLvO4HMwJ3Q

工业界第一手实战经验：深度学习高效网络结构设计

https://mp.weixin.qq.com/s/F0ykoKv027ycinsAZZjbWQ

ThunderNet：国防科大、旷视提出首个在ARM上实时运行的通用目标检测算法

https://mp.weixin.qq.com/s/J3ftOKDPBY5YYD4jkS5-aQ

ThunderNet：Two-stage形式的目标检测也可很快而且精度很高
