---
layout: post
title:  CUDA（一）
category: AI 
---

* toc
{:toc}

# CUDA

CUDA是NVIDIA最早推出的通用数学运算库。除了基本的数学运算之外，还提供了一些工具包：

cuBLAS：线性计算库。除了基本版的API之外，它还包括以下扩展：

- cuBLASXt适合处理非常大的矩阵和多GPU操作。
- cuBLASLt提供了一定程度的灵活性，适合中等大小的矩阵。
- cuBLASDx则提供了更高的灵活性和控制，适合在设备端执行小规模的矩阵操作和融合操作。

NVBLAS：多GPU版的cuBLAS。

cuFFT：FFT计算库。

nvGRAPH：图计算库。（这里的图是数学图论中的图，和DL框架中的计算图是两回事。）

cuRAND：随机数生成库。

官方文档：

https://docs.nvidia.com/cuda/pdf/CURAND_Library.pdf

cuSPARSE；稀疏矩阵计算库。

cuSOLVER：解线性方程的计算库。包括解稠密方程的cuSolverDN、解稀疏方程的cuSolverSP和矩阵分解的cuSolverRF。

---

官方文档：

https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html

---

https://github.com/nvidia/cccl

CUDA Core Compute Libraries (CCCL)

https://cuda.godbolt.org/

nvcc online compiler

## NVIDIA DALI

NVIDIA DALI是一个GPU加速的数据增强和图像加载库，为优化深度学习框架数据pipeline而设计，而其中的NVIDIA nvJPEG是用于JPEG解码的高性能GPU加速库。

代码：

https://github.com/NVIDIA/dali

## Tensor Core

Tensor Core是Nvidia GPU自Volta架构开始，专门为深度学习矩阵运算设计的计算单元。

CUTLASS：另一个线性计算库，专为Tensor Core设计。

![](/images/img6/CUTLASS.png)

类似的东西还有Arm的SME、Intel的AMX等。

---

![](/images/img6/CUTLASS_2.png)

CUTLASS主要基于以下指令：

- MMA（Matrix Multiply-Accumulate）
- WMMA（Warp Matrix Multiply-Accumulate）：WMMA是针对Tensor Core设计的，它在warp级别（即32个线程）上执行矩阵乘法运算。
- WGMMA（Warp Group Matrix Multiply-Accumulate）：WGMMA是WMMA的扩展，提供了更广泛的矩阵尺寸和数据类型的支持。对并行计算的控制也更为精细。
- TMA（Tensor Memory Accelerator）：用于在global memory和shared memory之间搬运数据。
- BMMA（Binary Matrix Multiply-Accumulate）：提供按位操作的矩阵乘法。

---

CuTe，全称为"collection of C++ CUDA template abstractions for defining and operating on hierarchically multidimensional layouts of threads and data"，是一个处理嵌套layout的模板抽象的集合，其并不提供**现成算子**支持，而是给出数据结构，使得复杂的线性代数计算得以加速。

https://dingfen.github.io/2024/08/18/2024-8-18-cute/

深入CUTLASS之CuTe详解

https://zhuanlan.zhihu.com/p/699255051

cute TiledMMA

---

pingpong就是N=2的multi-stage，所以这个问题等价于为什么在Ampere NStage=2不够了。

Warp-Specialization的优势是在计算访存流水上的调度更灵活，劣势是代码写起来更麻烦。直到Ampere它的优势都不足以让人忍受它的劣势，而Hopper上Warp-Specialization变成了一种必须要使用的技术。

https://www.zhihu.com/question/11261005710

为什么Hopper架构上warp-specialization比multi-stage要好？

---

参考：

https://mp.weixin.qq.com/s/pPjPLqgXZ8iCPS42vXJpuQ

NVIDIA Tensor Core深度学习核心解析

https://mp.weixin.qq.com/s/Qfbc2iQnXacOqOGIrpRQRw

Tensor Core究竟有多快？全面对比英伟达Tesla V100/P100的RNN加速能力

https://www.zhihu.com/question/451127498

英伟达GPU的tensor core和cuda core是什么区别？

https://developer.nvidia.com/blog/cutlass-linear-algebra-cuda/

CUTLASS: Fast Linear Algebra in CUDA C++

https://zhuanlan.zhihu.com/p/663092747

cute之MMA抽象

https://zhuanlan.zhihu.com/p/712451053

cutlass GEMM流水线——single-stage、pipelined、multi-stage

https://research.colfax-intl.com/cutlass-tutorial-wgmma-hopper/

CUTLASS Tutorial: Fast Matrix-Multiplication with WGMMA on NVIDIA® Hopper™ GPUs

## PTX

PTX (Parallel Thread Execution) 是NVIDIA GPU的伪指令集，之所以加个伪字，主要是因为这个指令集并不是真的硬件指令集，而仅仅是个抽象指令集。

该抽象指令集可以屏蔽不同架构显卡之间的指令差异。

![](/images/img6/just-in-time-compilation.png)

nvvm ir->PTX->SASS->runtime/jit->片上调度。

官网：

https://docs.nvidia.com/cuda/parallel-thread-execution/index.html

---

![](/images/img6/cuda-compilation-from-cu-to-executable.png)

gcc和llvm都有特定的pass可以生成PTX代码。

CICC（CUDA Integrated Compiler Command）是CUDA Toolkit中的一个编译器组件，它负责将CUDA代码编译成PTX代码。

cudafe++是CUDA编译过程中的一个组件，它的主要作用是将CUDA特有的C++扩展转换成标准C++结构。

ptxas：和gcc中的as类似，也是一个汇编器。ptxas的作用是将PTX代码编译成SASS（Streaming Assembler）代码。

官方文档：

https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html

---

NVIDIA GPU真正的指令集，被称作SASS。

和`.ptx`文件相对应，SASS的二进制格式为`.cubin`文件。但是由于后者是真正的硬件指令，在各架构之间不通用，所以还有一个`.fatbin`文件，可以打包不同架构的bin。

https://zhuanlan.zhihu.com/p/161624982

SASS指令集概述

https://www.zhihu.com/question/639210103

为什么没人去做CUDA逆向和反编译？

## Thrust

Thrust是一个C++库，它提供了对GPU加速并行算法的便捷访问。

它对标的是STL和TBB（Threading Building Blocks），后者是Intel开源的并行计算的C++模板库。

## 访存

从Ampere架构开始，引入了异步访存指令。

同步版本的流水线访存就是ld.global到regsiters，然后st.shared写入到共享内存，它们都会阻塞计算指令，但是warp scheduler会通过warp切换，让其他已经eligible的warp继续执行（本质上还是ILP），因此，一般同步版本最多开双流水（double-buffer），因为需要额外的寄存器进行prefetch，占用率不会太高，计算没法更好地掩盖访存的延迟。

异步版本是硬件层面的异步指令（cp/store.async），本身计算和访存单元就是可以独立运行的，有了异步层级的指令支持后，可以充分发挥这一特点，指令不会阻塞计算指令，但是需要fence/barrier等同步手段，因此，warp可以继续执行下去（如果条件允许），此外，这些指令需要消耗额外的寄存器进行预取，直接global->shared或者shared->global，一般可以开2-4条流水。

https://zhuanlan.zhihu.com/p/709750258

Tensor Memory Access（TMA）

---

Device to Device (DtoD)：指的是在单个GPU内部进行的内存拷贝。

Peer to Peer (PtoP)：指的是从一个GPU到另一个GPU的内存拷贝，这种情况仅发生在多GPU系统中。

RR (Read-Read)：表示连续的读操作。

RW (Read-Write)：表示读写混合操作。

---

Generic Addr是一种不携带任何状态或附加信息来声明它属于哪个状态空间的指针。在CUDA C++中，与C++一样，指针就是指针，它们没有额外的装饰或元信息。在PTX或SASS中，CUDA GPU具有状态空间系统，这是一种分区寻址结构。例如，shared就是一个状态空间。

## Warp

一个SP可以执行一个thread，但是实际上并不是所有的thread能够在同一时刻执行。Nvidia把32个threads组成一个warp，warp是调度和运行的基本单元。warp中所有threads并行的执行相同的指令。

https://zhuanlan.zhihu.com/p/266633373

详解CUDA的Context、Stream、Warp、SM、SP、Kernel、Block、Grid

https://www.zhihu.com/question/35361192

CUDA为什么要分线程块和线程网格？

---

Warp函数通过直接操作线程的寄存器来实现数据交换，而不是通过内存访问。因此，数据交换非常快速，延迟极低。

https://zhuanlan.zhihu.com/p/669917716

束内表决函数（Warp Vote Function）

https://zhuanlan.zhihu.com/p/669957986

束内洗牌函数（Warp Shuffle Functions）

https://zhuanlan.zhihu.com/p/670290502

束内匹配函数（Warp Match Functions）

https://zhuanlan.zhihu.com/p/670534280

束内规约函数（Warp Reduce Functions）

https://zhuanlan.zhihu.com/p/652255520

束内规约与块内规约问题

https://zhuanlan.zhihu.com/p/646998011

CUDA编程中的并行规约问题

## Memory Coalescing

![](/images/img6/Memory_Coalescing.jpg)

Memory Coalescing合并发生在不同线程之间，而不是线程内部的不同迭代之间。

warp中的所有线程都执行相同的指令，它们在任何时候都在同时执行第k次迭代。因此，一个线程在其生命周期内是否读取整行数据并不重要。重要的是，wrap内的所有线程在每次内存访问时可以合并。

在上图中，矩阵M内存访问模式是低效的，而矩阵N的访问模型是高效的。

参考：

https://zhuanlan.zhihu.com/p/300785893

CUDA编程之Memory Coalescing

## Debug

`nvcc -g -G -o test metrixMul.cu`

- `-g`: debug host code.
- `-G`: debug device code.

给VSCode安装Nsight扩展。

launch.json:

```json
{
    "name": "CUDA C++: Launch",
    "type": "cuda-gdb",
    "request": "launch",
    "program": "${fileDirname}/test",
}
```

https://zhuanlan.zhihu.com/p/508810115

Visual Studio Code的CUDA环境

## Profile

NVIDIA System Management Interface (NSMI): 即nvidia-smi。

NVIDIA Nsight Systems (NSYS)

NVIDIA Data Center GPU Manager (DCGM)

NVIDIA Management Library (NVML): NVML为GPU硬件数据提供了编程接口，开发者可以通过编程的方式访问GPU的各项数据，其中就包含GPU利用率，nvidia-smi和DCGM的背后就是NVML，推荐高级开发者使用。

cuda的调试主要使用ncu和nsys两个工具。

NCU侧重于内核级别的性能分析，例如显示不同block size内核函数的执行时间、执行的吞吐量、带宽分析等。

而Nsight System提供了更全面的系统级性能分析。包括CPU和GPU之间的交互、内存操作、内核执行时间等。它可以帮助开发者发现性能瓶颈，例如GPU饥饿、不必要的GPU同步、CPU并行度不足等问题。还提供了对多节点性能的分析，这对于数据中心和集群环境中的性能优化尤为重要。

nsys的UI版本的可执行文件名字叫做`nsys-ui`，同理还有`ncu-ui`。

官方文档：

https://docs.nvidia.com/nsight-systems

https://docs.nvidia.com/nsight-compute

---

显存被占用，但是nvidia-smi里看不到进程：

`sudo fuser -v /dev/nvidia*`

kill所有使用显卡的进程即可。
