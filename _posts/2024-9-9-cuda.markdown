---
layout: post
title:  CUDA
category: AI 
---

* toc
{:toc}

# CUDA

CUDA是NVIDIA最早推出的通用数学运算库。除了基本的数学运算之外，还提供了一些工具包：

cuBLAS：线性计算库。

NVBLAS：多GPU版的cuBLAS。

cuFFT：FFT计算库。

nvGRAPH：图计算库。（这里的图是数学图论中的图，和DL框架中的计算图是两回事。）

cuRAND：随机数生成库。

cuSPARSE；稀疏矩阵计算库。

cuSOLVER：解线性方程的计算库。包括解稠密方程的cuSolverDN、解稀疏方程的cuSolverSP和矩阵分解的cuSolverRF。

CUTLASS：另一个线性计算库。功能比cuBLAS更多。

## Deep Learning SDK

cuDNN：DL计算库。

TensorRT：嵌入式设备上专用于DL inference的计算库。

NVIDIA DIGITS：一款web应用工具，可在网页上对Caffe进行图形化操作和可视化。

TensorRT还有个云端的集群版本：

https://github.com/NVIDIA/tensorrt-inference-server

参考：

https://mp.weixin.qq.com/s/v8-JHd5tWm41WLqR-h6eKA

使用TensorRT集成加速TensorFlow推理

https://mp.weixin.qq.com/s/rMvhsi2vXxVC65C5Z4IXIw

AI视频处理加速引擎TensorRT及Deepstream介绍

https://zhuanlan.zhihu.com/p/35657027

高性能深度学习支持引擎实战——TensorRT

## NVIDIA DALI

NVIDIA DALI是一个GPU加速的数据增强和图像加载库，为优化深度学习框架数据pipeline而设计，而其中的NVIDIA nvJPEG是用于JPEG解码的高性能GPU加速库。

代码：

https://github.com/NVIDIA/dali

## Tensor Core

Tensor Core是Nvidia GPU自Volta架构开始，专门为深度学习矩阵运算设计的计算单元。

WMMA（warp matrix multiply-accumulate）

类似的东西还有Arm的SME、Intel的AMX等。

https://mp.weixin.qq.com/s/pPjPLqgXZ8iCPS42vXJpuQ

NVIDIA Tensor Core深度学习核心解析

https://mp.weixin.qq.com/s/Qfbc2iQnXacOqOGIrpRQRw

Tensor Core究竟有多快？全面对比英伟达Tesla V100/P100的RNN加速能力

https://www.zhihu.com/question/451127498

英伟达GPU的tensor core和cuda core是什么区别？

## PTX

PTX (Parallel Thread Execution) 是NVIDIA GPU的伪指令集，之所以加个伪字，主要是因为这个指令集并不是真的硬件指令集，而仅仅是个抽象指令集。

该抽象指令集可以屏蔽不同架构显卡之间的指令差异。

nvvm ir->PTX->SASS->runtime/jit->片上调度。

官网：

https://docs.nvidia.com/cuda/parallel-thread-execution/index.html

gcc和llvm都有特定的pass可以生成PTX代码。

---

NVIDIA GPU真正的指令集，被称作SASS。

https://zhuanlan.zhihu.com/p/161624982

SASS指令集概述

https://www.zhihu.com/question/639210103

为什么没人去做CUDA逆向和反编译？

## CUDA-X AI

CUDA-X AI是软件加速库的集合，这些库建立在CUDA之上，提供对于深度学习、机器学习和高性能计算必不可少的优化功能。这些库包括cuDNN（用于加速深度学习基元）、cuML（用于加速数据科学工作流程和机器学习算法）、TensorRT（用于优化受训模型的推理性能）、cuDF（用于访问 pandas 之类的数据科学 API）、cuGraph（用于在图形上执行高性能分析），以及超过13个的其他库。

官网：

https://www.nvidia.cn/technologies/cuda-x/

## CUDA实战

安装：

http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html

---

`${CUDA_HOME}/targets/x86_64-linux/lib/stubs/`文件夹下有常见的libcuda.so、libcublas.so等动态链接库，但是里面只有函数名，没有函数实现。所以文件大小很小。当我们的代码在一台没有GPU的机器上编译时，可以动态链接到这些stubs库，这样就能够正常编译。编译结束得到的二进制文件可以部署到其它有GPU的机器，在运行时它们就会链接到正确的动态链接库。

---

参考：

http://ishare.iask.sina.com.cn/f/17211495.html

深入浅出谈CUDA技术

http://blog.csdn.net/xsc_c/article/category/2186063

某人的并行计算专栏

https://mp.weixin.qq.com/s/9D7uda3CV7volenhl-jchg

推荐几个不错的CUDA入门教程

https://mp.weixin.qq.com/s/bvNnzkOzGYYYewc3G9DOIw

GPU是如何优化运行机器学习算法的？

https://mp.weixin.qq.com/s/nAwxtOUi6HpIjVOREgEfaA

CUDA编程入门极简教程

https://mp.weixin.qq.com/s/-zdIWkuRZXhsLJmOZljOBw

《基于GPU-多核-集群等并行化编程》

https://mp.weixin.qq.com/s/bCb5VsH58JII886lpg9lvg

如何在CUDA中为Transformer编写一个PyTorch自定义层

https://mp.weixin.qq.com/s/OYSzol-vufiKPuU9YxtbuA

矩阵相乘在GPU上的终极优化：深度解析Maxas汇编器工作原理

https://zhuanlan.zhihu.com/p/358220419

PyTorch自定义CUDA算子教程与运行时间分析

https://zhuanlan.zhihu.com/p/358778742

详解PyTorch编译并调用自定义CUDA算子的三种方式

https://zhuanlan.zhihu.com/p/360441891

熬了几个通宵，我写了份CUDA新手入门代码

https://mp.weixin.qq.com/s/EZxO8IIBDJ4c7eQhUffc2w

怎样节省2/3的GPU？爱奇艺vGPU的探索与实践

https://mp.weixin.qq.com/s/3VjGpyXZSkJhy6sFPUsZzw

GPU虚拟化，算力隔离，和qGPU

https://zhuanlan.zhihu.com/p/383115932

大佬是怎么优雅实现矩阵乘法的？

https://zhuanlan.zhihu.com/p/410278370

CUDA矩阵乘法终极优化指南

https://www.zhihu.com/column/c_1437330196193640448

深入浅出GPU优化

https://www.zhihu.com/question/41060378

自己写的CUDA矩阵乘法能优化到多快？

https://zhuanlan.zhihu.com/p/559957579

简单谈谈CUDA的访存合并

https://zhuanlan.zhihu.com/p/565897763

GPGPU编程模型之CUDA

http://blog.csdn.net/augusdi/article/details/12833235

这是一篇转帖的CUDA教程，原帖比较分散，不好看。

https://zhuanlan.zhihu.com/p/544864997

cuda中threadIdx、blockIdx、blockDim和gridDim的使用

https://zhuanlan.zhihu.com/p/690717002

一文读懂cuda代码编译流程

https://zhuanlan.zhihu.com/p/690880124

并不太短的CUDA入门（The Not So Short Introduction to CUDA）

https://zhuanlan.zhihu.com/p/693690123

一文读懂nvidia-smi背后的nvml库

https://www.zhihu.com/question/445590537

问个CUDA并行上的小白问题，既然SM只能同时处理一个WARP，那是不是有的SP处于闲置？
