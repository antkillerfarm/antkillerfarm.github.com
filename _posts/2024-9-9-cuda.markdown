---
layout: post
title:  CUDA
category: AI 
---

* toc
{:toc}

# CUDA

CUDA是NVIDIA最早推出的通用数学运算库。除了基本的数学运算之外，还提供了一些工具包：

cuBLAS：线性计算库。除了基本版的API之外，它还包括以下扩展：

- cuBLASXt适合处理非常大的矩阵和多GPU操作。
- cuBLASLt提供了一定程度的灵活性，适合中等大小的矩阵。
- cuBLASDx则提供了更高的灵活性和控制，适合在设备端执行小规模的矩阵操作和融合操作。

NVBLAS：多GPU版的cuBLAS。

cuFFT：FFT计算库。

nvGRAPH：图计算库。（这里的图是数学图论中的图，和DL框架中的计算图是两回事。）

cuRAND：随机数生成库。

官方文档：

https://docs.nvidia.com/cuda/pdf/CURAND_Library.pdf

cuSPARSE；稀疏矩阵计算库。

cuSOLVER：解线性方程的计算库。包括解稠密方程的cuSolverDN、解稀疏方程的cuSolverSP和矩阵分解的cuSolverRF。

---

官方文档：

https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html

---

https://github.com/nvidia/cccl

CUDA Core Compute Libraries (CCCL)

https://cuda.godbolt.org/

nvcc online compiler

## NVIDIA DALI

NVIDIA DALI是一个GPU加速的数据增强和图像加载库，为优化深度学习框架数据pipeline而设计，而其中的NVIDIA nvJPEG是用于JPEG解码的高性能GPU加速库。

代码：

https://github.com/NVIDIA/dali

## Tensor Core

Tensor Core是Nvidia GPU自Volta架构开始，专门为深度学习矩阵运算设计的计算单元。

CUTLASS：另一个线性计算库，专为Tensor Core设计。

![](/images/img6/CUTLASS.png)

类似的东西还有Arm的SME、Intel的AMX等。

---

![](/images/img6/CUTLASS_2.png)

CUTLASS主要基于以下指令：

- MMA（Matrix Multiply-Accumulate）
- WMMA（Warp Matrix Multiply-Accumulate）：WMMA是针对Tensor Core设计的，它在warp级别（即32个线程）上执行矩阵乘法运算。
- WGMMA（Warp Group Matrix Multiply-Accumulate）：WGMMA是WMMA的扩展，提供了更广泛的矩阵尺寸和数据类型的支持。对并行计算的控制也更为精细。
- TMA（Tensor Memory Accelerator）：用于在global memory和shared memory之间搬运数据。
- BMMA（Binary Matrix Multiply-Accumulate）：提供按位操作的矩阵乘法。

---

CuTe，全称为"collection of C++ CUDA template abstractions for defining and operating on hierarchically multidimensional layouts of threads and data"，是一个处理嵌套layout的模板抽象的集合，其并不提供**现成算子**支持，而是给出数据结构，使得复杂的线性代数计算得以加速。

https://dingfen.github.io/2024/08/18/2024-8-18-cute/

深入CUTLASS之CuTe详解

---

参考：

https://mp.weixin.qq.com/s/pPjPLqgXZ8iCPS42vXJpuQ

NVIDIA Tensor Core深度学习核心解析

https://mp.weixin.qq.com/s/Qfbc2iQnXacOqOGIrpRQRw

Tensor Core究竟有多快？全面对比英伟达Tesla V100/P100的RNN加速能力

https://www.zhihu.com/question/451127498

英伟达GPU的tensor core和cuda core是什么区别？

https://developer.nvidia.com/blog/cutlass-linear-algebra-cuda/

CUTLASS: Fast Linear Algebra in CUDA C++

https://zhuanlan.zhihu.com/p/663092747

cute之MMA抽象

https://zhuanlan.zhihu.com/p/712451053

cutlass GEMM流水线——single-stage、pipelined、multi-stage

https://research.colfax-intl.com/cutlass-tutorial-wgmma-hopper/

CUTLASS Tutorial: Fast Matrix-Multiplication with WGMMA on NVIDIA® Hopper™ GPUs

## PTX

PTX (Parallel Thread Execution) 是NVIDIA GPU的伪指令集，之所以加个伪字，主要是因为这个指令集并不是真的硬件指令集，而仅仅是个抽象指令集。

该抽象指令集可以屏蔽不同架构显卡之间的指令差异。

nvvm ir->PTX->SASS->runtime/jit->片上调度。

官网：

https://docs.nvidia.com/cuda/parallel-thread-execution/index.html

gcc和llvm都有特定的pass可以生成PTX代码。

CICC（CUDA Integrated Compiler Command）是CUDA Toolkit中的一个编译器组件，它负责将CUDA代码编译成PTX代码。

cudafe++是CUDA编译过程中的一个组件，它的主要作用是将CUDA特有的C++扩展转换成标准C++结构。

ptxas：和gcc中的as类似，也是一个汇编器。ptxas的作用是将PTX代码编译成SASS（Streaming Assembler）代码。

---

NVIDIA GPU真正的指令集，被称作SASS。

https://zhuanlan.zhihu.com/p/161624982

SASS指令集概述

https://www.zhihu.com/question/639210103

为什么没人去做CUDA逆向和反编译？

## Thrust

Thrust是一个C++库，它提供了对GPU加速并行算法的便捷访问。

它对标的是STL和TBB（Threading Building Blocks），后者是Intel开源的并行计算的C++模板库。

## 访存

从Ampere架构开始，引入了异步访存指令。

同步版本的流水线访存就是ld.global到regsiters，然后 st.shared写入到共享内存，它们都会阻塞计算指令，但是warp scheduler会通过warp切换，让其他已经eligible的warp继续执行（本质上还是ILP），因此，一般同步版本最多开双流水（double-buffer），因为需要额外的寄存器进行prefetch，占用率不会太高，计算没法更好地掩盖访存的延迟。

异步版本是硬件层面的异步指令（cp/store.async），本身计算和访存单元就是可以独立运行的，有了异步层级的指令支持后，可以充分发挥这一特点，指令不会阻塞计算指令，但是需要fence/barrier等同步手段，因此，warp可以继续执行下去（如果条件允许），此外，这些指令需要消耗额外的寄存器进行预取，直接 global -> shared 或者 shared -> global，一般可以开2-4条流水。

https://zhuanlan.zhihu.com/p/709750258

Tensor Memory Access（TMA）

---

Device to Device (DtoD)：指的是在单个GPU内部进行的内存拷贝。

Peer to Peer (PtoP)：指的是从一个GPU到另一个GPU的内存拷贝，这种情况仅发生在多GPU系统中。

## Warp

https://zhuanlan.zhihu.com/p/669917716

束内表决函数（Warp Vote Function）

https://zhuanlan.zhihu.com/p/669957986

束内洗牌函数（Warp Shuffle Functions）

https://zhuanlan.zhihu.com/p/670290502

束内匹配函数（Warp Match Functions）

https://zhuanlan.zhihu.com/p/670534280

束内规约函数（Warp Reduce Functions）

## CUDA实战

安装：

http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html

---

`${CUDA_HOME}/targets/x86_64-linux/lib/stubs/`文件夹下有常见的libcuda.so、libcublas.so等动态链接库，但是里面只有函数名，没有函数实现。所以文件大小很小。当我们的代码在一台没有GPU的机器上编译时，可以动态链接到这些stubs库，这样就能够正常编译。编译结束得到的二进制文件可以部署到其它有GPU的机器，在运行时它们就会链接到正确的动态链接库。

---

"stall"（停滞）是指warp在执行过程中因为各种原因暂时无法继续执行下一步操作，需要等待某个条件满足后才能继续执行的现象。

CTA：Cooperative Thread Array，即协作线程数组。它是由一组线程组成的集合，这些线程可以执行相同的程序，并且能够相互通信。CTA是CUDA中线程组织的基本单元，通常被称为线程块（Thread Block）。

CTA提供了同步点，允许开发者在需要时对CTA内的所有线程进行同步，例如使用__syncthreads()函数。

和Thread Block密切相关的概念还有Data Block，用于规划数据的访存。

---

`vectorAdd<<<4096, 256, 0, s0>>>`表示内核函数vectorAdd将在GPU上以4096个块执行，每个块包含256个线程，总共有4096x256个线程。

0表示为这个内核函数分配的动态共享内存的大小，单位是字节。s0指定关联的stream。

---

遇到cudaXX找不到：

```bash
export CPATH=/usr/local/cuda/targets/x86_64-linux/include:$CPATH
export LD_LIBRARY_PATH=/usr/local/cuda/targets/x86_64-linux/lib:$LD_LIBRARY_PATH
export PATH=/usr/local/cuda/bin:$PATH
```

---

nvcc编译cuda程序，不运行device（GPU）部分代码的解决方案：指定GPU的arch。

`nvcc ./xxx.cu -o xxx -arch sm_90 -Wno-deprecated-gpu-targets`

---

执行环境标识符：

- `__global__`：在CPU调用父函数，子函数在GPU执行(异步)。用`__global__`修饰的一般就是内核(kernel)函数。
- `__device__`：在GPU调用父函数，子函数在GPU执行。 由`__device__`修饰的函数可以被由`__global__`和`__device__`修饰的函数调用。
- `__host__`：在CPU调用父函数，子函数在CPU执行。 

---

https://developer.download.nvidia.cn/assets/cuda/files/NVIDIA-CUDA-Floating-Point.pdf

IEEE 754 mode(default): `-ftz=false -prec-div=true -prec-sqrt=true`
fast mode: `-ftz=true -prec-div=false -prec-sqrt=false`

在fast模式中，非规格化数将被转换为零，并且除法和平方根运算不会被计算到最接近的真实值的浮点数值。

当浮点异常发生时，NVIDIA的GPU不会触发trap handlers，也没有指示上溢、下溢或者denormal的标志位。

---

`#pragma unroll`指令建议编译器完全展开for循环。如果N是一个常量，编译器会尝试将循环体展开N次。如果N不是一个常量或者太大而无法完全展开，编译器可能会忽略这个指令，或者展开一定次数的迭代。

---

因为GPU不支持常规的Kernel递归，CPU上的很多递归算法只能换思路后进行改写，不能直接按原思路实现。而随着动态并行（Dynamic Parallelism）的引入，GPU现在能直接在Kernel中启动Kernel了。

https://zhuanlan.zhihu.com/p/674856090

CUDA动态并行详解（CDP2）

---

pytorch CUDA RadixSort call stack：

```cpp
MediumRadixSort
should_use_small_sort
sortKeyValueInplace
launch_stable_sort_kernel
segmented_sort_large_segments
radix_sort_pairs_impl
NO_ROCM(at_cuda_detail)::cub::DeviceRadixSort::SortPairs
cub::DeviceRadixSort::SortPairs
DeviceRadixSort::custom_radix_sort
DispatchRadixSort::Dispatch
DeviceRadixSortSingleTileKernel
triple_chevron
BlockRadixSort
BlockRadixSortT(temp_storage.sort).SortBlockedToStriped
RankKeys
DescendingBlockRadixRank
BlockRadixRank
```
