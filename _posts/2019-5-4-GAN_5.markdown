---
layout: post
title:  GAN（五）——InfoGAN, ProGAN, GAN参考资源（1）
category: Generative Model
---

* toc
{:toc}

# StarGAN（续）

StarGAN给出的办法是：所有的Domain共享一个G网络。如上图右半部分所示。

具体的操作如下图所示：

![](/images/img3/StarGAN_2.png)

1.D网络除了常规的Real/Fake判别器之外，还有一个Domain分类器。

2.G网络的结构和CycleGAN类似，也包括了两部分：$$G_{X\to Y}$$和$$G_{Y\to X}$$。区别在于：后者的两个G网络是不同的网络，而前者是同一个网络。

3.既然G网络只有一个，那么如何完成Domain变换呢？答案就是：把目标Domain的信息也输进G网络中。

![](/images/img3/StarGAN_3.png)

StarGAN不仅可在同一数据集中进行Domain变换，还可在不同数据集之间进行Domain变换。上图展示的是StarGAN在CelebA和RaFD数据集上的训练过程：

1.两个数据集的标签不是完全相同的。（实际上是完全不同，囧）

2.对标签进行编码。例如图中使用的Onehot编码。

3.**利用Mask区分是哪个数据集。**这一步是关键。

![](/images/img3/GAN_5.png)

除此之外，同期的Couple GAN也采用了类似的设计。上图是Couple GAN的网络结构图，其中的虚线表示网络的参数是共享的。

参考：

https://mp.weixin.qq.com/s/rPDvLnG4MBDRUMCWs2fjcQ

最新StarGAN对抗生成网络实现多领域图像变换

https://mp.weixin.qq.com/s/CsIKES2APuxTP33RfX81fg

升级版StarGAN来袭！你想要的多目标域多风格图像变换它都有

# InfoGAN

论文：

《InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets》

CGAN虽然已经有了些user control的能力，然而还不够强。比如人脸图片，user control的点（例如肤色、发型、表情等）就非常多，简单的标签不足以表达这么多含义。InfoGAN主要就是用来提升user control能力的。

![](/images/img3/InfoGAN.png)

上图是InfoGAN的网络结构图。相比CGAN，它的改进在于：

1.将控制变量嵌入网络中。

2.Discriminator和Classifier共享大多数参数，仅最后一层不同。

参考：

https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492415&idx=1&sn=a359e72ee99555f7a2fb4e21b2ad51db

InfoGAN：一种无监督生成方法

https://zhuanlan.zhihu.com/p/140544756

InfoGAN与betaVAE

# ProGAN

论文：

《Progressive Growing of GANs for Improved Quality, Stability, and Variation》

![](/images/img3/ProGAN.png)

如果现在我们想生成超高分辨率的图像，譬如1024×1024图片，假设我们采用StackGAN或者是LapGAN的话，我们需要用到的 GANs结构会非常多，这样会导致网络深度巨大，训练起来非常慢。

为了解决这一问题，ProGAN（也称PGGAN）提出的想法是，我们只需要一个GANs就能产生1024×1024图片。但是一开始的时候GANs的网络非常浅，只能学习低分辨率（4x4）的图片生成，随着训练进行，我们会把GANs的网络层数逐渐加深，进而去学习更高分辨率的图片生成，最终不断的更新GANs，从而能学习到1024×1024分辨率的图片生成。

也就是说，PGGAN与StackGAN和LapGAN的最大不同在于，后两者的网络结构是固定的，但是PGGAN随着训练进行网络会不断加深，网络结构是在不断改变的。这样做最大的好处就是，PGGAN大部分的迭代都在较低分辨率下完成，训练速度比传统GANs提升了2-6倍。

当然，这也带来了另一个问题：网络结构切换的时候，Loss会发生抖动现象，论文中专门提出了如何smooth的方法，这里不再赘述。

参考：

https://mp.weixin.qq.com/s/X8osUSPROJqGVTvw0gieDQ

T2T：利用StackGAN和ProGAN从文本生成人脸

# StyleGAN

StyleGAN是Nvidia Lab的Tero Karras的作品。（2018.12）

论文：

《A Style-Based Generator Architecture for Generative Adversarial Networks》

参考：

https://mp.weixin.qq.com/s/Pmr2yPZ3Mi32W5JuJCco_A

用英伟达StyleGAN生成老婆吧，他生成了一百多只明日香

https://mp.weixin.qq.com/s/i3lNcbOblgVKUTBtwKIFwg

AI秒造全球房源：StyleGAN快速生成假房子，连图说都配好了！

https://mp.weixin.qq.com/s/e1g1B-6bLe0IjNAHMJtGOw

英伟达发布最强图像生成器StyleGAN2，生成图像逼真到吓人

https://zhuanlan.zhihu.com/p/136392096

看GAN如何一步步控制图像生成风格？详解StyleGAN进化过程

https://mp.weixin.qq.com/s/cQAl7k7D6P-wG75VM_KyGw

StyleGAN2玩出新高度！从华盛顿到特朗普，无缝切换生成历届美国总统

https://mp.weixin.qq.com/s/P1cfC7smeTSBy_6LYn_HOA

看GAN如何一步步控制图像生成风格？详解StyleGAN进化过程

https://mp.weixin.qq.com/s/2G9JAWmXig0o8WR1J7dfkg

终于有人把各路StyleGAN做了个大汇总

# BigGAN

论文：

《Large Scale GAN Training for High Fidelity Natural Image Synthesis》

参考：

https://mp.weixin.qq.com/s/b3EVdPGY2jxliwdbbB1kcQ

“史上最强GAN图像生成器”BigGAN的demo出了！

https://mp.weixin.qq.com/s/kSyXd5dgdEcqupDeouhObQ

BigGAN论文解读

https://mp.weixin.qq.com/s/akLvNQZMNTaVbkbUrZY4tw

史上最强图像生成器BigGAN变身DeepGAN？四倍深度实现更强效果

https://mp.weixin.qq.com/s/jglebP4Zb9rZtb2EhWiQDA

BigGAN被干了！DeepMind发布LOGAN：FID提升32%，华人一作领衔

# SAGAN

论文：

《Self-Attention Generative Adversarial Networks》

# S3GAN

论文：

《High-Fidelity Image Generation With Fewer Labels》

# DAGAN

论文：

《Data Augmentation Generative Adversarial Networks》

这是一篇用GAN来进行数据增强的论文。

![](/images/img3/DAGAN.png)

# FUNIT

https://mp.weixin.qq.com/s/KupmZpMi1A46f5_NKbTU2A

深入理解风格迁移三部曲(一)--UNIT

https://mp.weixin.qq.com/s/3hv44bkXYHn2wN_2OZmhxA

四大指标超现有模型！少样本的无监督图像翻译效果逆天（FUNIT）

https://mp.weixin.qq.com/s/H0kl1i4P3Dak2COdzQNG4A

一图生万物！英伟达推超强图像转换神器，小样本一秒猫变狗（FUNIT）

https://mp.weixin.qq.com/s/isrB3yda9sGgbOb4dBXMrQ

更自由的GAN图像联想：无监督跨类的图像转换模型FUNIT，英伟达&康奈尔大学

https://mp.weixin.qq.com/s/nAaKnI1ADKfeQ8UA_VP0Fw

FUNIT

# GauGAN

https://mp.weixin.qq.com/s/sTLDG0rmFZv20G5veNYS9g

英伟达再出黑魔法GauGAN：凭借几根线条，草图秒变风景照

https://mp.weixin.qq.com/s/nKME65tCeNOlY4SiPv-fWA

逼真照片随手画，马良神笔已上线--点击收获这份英伟达GauGAN开源代码

https://mp.weixin.qq.com/s/0gEmZRocv_49ngVvaa4LNg

装逼一步到位！GauGAN代码解读来了

# GAN参考资源

https://mp.weixin.qq.com/s/mUOSA387465ws0l9Fp-ebQ

生成对抗网络GAN在各领域应用研究进展(中文版)，37页pdf

https://mp.weixin.qq.com/s/Gjb-PkMqUIIV81Na6Za_BQ

超全的GAN PyTorch+Keras实现集合

https://github.com/FranxYao/Deep-Generative-Models-for-Natural-Language-Processing

Deep Generative Models for Natural Language Processing

https://mp.weixin.qq.com/s/Cb3C6Q5aWSjsNFs5hqD6kw

阿里提出应用LocalizedGAN进行半监督训练

https://mp.weixin.qq.com/s/Y8D0gr1ybQ48H0bDpPvD8w

二次元萌妹高清舞姿随心变，换装只需一瞬间：又是GAN立功了

https://mp.weixin.qq.com/s/H_EcHi9BRur214rktocGbg

怎样用GAN生成各种胖吉猫？谷歌大脑程序员教你撩妹神技

https://mp.weixin.qq.com/s/FDyN6fblDFGOSNRFs5OYqA

什么都能GAN，无监督神经网络翻译新方法

https://mp.weixin.qq.com/s/DYSnAwP9xt-p0ihsEtKm1Q

TensorFlow实现StarGAN代码全部开源，1天训练完

https://mp.weixin.qq.com/s/se_2Ci4eE5fxiiG4LZrv8w

怎样用可交互对抗网络增强人类创造力

https://mp.weixin.qq.com/s/29Ror1CKFubB0n38cihMqQ

六种GAN评估指标的综合评估实验，迈向定量评估GAN的重要一步

https://mp.weixin.qq.com/s/0I8jLO3srXC3fUdoMC585w

一些fancy的GAN应用

https://mp.weixin.qq.com/s/kD_163rjGRp4rXOdIPCvRA

亲历IJCAI 2018，为什么北京大学SentiGAN能获杰出论文？

https://mp.weixin.qq.com/s/v23rSjIKyVEAGCN8rEtsfg

伯克利新论文：合成GAN（Compositional GAN）

https://mp.weixin.qq.com/s/ddR7dwwBZnu3knKmfDWjCg

斯坦福大学PH.D Aditya Grover：115页Slides带你领略深度生成模型（Deep Generative Model）全貌

https://mp.weixin.qq.com/s/QjEShm__Rq0n7n_sdc6GNg

Ryan P.Adams教授：深度概率生成模型—156页普林斯顿教程带你回顾深度生成模型最新发展脉络

https://mp.weixin.qq.com/s/DSHuCNQWKN3pLozZ8i16hQ

卡成PPT不开心？GAN也能生成流畅的连续表情了

https://mp.weixin.qq.com/s/5S6TsyT6dwXP3cTE_KQleg

把酱油瓶放进菜篮子：UC Berkeley提出高度逼真的物体组合网络Compositional GAN

https://mp.weixin.qq.com/s/IE5h6AiAYhA1nBvsFiGUHA

GAN最新进展：8大技巧提高稳定性

https://mp.weixin.qq.com/s/QacQCrjh3KmrQSMp-G_rEg

贝叶斯生成对抗网络

https://mp.weixin.qq.com/s/c84LMFnIhoDeolc1B4MIVA

AI以假乱真怎么办？TequilaGAN教你轻松辨真伪

https://mp.weixin.qq.com/s/fgL6FtjeF-EgG5jjAGDR7A

GANimation让图片秒变GIF表情包，秒杀StarGAN

https://mp.weixin.qq.com/s/yShYrMFKox30jXajXXQPGw

如何让GAN生成更高质量图像？斯坦福大学给你答案

https://mp.weixin.qq.com/s/qiLFQowjH67XECXBlppUDg

对抗深度学习:鱼(模型准确性)与熊掌(模型鲁棒性)能否兼得？

https://mp.weixin.qq.com/s/1SpHGtjkSfDEFCZuudCm0Q

基于GAN和VAE的跨模态图像生成

https://mp.weixin.qq.com/s/02amaVnLFxeLDBsjG-iN1Q

UBC&腾讯AI Lab提出首个模块化GAN架构，搞定任意图像PS组合

https://mp.weixin.qq.com/s/pf0fNSoNDaI9bZvohRX28A

不再使用人眼评估，你训练的GAN还OK吗？ 

https://mp.weixin.qq.com/s/KeXXi5kwvWAfArv13f6VPg

给Cycle-GAN加上时间约束，CMU等提出新型视频转换方法Recycle-GAN

https://mp.weixin.qq.com/s/IzVTkH7fEiS4gAUIyA_IrA

谷歌GAN 实验室来了！迄今最强可视化工具，在浏览器运行GAN

https://mp.weixin.qq.com/s/1jBpz55pPgM8oxlUZLSWXA

ICML2018对抗生成网络论文评述

https://mp.weixin.qq.com/s/uQpmP7pJ8wnEgyJrvvHgwg

基于解剖结构的面部表情生成

https://mp.weixin.qq.com/s/cLCtxS1frJYvC5tLsQAWrQ

用神经网络生成音乐

https://mp.weixin.qq.com/s?__biz=MzIwOTc2MTUyMg==&mid=2247485368&idx=1&sn=1da8bd2490fa2fe16dbe25aea79dcd63

交互式GAN Lab让生成对抗网络轻松实现可视化！

https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247491630&idx=1&sn=394ffec2969cff23f63022526684f259

杜伦大学提出GANomaly：无需负例样本实现异常检测

https://mp.weixin.qq.com/s/BEuA5icaQwRJGsJJLnAFVg

用机器学习生成图片：GAN的局限性以及如何GAN的更爽
