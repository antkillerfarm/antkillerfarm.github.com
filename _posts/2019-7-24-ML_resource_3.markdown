---
layout: post
title:  ML参考资源（三）, Transformer Engine
category: resource 
---

* toc
{:toc}

# ML参考资源

https://mp.weixin.qq.com/s/vLvjo8Cso_bYEuW-AFoyiA

南大周志华等人提出无组织恶意攻击检测算法UMA

https://mp.weixin.qq.com/s/y6EwGHlKk1XjaasuuRzb5w

机器学习算法中的概率方法

https://mp.weixin.qq.com/s/jNQmh7NAiR-qJshBF38WkQ

DeepMind新研究：三招解决机器学习模型debug难题

https://mp.weixin.qq.com/s/rVXCjEilRC4sgluIg0q6TA

一文尽览近似最近邻搜索中的哈希与量化方法

https://mp.weixin.qq.com/s/HYZWANuSrt4DcO_monHRvA

一位数据科学PhD眼中的算法交易

https://zhuanlan.zhihu.com/p/40214106

流形学习概述

https://mp.weixin.qq.com/s/Uw02CapdvpaMKbjry1Q_Cg

爱犯错的智能体：谈谈黎曼流形与视觉距离错觉问题

https://mp.weixin.qq.com/s/oGSk9Hsu6lbthJjLHF59Hg

摩拜&京东联合利用智能单车数据挖掘违章停车

https://mp.weixin.qq.com/s/iyd0ade-ZcXCxLoZ8_vWPQ

应用于鲁棒主成分分析的双线性因子矩阵范数最小化

https://mp.weixin.qq.com/s/rDdpQDogQR1E6TMkG4j1sA

80页PPT解读量化开发与实盘

https://mp.weixin.qq.com/s/hPjf7t5j-kBrrEIhNGo8jQ

从区域到边界（边界元）

https://mp.weixin.qq.com/s/mZlJw3gKhc988n5JpN135g

如何解决春运中的铁路列车调度问题

https://mp.weixin.qq.com/s/yJom9cqh64YNqMbAzsgwOA

浅谈变分不等式与凸优化

https://mp.weixin.qq.com/s/WIx-yzbvgwSaKrRMIbgY2w

无边无际的虚拟城市来了！能走能飞的Demo，一火再火的“波函数坍缩”开源算法

https://mp.weixin.qq.com/s/NbEki2ByMmA93DyoQF1yjA

运满满如何将机器学习应用于车货匹配和公路干线价格预测？

https://mp.weixin.qq.com/s/R7Qud_x6DGqbHAOl7OMruQ

一文带你入门算法分发！

https://mp.weixin.qq.com/s/lpNTdnfp2FnJ97EivhUv2g

12种降维方法终极指南

https://mp.weixin.qq.com/s/Sez56UaCAt3Aspn7OTFj_Q

让AI来一场“简单”的黄金点游戏

https://mp.weixin.qq.com/s/C50IBm8EgrE13MOPMgPseQ

基于背景和潜在异常字典构造的高光谱图像异常目标检测

https://mp.weixin.qq.com/s/0bVwxkncZrqxvhHXvbTHIA

终于把微软BING搜索-SPTAG算法的原理搞清了

https://mp.weixin.qq.com/s/8KEWJROGSe-7nmBlrkQ7Nw

雇水军刷分有效吗？虚假评论的影响研究分析

https://mp.weixin.qq.com/s/csQoFtE0v1jUAGC08NtX3g

解读：滴滴“猜你去哪儿”功能的算法实现

https://mp.weixin.qq.com/s/-SevTK_5SCTRU6xrdX3nMw

高德网络定位之“移动WiFi识别”

https://mp.weixin.qq.com/s/jW3OMns-38qd8f0twd7eyA

J.P. Morgan首发川普指数：效果如何？量化看看！

https://mp.weixin.qq.com/s/sJ4qb2OF96YtjPVNd3jXzQ

浅谈滴滴派单算法

https://mp.weixin.qq.com/s/1T2u2NOZ8wS84HzRdQCbwg

标签噪声对分类性能会有什么样的影响？

https://mp.weixin.qq.com/s/iAmkb2EdYofJU1AoBw2HyA

多目标优化详解

https://mp.weixin.qq.com/s/9FBl5zSz9WEgjFeq41y1kQ

动态多目标优化问题

https://mp.weixin.qq.com/s/q1CC7pj8kj2E9zBw-IJnDw

相亲数据告诉你，什么样的人更找不到对象？

https://mp.weixin.qq.com/s/W-4lv_SfT25AqHHvOmG6BA

实锤！用python扒一扒那些疯狂收割着大家的智商税的“烂片”和“艺人”

https://mp.weixin.qq.com/s/byzL0Te5-QQLR7bxJpoZrw

超好用的自信学习：1行代码查找标签错误，3行代码学习噪声标签

https://mp.weixin.qq.com/s/p3w2GSjGMJOwlMJk3xmbvQ

AI插手！用文本分析鉴定《红楼梦》、《亨利八世》实际作者

https://mp.weixin.qq.com/s/ZY7WZzePqRfDPv6JX2vWsQ

30张地图看懂世界格局，用大数据说话

https://mp.weixin.qq.com/s/FT8Yn8VpgVroEbgSTG9lGA

如何判断样本标注的靠谱程度？置信度学习（CL）简述

https://mp.weixin.qq.com/s/ukFPwO9vZ5t3OLiKr5MQMw

缺失数据统计分析，第三版，462页pdf

https://mp.weixin.qq.com/s/WJUGbyPgLgVX6Q8SXjOP1A

如何抢别人怀里的女孩子?

https://zhuanlan.zhihu.com/p/114264831

Kernel Distribution Embedding（用于测试两批数据是否来自同一个分布采样）

https://mp.weixin.qq.com/s/zJfafmJfmmQIjmjsLh_j-g

百度内部PPT流出：数据分析的道与术

https://zhuanlan.zhihu.com/p/146557232

标注数据存在错误怎么办？MIT&Google提出用置信学习找出错误标注

https://mp.weixin.qq.com/s/tdF46p_fLpaVjPfK2WtRgw

如何用运筹学帮助特朗普赢得大选?

https://mp.weixin.qq.com/s/typfJcOcRwS20HOwG_zcRg

如何通过抽样分布估计你的模型的不确定性

https://mp.weixin.qq.com/s/_igLvU_UZmRb2azn7RzJTg

非线性回归中的Levenberg-Marquardt算法理论和代码实现

https://mp.weixin.qq.com/s/41OmNMK1VFKQRuW6D7kqgA

王茂霖：数据挖掘提分三板斧

https://mp.weixin.qq.com/s/v7m0I9o6QV6qKSQqnsMoRw

共享两轮车供需算法浅谈

https://mp.weixin.qq.com/s/Mc9vHkt--u3jyh5VZmA56Q

如何消除多重共线性

# AI工具+

https://mp.weixin.qq.com/s/Uih8JaRCaeD38o9AoovRmA

字节跳动开源高性能分布式训练框架BytePS：兼容TensorFlow、PyTorch等

https://mp.weixin.qq.com/s/o9cYmqwuvlbOuUXSNIuicg

十个最常用深度学习图像/视频数据标注工具

https://mp.weixin.qq.com/s/iKXZmhffiYaFHsIU21zVQA

NeuralNLP-NeuralClassifier：腾讯开源深度学习文本分类工具

https://mp.weixin.qq.com/s/suLJs_GjRsdYA5fwtsje7g

腾讯AI开源框架Angel 3.0重磅发布：超50万行代码，支持3种算法，打造全栈机器学习平台

https://mp.weixin.qq.com/s/adroDI2bm13o6Q40ECc7Zw

MediaPipe: Google Research 开源的跨平台多媒体机器学习模型应用框架

https://mp.weixin.qq.com/s/U2e4H1QjjBqH9YbElFLhxw

Microsoft Icecaps：一个用于会话建模的开源工具包

https://zhuanlan.zhihu.com/p/75584326

combo:“Python机器学习模型合并工具库”简介

https://github.com/arraiyopensource/kornia

可微分的“OpenCV”：这是基于PyTorch的可微计算机视觉库

https://mp.weixin.qq.com/s/5Pm03dLW9vbDukgWi1-Tug

OpenARK：惊艳的增强现实、虚实交互开源库

https://mp.weixin.qq.com/s/h0PwA9vtABWHgxd42yX3Fg

当时尚遇上AI！港中文MMLab开源MMFashion工具箱

https://github.com/Media-Smart/vedaseg

vedaseg:A semantic segmentation toolbox in pytorch

https://mp.weixin.qq.com/s/gGCyMq4PM_Whv-Ssiwt-HA

秒杀Deepfake！微软北大提出AI换脸工具FaceShifter和假脸检测工具Face X-Ray

https://mp.weixin.qq.com/s/2EHv669PUqqgvAGz3XoZ6Q

FaceBook开源PyTorch3D：基于PyTorch的新3D计算机视觉库

https://mp.weixin.qq.com/s/Z27oInh5rdxnxt1-KFAiRA

1GB文本标记只需20秒！抱抱脸团队发布最新NLP工具

https://mp.weixin.qq.com/s/8mpc7AblZyRw7LCh35vL2g

哈工大讯飞联合实验室发布知识蒸馏工具TextBrewer

https://mp.weixin.qq.com/s/Zu_IPBQVJtcwNln-xvEZxQ

DarkLabel：支持检测、跟踪、ReID数据集的标注软件

https://mp.weixin.qq.com/s/5klwQCPtiZOwFJYHDOpWFg

语义分割标注工具Semantic Segmentation Editor快速安装指南

https://mp.weixin.qq.com/s/1EeYmZGoa-xpWmIvUoqCyw

瑞士小哥开源文本英雄Texthero：一行代码完成数据预处理

https://mp.weixin.qq.com/s/p9HpH2e5ShQCFcCxVNvMbg

清华开源迁移学习算法库

https://mp.weixin.qq.com/s/vzUt-5C_dRAChEfQYLp4lA

PyTorch实现，GitHub 4000星：这是微软开源的计算机视觉库

https://mp.weixin.qq.com/s/5VeersQKxcT9AtFXS_CXnA

推荐一款超高速、多特性的高性能序列推理引擎——LightSeq

https://mp.weixin.qq.com/s/kWJZA0acOPi46c2_Gd9aeA

安利一个开源的好工具Label Studio,闭环数据标注和模型训练

https://mp.weixin.qq.com/s/b-w_jUqxGR7hY19auiar-A

FAIR发布自监督训练库VISSL

# Transformer Engine

Transformer Engine（TE）是一种专门用于加速Transformer模型在NVIDIA GPU上执行的库。它包括在Hopper和Ada架构GPU上使用8位浮点（FP8）精度的能力。

`pip install transformer_engine[pytorch]`

注意：中括号里的内容不可省略。

安装的时候，依赖中有几个包（flash-attn、flashattn_hopper（on H100））需要本地的cuda编译，且耗时较长，大概要十分钟的样子。

代码：

https://github.com/NVIDIA/TransformerEngine

---

TE和目前流行的Hugging Face的集成，主要参考NV官方的文档：

https://docs.nvidia.com/deeplearning/transformer-engine-releases/release-1.12/user-guide/examples/te_llama/tutorial_accelerate_hf_llama_with_te.html

Accelerating a Hugging Face Llama 2 and Llama 3 models with Transformer Engine

其核心思想使用TELlamaForCausalLM替换掉LlamaForCausalLM：

```python
AutoConfig.from_pretrained("llama2")
model = TELlamaForCausalLM(config=config)
```

TELlamaForCausalLM由于使用KV cache的缘故，有些torch.Tensor被降级为io.BytesIO，导致transformers的一些应用产生问题，可以用类似以下手段过滤一下：

```python
if isinstance(tensor, torch.Tensor):
  do_sth()
```

---

TE的另一项重要特性是FP8的使用。这里需要借助Hugging Face的Accelerator库：

```python
fp8_kwarg_handler = [FP8RecipeKwargs(backend="te")]
accelerator = Accelerator(kwargs_handlers=fp8_kwarg_handler)

model, optimizer, tokenized_datasets = accelerator.prepare(
    model, optimizer, tokenized_datasets
)
```

从上例也可学习在已有代码中加入Accelerator的套路——将原有各对象作为参数传入Accelerator库，然后返回各自类型的被修改后的对象。

---

```python
from transformer_engine.pytorch.cpp_extensions.fused_attn import (
    fused_attn_fwd_qkvpacked,
    fused_attn_bwd_qkvpacked,
  ...
)

return CUDAExtension(
  name="transformer_engine_torch",
  ...
)

std::vector<at::Tensor> fused_attn_fwd_qkvpacked
if (qkv_type == DType::kFloat8E4M3 || qkv_type == Dtype::kFloat8E5M2)
nvte_fused_attn_fwd_qkvpacked
fused_attn_fp8_fwd_qkvpacked
fused_attn::fused_attn_fp8_fwd_impl
cudnn_frontend::OperationGraphBuilder
cudnn_frontend::ExecutionPlanBuilder
```

---

tensor_format里的sbhd、bshd和thd是用于描述Q、K、V的内存布局格式：

- s：序列长度（sequence length）
- b：批量大小（batch size）
- h：注意力头的数量（number of attention heads）
- d：每个头的维度（head dimension）
- t：批量中总序列数，即$$t = sum(s_i)$$，其中i从0到b-1。

---

permute操作用于根据给定的索引对输入张量中的元素进行重排。具体来说，它将具有相同索引的元素分组在一起。这在MoE模型中用于将输入张量中的不同专家的输入进行分组，以便每个专家可以独立处理其输入。

---

短序列（seq_len <= 512）：使用紧凑的内存布局（如BS3HD或SB3HD）

长序列（seq_len > 512）：BSH3D或SBH3D等布局，还使用了分块计算（Tiling）、重计算（Recompute）等方案。

---

参考：

https://developer.nvidia.com/zh-cn/blog/nvidia-gpu-fp8-training-inference/

NVIDIA GPU架构下的FP8训练与推理
