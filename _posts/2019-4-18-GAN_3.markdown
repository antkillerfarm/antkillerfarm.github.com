---
layout: post
title:  GAN（三）——GAN的评估指标, DCGAN, WGAN-GP, CGAN, BEGAN & EBGAN
category: Generative Model
---

* toc
{:toc}

# GAN进阶

## GAN的理论解释

顾险峰教授对GAN提出了自己的理论解释。

>顾险峰，1989年考入清华大学计算机科学与技术系。1992年获得清华大学特等奖学金。后于美国哈佛大学获得计算机博士学位，师从国际著名微分几何大师丘成桐先生。目前为美国纽约州立大学石溪分校计算机系终身教授。

参考：

https://mp.weixin.qq.com/s/7O0AKIUVYK7HRyvdRbUVkg

虚构的对抗，GAN with the wind

https://mp.weixin.qq.com/s/trvMOTXNs7L6fSmTkZXwsA

看穿机器学习（W-GAN模型）的黑箱

https://mp.weixin.qq.com/s/thcxsBVttSIEzVNLQlAVCA

看穿机器学习的黑箱（II）

https://mp.weixin.qq.com/s/Jx0o17CwlIVcRV22PXk4wQ

看穿机器学习的黑箱（III）

https://mp.weixin.qq.com/s/ecqPzcSa75U9n4BcvnNJ_Q

GAN模式崩溃的理论解释

# GAN的评估指标

尽管可用的GAN模型非常多，但对它们的评估仍然主要是定性评估，通常需要借助人工检验生成图像的视觉保真度来进行。此类评估非常耗时，且主观性较强、具备一定误导性。鉴于定性评估的内在缺陷，恰当的定量评估指标对于GAN的发展和更好模型的设计至关重要。

论文：

《An empirical study on evaluation metrics of generative adversarial networks》

这篇论文是GAN评估指标方面的综述文章。

![](/images/img3/GAN_evaluation.png)

上图是该文给出的各种常见评估指标的体系结构图。

## Inception Score

论文：

《Improved Techniques for Training GANs》

Inception来源于Google的Inception Net，因为计算这个score需要用到Inception Net-V3。

评价一个生成模型，我们需要考验它两方面性能：

1.生成的图片是否清晰；

2.生成的图片是否多样。

生成的图片不够清晰，显然说明生成模型表现欠佳；生成的图片够清晰了，我们还要看是不是能生成足够多样的图片，有些生成模型只能生成有限的几种清晰图片，陷入了所谓mode collapse，也不是好的模型。

---

**mode collapse(模式坍塌)**，即生成高度相似的样本。

![](/images/img2/mode_collapse.jpg)

假设某个data distribution有两个模式（如上图所示），generator可能就只学到一个mode，另一个mode则完全没学到。

参考：

https://mp.weixin.qq.com/s/A7NBKV6puxqI2xCghktA9Q

什么是模式崩溃，以及如何从优化目标上解决这个问题

https://mp.weixin.qq.com/s/QFCJ7BxNvfj2L9Wlr6aq9A

解决模式崩溃的两条思路：改进优化和网络架构

---

针对这两方面，IS的思路如下：

1.清晰度：把生成的图片x输入Inception V3中，将输出1000维的向量y，向量的每个维度的值对应图片属于某类的概率。对于一个清晰的图片，它属于某一类的概率应该非常大，而属于其它类的概率应该很小。即$$p(y\mid x)$$的熵应该很小。

2.多样性：如果一个模型能生成足够多样的图片，那么它生成的图片在各个类别中的分布应该是平均的，假设生成了10000张图片，那么最理想的情况是，1000 类中每类生成了10张。即$$p(y)$$的熵很大（熵代表混乱度，均匀分布的混乱度最大）。

IS的计算方法：

$$IS(G)=\exp(\mathbb{E}_{x\sim p_g}D_{KL}(p(y \mid x)\|p(y)))$$

由于生成器的分布并不能精确得到，这里将用采样来近似分布。因此，IS的最终计算方法为：

$$\hat{p}(y)=\frac{1}{N}\sum_{i=1}^N p(y\mid x^{(i)})$$

$$IS(G)\approx \exp(\frac{1}{N}\sum_{i=1}^ND_{KL}(p(y \mid x^{(i)})\|\hat{p}(y)))$$

这里的N表示生成图片的数量。

IS是早期的评估指标，它也有很多问题。例如：均匀分布$$U(-100,100)$$，正态分布$$N(0, 20)$$，因为它们都可以得到$$H(y)=\log 2$$（关于坐标原点对称，所以生成两类的概率相同），同时得到一个很小的$$H(y\mid x)=0$$（最优判别器下，大于0的数对应的概率都很大，小于0的数，概率都很小）。反而真正的分布，左右两个正态分布对应的Inception Score小于前面这些分布。

除了这些特例之外，IS本身的假设也有站不住脚的地方：

1.是否越真实的图片，分类网络输出的概率分布函数越尖锐？显然是不见得的，如果某一个物体所属的类别在分类网络中并不存在，那么它的分布函数依然尖锐吗？

2.是否输出图片均匀地覆盖每个类别，就意味着生成模型不存在mode collapse？Inception net输出1000类，假设生成模型在每类上都生成了50个图片，那么生成的图片的类别边缘分布是严格均匀分布的，按照Inception Score的假设，这种模型不存在mode collapse，但是，如果各类中的50个图片，都是一模一样的，仍然是mode collapse。Inception Score无法检测这种情况。

本质上来说，计算IS时只考虑了生成样本，没有考虑真实数据，即IS无法反映真实数据和样本之间的距离，IS判断数据真实性的依据，源于Inception V3的训练集：ImageNet，在Inception V3的“世界观”下，凡是不像ImageNet的数据，都是不真实的，不能保证输出一个sharp的predition distribution。

相关代码：

https://github.com/sbarratt/inception-score-pytorch

## FID

Fréchet Inception Distance(FID)计算了真实图片和假图片在feature层面的距离，其公式如下：

$$FID=\|\mu_r-\mu_g\|^2+Tr\left(\Sigma_r+\Sigma_g-2(\Sigma_r\Sigma_g)^{1/2}\right)$$

$$\mu_r$$：真实图片的特征的均值。

$$\mu_g$$：生成的图片的特征的均值。

$$\Sigma_r$$：真实图片的特征的协方差矩阵。

$$\Sigma_g$$：生成图片的特征的协方差矩阵。

## 参考

https://mp.weixin.qq.com/s/EPwsQ_005CYNlCK_82SYWQ

六种GAN评估指标的综合评估实验，迈向定量评估GAN的重要一步

https://mp.weixin.qq.com/s/WTvJjiF8fkXWKW7rI9Uvug

全面解析Inception Score原理及其局限性

https://zhuanlan.zhihu.com/p/54213305

Fréchet Inception Distance(FID)

https://mp.weixin.qq.com/s/jGSqB6UpCeQo8FC219TWbQ

学习GAN模型量化评价，先从掌握FID开始吧

https://mp.weixin.qq.com/s/tV3ymNXo6xmXFu3K1AJYJQ

最早被用于评价GAN模型的定量指标Inception Score是什么

https://mp.weixin.qq.com/s/kHBPGq2z1IaKUFQe4WKd3Q

长文综述解读如何定量评价生成对抗网络(GAN)

# DCGAN

论文：

《Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks》

![](/images/img2/DCGAN.png)

DCGAN的改进主要是：

1.使用步长卷积代替上采样层，卷积在提取图像特征上具有很好的作用，并且使用卷积代替全连接层。

2.不使用pooling层。

3.上图是G网络的结构图，而D网络和G网络的结构基本是对称的。

4.在判别器中使用leakrelu激活函数，而不是RELU，防止梯度稀疏，生成器中仍然采用relu，但是输出层采用tanh。

参考：

https://mp.weixin.qq.com/s/Dz5c32SnM8-Pdjb9oWxZ_Q

想实现DCGAN？从制作一张门票谈起！

https://mp.weixin.qq.com/s/ouLWl623r_YaZdIdpqSWcw

深度卷积对抗生成网络(DCGAN)实战

https://mp.weixin.qq.com/s/qvNT_QjQh0NkDl6bgsnfwg

DCGAN

# WGAN-GP

论文：

《Improved Training of Wasserstein GANs》

![](/images/img2/WGAN_GP.png)

在某些情况下，weight clipping会导致weight集中在两端，这样整个网络就退化成二值网络了。为了改善这一点，WGAN-GP提出了一种叫做gradient penalty的办法，来取代weight clipping。

weight clipping对于超出limit的值，采用了简单粗暴clipping方式。而gradient penalty则偏于软性的“惩罚”，也就是说：对于超出limit的值，允许其存在，但要惩罚一下，使之靠近limit。距离越远，惩罚力度越大。

Lipschitz约束只关心所有的梯度都小于C，但C的值是多少，其实并不care。gradient penalty虽然并不能把所有值都约束在limit之内，但是梯度总归不会是无穷大，因此还是满足Lipschitz约束的。

WGAN-GP只是对于梯度的模大于1的区域的x作出了惩罚，它并没有保证每一个x的梯度的模都小于或等于1，也就是说它并没有从根本上解决判别器的1-Lipschitz限制问题。针对这个问题，后来又有了Spectral Normalization GAN。

参考：

https://mp.weixin.qq.com/s/aSQ2-QxbToGF0ROyjxw2yw

萌物生成器：如何使用四种GAN制造猫图

https://mp.weixin.qq.com/s/h7lrJYQ_RqJDako8UoYK-A

六种改进均未超越原版：谷歌新研究对GAN现状提出质疑

# CGAN

论文：

《Conditional Generative Adversarial Nets》

GAN不仅可用于无监督学习，也可用于有监督学习。Conditional GAN中的Condition实际上就是监督学习中的类别信息。

GAN首先是个生成模型，类别信息对于GAN的意义在于：**我不仅可以生成和数据集中样本类似的fake data，而且还可以指定它的类别。**

以MNIST数据集为例，GAN能生成数字，但生成之前，无法知道是哪个数字，而CGAN则可以按需生成。

类别信息和随机噪声的融合，可以采用组合编码（combined embedding）的方式，也可以采用hadamard product之类的互相关操作。

从数学角度看，GAN拟合的是$$p(data)$$，而CGAN拟合的是条件概率$$p(data \mid c)$$。

CGAN的D网络，除了预测数据的真假之外，还要预测数据的类别。

![](/images/img3/CGAN.png)

上图展示了监督学习（图左二）、GAN（图左三）和CGAN（图左四）的效果：

1.监督学习一般采用MSE loss，它学习到的往往是若干训练图片的平均值，所以生成的图片比较模糊。

2.GAN生成的图片细节较多，但是只保留了训练数据的语义信息，而忽略了具体内容。这里的语义信息，指的是高层级的抽象，比如都是狗图片（语义相同），内容却可以千差万别。

3.CGAN较好的解决了监督学习和GAN的结合问题，即保留了语义，也保留了内容。

参考：

https://mp.weixin.qq.com/s/0fr6H5xGxmFoNuSxs7z7bQ

CGAN

# ACGAN

https://mp.weixin.qq.com/s/oQpDW1oHIVZlvjTZm_AuYg

ACGAN

# EBGAN & BEGAN

论文：

《Energy-based Generative Adversarial Network》

《BEGAN: Boundary Equilibrium GenerativeAdversarial Networks》

这两篇论文的思路（包括名字）都差不多，都是从AutoEncoder中获取的灵感，这里就放在一起讲了。

AutoEncoder包含两个部分：

**1.Encoder。**将图片编码为tensor。

**2.Decoder。**将tensor解码为图片。

对于原始的GAN来说，G网络和Decoder的结构类似，而D网络和Encoder的结构类似。所以整个网络D(G(z))就像是一个反着接的AutoEncoder。
