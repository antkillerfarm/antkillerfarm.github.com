---
layout: post
title:  AI Chip（二）
category: Chip 
---

* toc
{:toc}

# AI Chip

## TPU

​Tensor Processing Unit(TPU)是Google推出的AI芯片系列。目前已经有3个版本：

TPU v1, deployed 2015, 92 teraops, inference only.

TPU v2, cloud TPU 2017, pod 2018, 180 teraflops, 64 GB HBM, training and inference, generally available. 11.5 petaflops in a pod.

TPU v3, cloud beta 2018, 420 teraflops, 128 GB HBM, training and inference, beta. >100 petaflops in a pod.

论文：

《In-Datacenter Performance Analysis of a Tensor Processing Unit​》

《TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings》

![](/images/img4/TPU.png)

---

![](/images/img5/TPU.png)

https://www.zhihu.com/answer/2716117809

David Patterson在UCB的演讲，分享了Google TPU近十年的发展历程以及心得体会

## Coral Dev Board

Coral Dev Board是Google于2019年3月推出的一款搭载TPU的嵌入式开发板。

参考：

http://linuxgizmos.com/google-launches-i-mx8m-dev-board-with-edge-tpu-ai-chip/

Google launches i.MX8M dev board with Edge TPU AI chip

## 脉动阵列

**AI=矩阵乘+非线性**

由于非线性只有可怜的O(N)的计算量，矩阵乘的O(N^3)的计算量才是AI中的绝对计算瓶颈。

---

Systolic array是孔祥重和他的博士生Charles Leiserson于1978年发明的。

论文：

《Why systolic architectures?》

![](/images/img4/Systolic_array.gif)

>孔祥重（H. T. Kung/Kung, Hsiang-Tsung），1945年生。台湾国立清华大学本科（1968）+CMU博士（1974）。CMU、Harvard教授。台湾中央研究院院士、美国工程院院士。除了Systolic array之外，数据库领域的Optimistic concurrency control（乐观并发控制）也是他的贡献。   
>除了Charles Eric Leiserson之外，他的博士生还有Robert Tappan Morris，也就是著名的Morris Worm的作者。

参考：

http://web.cecs.pdx.edu/~mperkows/temp/May22/0020.Matrix-multiplication-systolic.pdf

矩阵乘法器原理

http://www.eecs.harvard.edu/~htk/publication/1980-introduction-to-vlsi-systems-kung-leiserson.pdf

Algorithms for VLSI Processor Arrays

https://zhuanlan.zhihu.com/p/26522315

脉动阵列-因Google TPU获得新生

http://www.sohu.com/a/142237570_505803

我们应该拥抱“脉动阵列”吗？

https://zhuanlan.zhihu.com/p/26882794

Google深度揭秘TPU

---

参考：

https://mp.weixin.qq.com/s/1X9xiZkmVPI-j-aipr-ocg

AlphaGo Master最新架构和算法，谷歌云与TPU拆解

https://mp.weixin.qq.com/s/Yo0uKd1Mzy4mmS4r0mxfVw

有图有真相：深度拆解谷歌TPU3.0，新一代AI协同处理器

https://mp.weixin.qq.com/s/kPrZ0PuevXEJjVB7RXs70g

谷歌TPU率队，颠覆3350亿美元的半导体行业

https://mp.weixin.qq.com/s/wunqEHC6c-yUVXTl4yTG4w

仅需1/5成本：TPU是如何超越GPU，成为深度学习首选处理器的

https://mp.weixin.qq.com/s/vncPcczTyqglndeZAgjWfw

一文读懂：谷歌千元级Edge TPU为何如此之快？

https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/

Tearing Apart Google’s TPU 3.0 AI Coprocessor

https://mp.weixin.qq.com/s/3DubSQ1D59Z-PCovjHiidQ

TPU(灵魂三问 WHAT? WHY? HOW?)

https://mp.weixin.qq.com/s/j053qtpdz21IdgS22uGwAw

深入剖析卷积乘累加的硬件加速技术

https://mp.weixin.qq.com/s/XXO4hkjJkcZ5sTVVKWghEw

TPU的起源，Jeff Dean综述后摩尔定律时代的ML硬件与算法

https://mp.weixin.qq.com/s/e8zOrmiIidy8IoV1yMfdKg

谷歌长文总结四代TPU打造经验：里程碑式的TPUv4是怎样炼成的？

https://mp.weixin.qq.com/s/uEAlKdpzutOpnPGmg5dOjw

谷歌TPU超算，大模型性能超英伟达，已部署数十台：图灵奖得主新作

## Groq 

Groq是Google TPU团队的部分成员创立的AI芯片公司。

官网：

https://groq.com/

参考：

https://zhuanlan.zhihu.com/p/102357412

Groq，“软件定义硬件”概念的背后

https://www.zhihu.com/question/510527941

DSA AI芯片，相对GPGPU，能效上有多大优势？是从哪些方面提升了能效？

## Graphcore

Graphcore是一家英国芯片设计企业，成立于2012年。它的产品被称为IPU，主打数据中心的AI训练和推理。

官网：

https://www.graphcore.ai/

文档：

https://docs.graphcore.ai

这里必须表扬一下Graphcore的文档，写的非常好。

---

Graphcore的Tensorflow支持，使用了XLA接口。

而Pytorch支持，则采用了自研的PopTorch和PopART库。

PopTorch作为pytorch的平替，在建模型的同时，将模型导出为onnx格式。

PopART负责导入onnx格式的模型，并调度硬件执行。

---

参考：

https://zhuanlan.zhihu.com/p/103963276

深度剖析AI芯片初创公司Graphcore的IPU

https://mp.weixin.qq.com/s/WZQDmyjGgkGMpLjVP5jKlw

Graphcore

https://zhuanlan.zhihu.com/p/31782874

Graphcore AI芯片：更多分析

https://mp.weixin.qq.com/s/7vxJTh4IHeqUsc7IsLFLSA

解密哈萨比斯投资的IPU，他们要分英伟达一杯羹

https://www.cnblogs.com/zuyunfei/p/16349835.html

AI芯片：编程模型和硬件抽象（Nvidia CUDA vs Graphcore Poplar）

## 算力 vs 带宽

https://blog.csdn.net/tugouxp/article/details/126479276

利用roofline模型分析异构系统算力VS带宽

## HBM

HBM==High Bandwidth Memory是一款新型的CPU/GPU内存芯片（即 “RAM”），其实就是将很多个DDR芯片堆叠在一起后和GPU封装在一起，实现大容量，高位宽的DDR组合阵列。

![](/images/img2/HBM.jpg)

这是HBM的结构图。

![](/images/img2/HBM_2.jpg)

这是HBM和GDDR5的对比图。

从上面两图可以看出，HBM的集成程度在die一级，介于PCB和chip之间，这也就是近来比较火的Chiplet技术。

HBM带宽是传统内存（DRAM）的4.5倍，因此更适合处理AI应用程序所需的大量数据。这种性能的提升是如此之大，以至于许多客户更愿意支付专用内存所需的更高价格(每GB大约25美元，标准内存大约8美元)。

参考：

https://zhuanlan.zhihu.com/p/33990592

HBM火了，它到底是什么？

https://zhuanlan.zhihu.com/p/34164501

HBM技术之显卡应用

https://mp.weixin.qq.com/s/5JrsQnwL6u1fZNIpKq_hQA

DRAM的架构历史和未来

https://mp.weixin.qq.com/s/PzD1lCe5h3VkMrhFb7CfQg

后SoC时代或将迎来Chiplet拐点

https://mp.weixin.qq.com/s/oMA9RSaq0nuSNgKDRwHavQ

Chiplet最强科普

https://zhuanlan.zhihu.com/p/356505099

Chiplet与异构集成技术研究

https://www.zhihu.com/question/565166250

AMD的chiplets芯片出了这么多年了，为什么Intel和NVIDIA还不跟进？

## 行业信息

https://mp.weixin.qq.com/s/vGoWsyaal-gAzsrhPguvFg

深度解读：华为麒麟芯片是如何炼成的！

https://mp.weixin.qq.com/s/8RDHTn6P63otKXUdrHhbjw

一文看懂AI芯片产业生态及竞争格局

https://mp.weixin.qq.com/s/jINnom16KWiEKiug3N-f8g

一文看懂AI芯片：三大门派四大场景146亿美元大蛋糕

https://mp.weixin.qq.com/s/-FwuhibwwG6CFUcZXNBTFA

投资者梳理AI芯片产业，一文秒懂AI芯片生态！

https://zhuanlan.zhihu.com/p/28325678

零基础看懂全球AI芯片：详解“xPU”

https://mp.weixin.qq.com/s/Zng0NTR9P78lnR_vniiM8g

Chris Rowen: 分析全球334家真正的深度学习创业公司，盘点25家AI芯片创业公司

https://zhuanlan.zhihu.com/p/33462550

传统IP Vendor的AI加速器一览

https://mp.weixin.qq.com/s/IaCWZXQI8mYLJQXwDoNQcQ

自动驾驶芯片：GPU的现在和ASIC的未来

https://mp.weixin.qq.com/s/KjQ5BTGd92Y0Mqzk1A5JYg

老兵戴辉讲述海思视频监控芯片从0到1的血泪史！如何一步步成为行业霸主的

https://mp.weixin.qq.com/s/MwZ9j1MIwRBrJK4iWKzRqQ

芯故事：和AMD有渊源的那些AI创业公司

## 参考

![](/images/img3/Wallace_Tree.png)

https://mp.weixin.qq.com/s/_n1FA7H5q4AwXqeBg9tekA

硬件实现快速累加

>Christopher Stewart "Chris" Wallace，1933～2004，澳大利亚计算机科学家和物理学家。University of Sydney博士（1959）。Monash University教授。ACM fellow。在早期计算机的软件/硬件方面皆有重大贡献。

---

几乎每一个概述的AI加速解决方案都是从一个已经有几十年历史的学术思想开始的：脉动阵列起源于1978；VLIW架构起源于1983；数据流编程的概念可以追溯到1975；早期的内存内处理（processing-in-memory）出现在20世纪70年代。

https://www.thepaper.cn/newsDetail_forward_16268882

详解AI加速器（一）：2012年的AlexNet到底做对了什么？

https://www.thepaper.cn/newsDetail_forward_16641034

详解AI加速器（二）：为什么说现在是AI加速器的黄金时代？

https://www.thepaper.cn/newsDetail_forward_16681105

详解AI加速器（三）：架构基础离不开ISA、可重构处理器

https://www.thepaper.cn/newsDetail_forward_16787134

详解AI加速器（四）：GPU、DPU、IPU、TPU…AI加速方案有无限种可能

https://www.thepaper.cn/newsDetail_forward_16869908

详解AI加速器（最终篇）：给想进入赛道的玩家一些建议

---

https://zhuanlan.zhihu.com/p/58971347

深度学习的芯片加速器

https://mp.weixin.qq.com/s/S5Kjt4tuf_o6o3Qag8sukQ

Google Jeff Dean独自署名论文：深度学习革命及其对计算机架构和芯片设计的影响，讲述AI芯片发展历程与未来

https://cloud.tencent.com/community/article/244743

深度学习的异构加速技术（一）：AI需要一个多大的“心脏”？

https://cloud.tencent.com/community/article/581797

深度学习的异构加速技术（二）：螺狮壳里做道场

https://cloud.tencent.com/community/article/446425

深度学习的异构加速技术（三）：互联网巨头们“心水”这些AI计算平台

https://zhuanlan.zhihu.com/p/25382177

AI芯片怎么降功耗？

https://mp.weixin.qq.com/s/2aE5fzGZeyX-oFyWbcbA5A

揭开神经网络加速器的神秘面纱之DianNao

https://mp.weixin.qq.com/s/VAFb0DAZAUyDnjE6SlNcXw

如何对比评价各种深度神经网络硬件？不妨给它们跑个分

https://zhuanlan.zhihu.com/p/26594188

浅析Yann LeCun提到的两款Dataflow Chip

https://zhuanlan.zhihu.com/p/25728988

AI芯片的几种选择，你更看好哪个？

https://zhuanlan.zhihu.com/p/25510056

ISSCC 2017看AI芯片的四大趋势

https://zhuanlan.zhihu.com/p/26404565

AI芯片四大流派论剑，中国能否弯道超车？

https://zhuanlan.zhihu.com/p/27472524

从AI芯片说起，一起来看芯片门类

https://mp.weixin.qq.com/s/Cy_vb0PpcvGTDmlMt1VkSw

从GPU、TPU到FPGA及其它：一文读懂神经网络硬件平台战局

https://mp.weixin.qq.com/s/RKRDBiBzG5u2P2eaqNAFbg

机器学习的处理器列表

https://mp.weixin.qq.com/s/uzeeZiaAFdA0C_zAcX756w

深度学习架构之争

https://mp.weixin.qq.com/s/VM-KiIJHA2gXLVu0WRIzwA

王中风教授：如何满足不同应用场景下深度神经网络模型算力和能效需求

https://mp.weixin.qq.com/s/f5mQkWxPYc77t2we1Y306Q

深度学习引领AI芯片大战
