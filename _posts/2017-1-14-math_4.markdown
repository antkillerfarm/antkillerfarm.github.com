---
layout: post
title:  数学狂想曲（四）——矩阵&向量的积, 软件滤波算法, 玻尔兹曼分布
category: math 
---

# 矩阵&向量的积（续）

## 向量的点积

Dot product，又称inner product。

代数定义：

$$\mathbf{a}\cdot\mathbf{b}=\sum_{i=1}^n a_ib_i=a_1b_1+a_2b_2+\cdots+a_nb_n$$

几何定义：

$$\mathbf{a}\cdot\mathbf{b}=\|\mathbf{a}\|\ \|\mathbf{b}\|\cos(\theta)$$

复变积分定义：

$$\left\langle \psi , \chi \right\rangle = \int_a^b \psi(x) \overline{\chi(x)} d x $$

## 矩阵的积

matrix product的定义如下（以3阶方阵为例）：

$$\mathbf{AB} = \begin{pmatrix}
a & b & c \\
p & q & r \\
u & v & w
\end{pmatrix} \begin{pmatrix}
\alpha & \beta & \gamma \\
\lambda & \mu & \nu \\
\rho & \sigma & \tau \\
\end{pmatrix} =\begin{pmatrix}
a\alpha + b\lambda + c\rho & a\beta + b\mu + c\sigma & a\gamma + b\nu + c\tau \\
p\alpha + q\lambda + r\rho & p\beta + q\mu + r\sigma & p\gamma + q\nu + r\tau \\
u\alpha + v\lambda + w\rho & u\beta + v\mu + w\sigma & u\gamma + v\nu + w\tau
\end{pmatrix}$$

可以看出，积矩阵的每个元素是矩阵A、B相应行列向量的内积。

## 向量的向量积

Cross product是一个向量，其定义如下：

$$\mathbf{a} \times \mathbf{b} = \left\| \mathbf{a} \right\| \left\| \mathbf{b} \right\| \sin (\theta) \ \mathbf{n}$$

它还有个更出名的定义：

$$\mathbf{u\times v} = \begin{vmatrix}
  \mathbf{i}&\mathbf{j}&\mathbf{k}\\
  u_1&u_2&u_3\\
  v_1&v_2&v_3\\
\end{vmatrix}$$

由于Cross product和a、b所在平面垂直，因此多用于求解平面的法向量，且该法向量的方向符合“右手定则”。

## 向量的混合积

triple product，又称mixed product或box product。

$$\mathbf{a}\cdot(\mathbf{b}\times \mathbf{c}) \equiv \det \begin{bmatrix}
  a_1 & a_2 & a_3 \\
  b_1 & b_2 & b_3 \\
  c_1 & c_2 & c_3 \\
\end{bmatrix}={\rm det}\left(\mathbf{a},\mathbf{b},\mathbf{c}\right)$$

混合积相当于求解以a、b、c为棱的六面体的体积。由体积的唯一性，易得混合积具有交换律和结合律。

## 向量的笛卡尔积

Cartesian product实际上是集合论中的概念。

$$A\times B = \{1,2\} \times \{3,4\} = \{(1,3), (1,4), (2,3), (2,4)\}$$

## 向量的张量积

Tensor product，又称outer product。

$$\begin{align}\mathbf{u} \otimes \mathbf{v} = \mathbf{u} \mathbf{v}^\mathrm{T}
= \begin{bmatrix}u_1 \\ u_2 \\ u_3 \\ u_4\end{bmatrix}
\begin{bmatrix}v_1 & v_2 & v_3\end{bmatrix}
= \begin{bmatrix}u_1v_1 & u_1v_2 & u_1v_3 \\ u_2v_1 & u_2v_2 & u_2v_3 \\ u_3v_1 & u_3v_2 & u_3v_3 \\ u_4v_1 & u_4v_2 & u_4v_3\end{bmatrix}\end{align}$$

可以看出，Tensor product和Cartesian product，虽然形式上都是各向量的组合，然而前者是2维的，而后者是1维的。

>外积这个术语，在中文中也可以指Cross product，所以最好避免使用外积这个术语，避免混淆。

## 矩阵的张量积

张量积推广到矩阵，即所谓Kronecker product。

>注：Leopold Kronecker，1823～1891，德国数学家。柏林大学博士和教授。导师Dirichlet。他最牛逼的地方是，当Riemann去世的时候，拒绝了哥廷根大学的offer。而这个位置的前任分别是：Carl Gauss、Dirichlet、Riemann。

$$\mathbf{A}\otimes\mathbf{B} = \begin{bmatrix} a_{11} \mathbf{B} & \cdots & a_{1n}\mathbf{B} \\ \vdots & \ddots & \vdots \\ a_{m1} \mathbf{B} & \cdots & a_{mn} \mathbf{B} \end{bmatrix}$$

## Hadamard product

又叫Schur product或entrywise product。

>注：Jacques Salomon Hadamard，1865～1963，法国数学家。巴黎高等师范学校博士，波尔多大学教授。他曾于1936年访华，执教于清华大学。中国偏微分方程研究事业的主要创始人之一——吴新谋教授，就是他的学生。

$$\left(\begin{array}{ccc}
    \mathrm{a}_{11} & \mathrm{a}_{12} & \mathrm{a}_{13}\\
    \mathrm{a}_{21} & \mathrm{a}_{22} & \mathrm{a}_{23}\\
    \mathrm{a}_{31} & \mathrm{a}_{32} & \mathrm{a}_{33}
  \end{array}\right) \circ \left(\begin{array}{ccc}
    \mathrm{b}_{11} & \mathrm{b}_{12} & \mathrm{b}_{13}\\
    \mathrm{b}_{21} & \mathrm{b}_{22} & \mathrm{b}_{23}\\
    \mathrm{b}_{31} & \mathrm{b}_{32} & \mathrm{b}_{33}
  \end{array}\right) = \left(\begin{array}{ccc}
    \mathrm{a}_{11}\, \mathrm{b}_{11} & \mathrm{a}_{12}\, \mathrm{b}_{12} & \mathrm{a}_{13}\, \mathrm{b}_{13}\\
    \mathrm{a}_{21}\, \mathrm{b}_{21} & \mathrm{a}_{22}\, \mathrm{b}_{22} & \mathrm{a}_{23}\, \mathrm{b}_{23}\\
    \mathrm{a}_{31}\, \mathrm{b}_{31} & \mathrm{a}_{32}\, \mathrm{b}_{32} & \mathrm{a}_{33}\, \mathrm{b}_{33}
  \end{array}\right)$$

# 软件滤波算法

## 限幅滤波法

方法：根据经验判断，确定两次采样允许的最大偏差值（设为A），每次检测到新值时判断：如果本次值与上次值之差<=A，则本次值有效，如果本次值与上次值之差>A，则本次值有效，放弃本次值，用上次值代替本次值。

优点：能有效克服因偶然要素惹起的脉冲干扰。

缺点：无法抑制那种周期性的干扰，平滑度差。

## 中位值滤波法

方法：连续采样N次（N取奇数），把N次采样值按大小陈列，取中位值（第$$\frac{(N-1)}{2}$$个值）为本次有效值。

优点：能有效克服因偶然要素惹起的波动干扰，对变化缓慢的被测参数有良好的滤波效果。

缺点：对快速变化的参数不宜。

## 算术平均滤波法

方法：连续取N个采样值进行算术平均运算，N值较大时：信号平滑度较高，但灵敏度较低；N值较小时：信号平滑度较低，但灵敏度较高。

优点：适用于对普通具有随机干扰的信号进行滤波，这样信号的特点是有一个平均值，信号在某一数值范围附近上下波动。

缺点：对于测量速度较慢或要求数据计算速度较快的实时控制不适用，比较浪费RAM 。

## 递推平均滤波法（又称滑动平均滤波法）

方法：把连续取的N个采样值看成一个队列，队列的长度固定为N，每次采样到一个新数据放入队尾，并扔掉原来队首的一次数据(先进先出) 。把队列中的N个数据进行算术平均运算，就可获得新的滤波结果。

优点：对周期性干扰有良好的抑制效用，平滑度高，适用于高频振荡系统。

缺点：灵敏度低，对偶然出现的脉冲性干扰的抑制效用较差，不易消弭由于脉冲干扰所引起的采样值偏差，不适用于脉冲干扰比较严重的场合，比较浪费RAM。

## 中位值平均滤波法（又称防脉冲干扰平均滤波法）

方法：相当于“中位值滤波法”+“算术平均滤波法”，连续采样N个数据，去掉一个最大值和一个最小值，然后计算N-2个数据的算术平均值。。

优点：融合了两种滤波法的优点，对于偶然出现的脉冲性干扰，可消弭由于脉冲干扰所惹起的采样值偏差。

缺点：测量速度较慢，和算术平均滤波法一样，比较浪费RAM。

## 限幅平均滤波法

方法：相当于“限幅滤波法”+“递推平均滤波法”，每次采样到的新数据先进行限幅处理，再送入队列进行递推平均滤波处理。

优点：融合了两种滤波法的优点，对于偶然出现的脉冲性干扰，可消弭由于脉冲干扰所惹起的采样值偏差。

缺点：比较浪费RAM。

## 一阶滞后滤波法

方法：取a=0~1，本次滤波结果=(1-a)*本次采样值+a*上次滤波结果。

优点：对周期性干扰具有良好的抑制造用，适用于波动频率较高的场合。

缺点：相位滞后，灵敏度低，滞后程度取决于a值大小，不能消弭滤波频率高于采样频率的1/2的干扰信号。

## 加权递推平均滤波法

方法：这是对递推平均滤波法的改进，即不同时刻的数据加以不同的权，通常是，越接近现时刻的材料，权取得越大，给予新采样值的权系数越大，则灵敏度越高，但信号平滑度越低。

优点：适用于有较大纯滞后事件常数的对象和采样周期较短的系统。

缺点：对于纯滞后事件常数较小，采样周期较长，变化缓慢的信号，不能迅速反应系统当前所受干扰的严重程度，滤波效果差。

## 消抖滤波法

方法：设置一个滤波计数器，将每次采样值与当前有效值比较：如果采样值等于当前有效值，则计数器清零。如果采样值不等于当前有效值，则计数器+1，并判断计数器能否>=下限N(溢出)，如果计数器溢出，则将本次值交换当前有效值，并清计数器。

优点：对于变化缓慢的被测参数有较好的滤波效果，可避免在临界值附近控制器的反复开/关跳动或显示器上数值抖动。

缺点：对于快速变化的参数不宜，如果在计数器溢出的那一次采样到的值恰好是干扰值，则会将干扰值当作有效值导入系统。

## 限幅消抖滤波法

方法：相当于“限幅滤波法”+“消抖滤波法”，先限幅后消抖。

优点：承继了“限幅”和“消抖”的优点，改进了“消抖滤波法”中的某些缺陷，避免将干扰值导入系统。

缺点：对于快速变化的参数不宜。

## IIR数字滤波

方法：确定信号带宽，滤之。

$$Y(n)=a_1*Y(n-1)+a_2*Y(n-2)+...+a_k*Y(n-k)+$$

$$b_0*X(n)+b_1*X(n-1)+b_2*X(n-2)+...+b_k*X(n-k)$$

优点：高通，低通，带通，带阻任意。design简单(用matlab）。

缺点：运算量大。

# 玻尔兹曼分布

Boltzmann distribution（又叫Gibbs distribution）本来是脱胎于热力学和统计力学的分布，但在量子力学和机器学习领域也得到了广泛的应用。

>注：Ludwig Eduard Boltzmann，1844～1906，奥地利物理学家，统计力学的奠基人之一。维也纳大学博士，先后执教于格拉茨大学、维也纳大学、慕尼黑大学和莱比锡大学。英国皇家学会会员。

## 信息熵

设概率实验X有n个可能的独立结局，即n个随机事件$$A_1,\dots,A_n$$，每个随机事件的概率为$$p_1,\dots,p_n$$。则信息熵的定义为：

$$H_n=-k\sum_{i=1}^{n}p_i\ln p_i\tag{1}$$

其中k为一正常数。可以看出$$H_n$$实际上是$$p_i$$的泛函。

以下我们主要从信息熵的角度出发研究玻尔兹曼分布。但不能忽视的是，玻尔兹曼分布最早脱胎于热力学，而信息熵与热力学统计物理中的熵，虽然数学形式一致，但本质是不同的。两者相差一个玻尔兹曼常数。参见：

https://www.zhihu.com/question/20992022/answer/50458123

信息熵与热力学统计物理中的熵有什么区别和联系？

>注：信息熵的定义有多种，公式1给出的是Shannon熵的定义，除此之外还有von Neumann熵、Renyi熵等。以下如无特殊指出，信息熵均指Shannon熵。

参考：

https://mp.weixin.qq.com/s/LGyNq3fRlsRSatu1lpFnnw

机器学习各种熵：从入门到全面掌握

https://mp.weixin.qq.com/s/6I2-5zWbpAUSgoHRUEkj3Q

通俗理解信息熵

