---
layout: post
title:  GAN（七）——GAN参考资源（3）
category: GAN & VAE 
---

* toc
{:toc}

# GAN参考资源

https://zhuanlan.zhihu.com/p/41114883

手机照片脑补成超大画幅，这个GAN想象力惊人

https://mp.weixin.qq.com/s/bKve_tZi9usz4oX0T3S15A

悉尼大学陶大程：遗传对抗生成网络有效解决GAN两大痛点

https://zhuanlan.zhihu.com/p/46629127

生成对抗网络-GAN---一个好老师的重要性

https://mp.weixin.qq.com/s/Sp0EYvaq-1u0mtnrrmFNCQ

为什么说GANs是一个绝妙的艺术创作工具？

https://mp.weixin.qq.com/s/uHEAtuY1_KZdUAdDAwFi_A

以为GAN只能“炮制假图”？它还有这7种另类用途

https://mp.weixin.qq.com/s/Yf5quOXmzJAy0GnJnvam5g

台湾学者研发新型二元神经元GAN！有望用于AI作曲

https://mp.weixin.qq.com/s/8aL7COItG7lS4q5-3IZCmQ

定制人脸图像没那么难！使用TL-GAN模型轻松变脸

https://mp.weixin.qq.com/s/9t0GvQW-cmakM0E9dWxBcg

旧照片着色修复神器！自注意力GAN效果惊艳

https://mp.weixin.qq.com/s/cUFQ6EADa39h2eFoa_Dh0A

最高76%破解成功率！GAN已经能造出“万能指纹”，你的手机还安全吗？

https://mp.weixin.qq.com/s/_tABIMkWX8L5xQFmvPI7rw

有效稳定对抗模型训练过程，伯克利提出变分判别器瓶颈

https://mp.weixin.qq.com/s/xr9fDv9DFkwi2ImV4RZAHg

换个角度看GAN：另一种损失函数

https://mp.weixin.qq.com/s/U1rrPfJDLgXHRj__XwrMZw

只有条件GAN才能稳定训练？对抗+自监督的无监督方法了解一下

https://mp.weixin.qq.com/s/xHKQlFFkBQLBg2GdZuGPSw

提升GAN训练的技巧汇总

https://mp.weixin.qq.com/s/ctB90bNhaMYvbLE4yketHQ

一文读懂对抗机器学习Universal adversarial perturbations

https://mp.weixin.qq.com/s/zRNtEKS2dKxyQU4VZm6Mwg

用GANs来自动生成音乐

https://mp.weixin.qq.com/s/zwzl-Tel3Avc4Dm7L5FS5A

NLP中的对抗训练+PyTorch实现

https://mp.weixin.qq.com/s/Ze2BXEexTIpNluRSdfeCsA

GAN和PS合体会怎样？东京大学图像增强新研究：无需配对图像，增强效果还可解释

https://mp.weixin.qq.com/s/qLhnvLhXHhRoPGtPWYCY0w

ICCV2019最佳论文SinGAN全面解读

https://zhuanlan.zhihu.com/p/97138846

《SinGAN:从单个自然图像中学习生成模型》论文笔记

https://mp.weixin.qq.com/s/mXjNtZvUHutBABh-f9qisQ

那些底层的图像处理问题中，GAN能有什么作为？

https://mp.weixin.qq.com/s/zVGDYhBiLCNhKTnkzbMxGA

时间序列GAN，Subadditivity of Probability Divergences

https://mp.weixin.qq.com/s/ssD3NAvGx5Eu4-oWy4KtzA

如何生动有趣地对GAN进行可视化？

https://mp.weixin.qq.com/s/qz4wUpSeF8Nlem8x4CrR-Q

学习一个宫崎骏画风的图像风格转换GAN

https://zhuanlan.zhihu.com/p/50790727

SeqGAN: Sequence GAN with Policy Gradient

https://mp.weixin.qq.com/s/bH5yYbwq6NGQJ84xUDhoxg

生成对抗网络在图像翻译上的应用

https://mp.weixin.qq.com/s/3Gsmrl4HbcnXpje0nyAq2w

中国西北大学和北京大学的研究结果是否将终结CAPTCHA验证码时代？

https://zhuanlan.zhihu.com/p/53260242

抛开复杂证明，我们从直觉上理解W-GAN为啥这么好训

https://mp.weixin.qq.com/s/FJA8Tctq_p4Mj-KgNn_OGg

为什么让GAN一家独大？Facebook提出非对抗式生成方法GLANN

https://mp.weixin.qq.com/s/SGCoCy8wJEhEpLSHrYK3pQ

韩松、朱俊彦等人提出GAN压缩法：算力消耗不到1/9，现已开源

https://mp.weixin.qq.com/s/D-rh9m7G-ERjWEEG6BQJNg

每个人都能用英伟达GAN造脸了

https://mp.weixin.qq.com/s/qRW344wWgS9PJ6UCwknS8g

Local GAN

https://mp.weixin.qq.com/s/-rwzlX-WipaIdV6ESOimxw

GAN加持！英伟达发布“山寨”游戏创造器，已完美复现《吃豆人》

https://mp.weixin.qq.com/s/orm5r4XHyotBCpBKqfZ-ng

GANSynth：使用GAN制作音乐

https://mp.weixin.qq.com/s/4zKgFfyLGAmqgHtf_Wb0nw

使用GAN生成序列数据

https://mp.weixin.qq.com/s/oRCbr0TCzFmTuf5jpWKBaA

GAN版马里奥创作家来了：一个样本即可训练，生成关卡要素丰富

https://mp.weixin.qq.com/s/2NrPolWxV-L-dFUXgGOd9w

在GAN中通过上下文的复制和粘贴，在没有数据集的情况下生成新内容

https://mp.weixin.qq.com/s/iqCMA7E_vtdymVxxz7bpRA

生成对抗网络（GAN）的数学原理全解

https://mp.weixin.qq.com/s/D0gLR6YU3rYTbFqSCwyi9Q

Semi-Supervised GAN

https://mp.weixin.qq.com/s/MY-nx_MDyBJHUidS3Xqs7g

最新《生成式对抗网络GAN进展》综述论文，41页pdf阐述GAN在计算机视觉应用进展

https://mp.weixin.qq.com/s/fQiZpUbeYvFnNZYYSE4dMQ

用GANs来做数据增强

https://mp.weixin.qq.com/s/KT_YHNLGdOI-mr4EnYgGvw

使用有限的数据来训练GANs

https://mp.weixin.qq.com/s/_cKtmNZbqHwZszocPXuy8g

让GAN随音乐律动的Python工具，网友：这是我见过的GAN的最佳用法

https://mp.weixin.qq.com/s/skDZcvuek3pAV1U07aORVA

改善图像处理效果的五大生成对抗网络

https://mp.weixin.qq.com/s/a1f_8wP0bMyNf99ihaCISg

对抗学习如何应用到推荐系统？ECIR2021<对抗学习推荐系统>教程，197页ppt

https://mp.weixin.qq.com/s/n8c2-NPtVe-k2L6qvEHsUA

改善图像处理效果的五大生成对抗网络

https://mp.weixin.qq.com/s/imOFQL01RaXUuZwew1izzg

基于GAN来做低光照图像增强，EnlightenGAN论文解读

# Polyhedral Model+

循环不变量外提

循环展开，软流水，并行化，向量化

向量化：标量运算转换为向量运算，并在同一硬件上执行。

并行化：将任务拆分成多个可并行执行的子任务，并同时在多个硬件单元上执行。

向量化和并行化通常是两个冲突的优化目标，前者通常在内层循环进行，而后者通常在外层循环进行。

---

Loop tiling：将大块循环迭代拆解为若干小块的循环迭代，减少数据重用的周期。

Loop fusion：将多个具有“生产-消费”关系的循环块合并到一起，减少中间数据的搬运。

这也是两个冲突的目标，Loop fusion会导致Loop tiling的约束复杂化。

https://blog.csdn.net/wangbowj123/article/details/101173269

循环优化与多面体模型

---

线性变换（linear transformation）：$$y=Ax$$

仿射变换（affine transformation）：$$y=Ax+b$$

迭代空间（iteration space）：在一些计算过程中动态执行示例的集合，也就是各个循环下标的取值的组合。

数据空间（data space）：被访问的数组元素的集合。

处理器空间（processor space）：系统中处理器的集合。通常情况下，这些处理器使用整数或者整数向量进行编号。

因为循环是多重的，所以iteration space是个多面体。同样的，数据是多维的，它也是一个多面体。

从ALU到core，到die，到chip；从register到L0 Cache，到L1 Cache，到RAM；无论是运算器，还是存储器，都是一个有层次的结构，这也是一个多面体。

由于非线性数学理论的不完备，目前的Polyhedral Model主要研究仿射变换。在这个前提下，人们发现不同space之间的变换，可以用矩阵运算来表示。而矩阵运算的数学工具已经相当丰富了。

---

Presburger表示：

$$S=\{(i,j): 0 \le i<R \land 0 \le j<C \}$$

访问函数：从迭代空间到数据空间的一个映射关系。一般可表示为如下矩阵形式：

$$S(i)=Fi+f$$

其中，i为循环迭代向量，S表示数组的下标向量。F和f分别为系数和常数。

所有不破环原有程序语义中的数据依赖的访问遍历顺序都是合法的，这个遍历顺序被称为一种**调度**。显然不同调度的性能是不同的，循环优化算法的目标就是找到其中的最优调度。

---

依赖分析：读后写依赖，写后写依赖，写后读依赖。

doall循环：没有依赖的循环。

doacross循环：有依赖的循环。

依赖判断的充要条件是：

$$F_1i_1+f_1=F_2i_2+f_2$$

求上述等式整数解的问题是一个典型的整数规划问题。但后者已经确认是个NP完全问题。

所以编译器通常用Banerjee测试和GCD测试来检测依赖。

---

几种基础的仿射变换：

- 循环交换（loop permutation）：交换内层循环和外层循环的次序。$$S(i,j)\to (j,i)$$
- 循环反转（loop reversal）：按照相反的顺序执行一个循环中的所有迭代。$$S(i)\to (-i)$$
- 循环倾斜（loop skewing）：对原始循环的迭代空间进行坐标变换。$$S(i,j)\to (i, f\times i+j)$$

上面3种被称为幺模变换。

- 循环延展（loop scaling）：将循环索引变量和循环步长做等比例缩放。$$S(i)\to (s\times i)$$
- 循环合并（loop fusion）：将原程序中的多个循环下标映射到同一个循环下标上。$$S1(i)\to (0,i);S2(i)\to (1,i)$$
- 循环分布（loop distribution/fission）：将不同语句的同一个循环下标映射到不同的循环下标。$$S(i,j)\to (j,i)$$
- 循环偏移（loop shifting）：将一个动态语句实例偏移固定多个循环迭代。$$S(i,j)\to (j,i)$$

上面7种被称为基础仿射变换。

- 循环分段（loop strip-mining）：将某维度的迭代拆成两个粒度，比如先以4步长遍历、4步长内以1步长遍历。
- 循环分块（loop tiling）：将对一个大数组的遍历访问拆成更多维度，以利用局部性，比如将调度（i, j）改为 (i/4, j/4, i, j)。它实际等同是循环分段+循环交换。
- 循环展开压紧（loop unroll and jam）：提升外层循环的粒度，并向内压紧。

这几种涉及除法，被称为近似仿射变换。无论基础仿射变换，还是近似仿射变换，都是改变指令实例执行顺序的变换。

除此之外，还有一些不改变指令实例执行顺序的变换：

- 分块分离（loop tile isolation），分块有时会分出半块，导致循环内部有一些判断语句是用于处理这部分计算的。把它们分走，避免冗余判断。
- 循环展开（loop unrolling），降低循环条件本身的判断代价。
- 循环判断外提（loop unswitching），循环剥离（loop peeling）等。
- 循环压紧（loop coalescing/linearization），其实就是线性化；这一般是要被避免的，这种变换使循环的结构丧失了。

参考：

https://zhuanlan.zhihu.com/p/604571955

常见的循环变换
