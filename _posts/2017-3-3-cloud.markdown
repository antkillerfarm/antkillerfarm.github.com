---
layout: post
title:  云计算论文集, Spark, Apache Kylin, 多维数组的行优先和列优先
category: AI 
---

# 云计算论文集

这里列出一些在这个领域产生重大影响的论文。仅作备忘，肯定不全，Google是其中的绝对主力。

## CAP

《Towards Robust Distributed Systems》（2000）

>作者：Eric Brewer是University of California, Berkeley的计算机科学教授，在Google担任基础设施方面的VP。他的研究兴趣包括云计算、可伸缩的服务器、传感器网络，还有适合发展中地区应用的技术。他还帮助建立了美国联邦政府的门户网站USA.gov。Brewer从MIT获得电子工程和计算机科学的博士学位。他是National Academy of Engineering的院士。

## GFS

《The Google File System》（2003）

开源实现：Hadoop HDFS

>作者：Sanjay Ghemawat，Ph.D. in Computer Science from MIT，2009年当选美国国家工程学院院士。

>Howard Gobioff(1971 – 2008)，Carnegie Mellon University，Ph.D. Computer Science。

>Shun-Tak Leung，University of Washington，Ph.D. Computer Science。

## MapReduce

《MapReduce: Simplified Data Processing on Large Clusters》（2004）

开源实现：Hadoop MapReduce

>作者：Jeffrey Dean，University of Washington，Ph.D. Computer Science (1996)，2009年当选美国国家工程学院院士。

>Sanjay Ghemawat。

## Bigtable

开源实现：Hbase

《Bigtable: A Distributed Storage System for Structured Data》（2006）

>作者：Fay W. Chang，Carnegie Mellon University，Ph.D. Computer Science 。

>Jeffrey Dean, Sanjay Ghemawat, Wilson C. Hsieh, Deborah A. Wallach, Mike Burrows, Tushar Chandra, Andrew Fikes, Robert E. Gruber

## Spanner

《Spanner: Google’s Globally-Distributed Database》（2012）

>作者：James C. Corbett，PhD in Computer Science from the University of Massachusetts at Amherst.

>Jeffrey Dean, Michael Epstein, Andrew Fikes, Christopher Frost, JJ Furman, Sanjay Ghemawat, Andrey Gubarev, Christopher Heiser, Peter Hochschild, Wilson Hsieh,Sebastian Kanthak, Eugene Kogan, Hongyi Li, Alexander Lloyd, Sergey Melnik, David Mwaura,David Nagle, Sean Quinlan, Rajesh Rao, Lindsay Rolig, Yasushi Saito, Michal Szymaniak,Christopher Taylor, Ruth Wang, Dale Woodford

## Dremel

Dremel是Google的“交互式”数据分析系统。可以组建成规模上千的集群，处理PB级别的数据，是MapReduce的有力补充。

《Dremel: Interactive Analysis of WebScaleDatasets》（2006）

>作者：Sergey Melnik, Ph.D. in Computer Science from the University of Leipzig, Germany. Microsoft Research (2003-2008), Google(since 2008)

>Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shivakumar, Matt Tolton, Theo Vassilakis

## Chubby Lock

《The Chubby lock service for loosely-coupled distributed systems》（2006）

开源实现：Zookeeper

>作者：Mike Burrows，1963年生，英国计算机学家。剑桥大学博士。2013年当选皇家学会会员。

# Spark

官网：

http://spark.apache.org/

## RDD

Resilient Distributed Datasets是一个只读的，可分区的分布式数据集，这个数据集的全部或部分可以缓存在内存中，在多次计算间重用。RDD克服了传统的MapReduce所进行大量的磁盘IO操作。

我的理解：RDD将计算包括中间结果，全部放到内存中，以节省磁盘IO操作。

http://www.infoq.com/cn/articles/spark-core-rdd

理解Spark的核心RDD

http://f.dataguru.cn/thread-475874-1-1.html

Spark RDD详解

## DataFrame和DataSet

http://www.jianshu.com/p/c0181667daa0

RDD、DataFrame和DataSet的区别

http://www.csdn.net/article/2015-02-17/2823997

Spark新年福音：一个用于大规模数据科学的API——DataFrame

https://www.iteblog.com/pdf/1675

Spark 2.0介绍：从RDD API迁移到DataSet API

https://www.jianshu.com/p/0fe48bc43a8c

spark程序jar与spark lib jar冲突，加载顺序

## transformation & action

transformation是得到一个新的RDD，方式很多，比如从数据源生成一个新的RDD，从RDD生成一个新的RDD。

action是得到一个值，或者一个结果（直接将RDDcache到内存中）。

所有的transformation都是采用的懒策略，就是如果只是将transformation提交是不会执行计算的，计算只有在action被提交的时候才被触发。

## Spark部署

Spark没有服务程序，因此无须部署，只需要在集群中的某台机器上安装spark，进行任务提交即可。Spark的并行执行主要依赖Hadoop YARN。

参见：

http://blog.csdn.net/book_mmicky/article/details/25714287

Spark虽然对Hadoop的版本有一定的要求，但是并不是太严重的问题。比如，目前最新的Spark 2.0.1（2016.10）仍然支持Hadoop 2.3，而后者是2014年2月出的版本。

## shuffle

![](/images/article/mapreduce-process.jpg)

上图描述了MapReduce算法的整个流程，其中shuffle phase就是介于Map phase和Reduce phase之间的那一堆连线。很显然，shuffle虽然是MapReduce算法提出的概念，但在各类分布式计算框架中普遍存在，也是影响计算效率的关键点和框架设计的难点之一。

参考：

http://jerryshao.me/architecture/2014/01/04/spark-shuffle-detail-investigation/

## 控制日志输出等级

有的时候为了防止控制台的日志输出过多，淹没了程序的正常输出，可以采用如下方法：

{% highlight java %}
SparkContext sc = SparkContext.getOrCreate(conf);
sc.setLogLevel("WARN");
{% endhighlight %}

## 基本统计操作

1.统计列中不相同值的个数。

方法一：

比如在观众观影的表格中，找出观众的数量或电影的数量。

`Dataset<Row> df = session.sql("SELECT userId FROM Movie group by userId");//df.count() is the count of different values`

方法二：

Spark中有个org.apache.spark.sql.functions类，专门针对数据集进行各种运算操作。其中的countDistinct方法可实现该功能。片段示例如下：

`Dataset<Row> df2 = df.agg(functions.countDistinct("userId"));df2.show();`

## MLlib

MLlib是Spark的机器学习库。官网：

https://spark.apache.org/mllib/

和Spark的其他部分一样，MLlib也存在RDD API和DataFrame API两套API。其中前者已经停止开发，而后者的设计思想显然来自R语言。RDD API在spark.mllib包中，而DataFrame API在spark.ml包中。

## 参考

http://www.cnblogs.com/zlslch/p/5723857.html

Spark的各种算子

http://mp.weixin.qq.com/s?__biz=MjM5NzAyNTE0Ng==&mid=2649517135&idx=2&sn=7fc02a006b7c5015f3492354d0e298a4&scene=0#rd

Spark性能优化指南：高级篇

https://www.zhihu.com/question/23079001

内存有限的情况下，Spark如何处理T级别的数据

https://www.zhihu.com/question/26568496

与Hadoop对比，如何看待Spark技术？

http://www.csdn.net/article/1970-01-01/2825748

如何利用“图计算”实现大规模实时预测分析

http://www.cnblogs.com/bluejoe/p/5115846.html

学习GraphX

http://www.cnblogs.com/bluejoe/p/5115845.html

Hive体系结构介绍

https://mp.weixin.qq.com/s/vM5DM6CEVuKjcWBxZZSbhA

既生Mahout，何生Spark MLlib？

https://mp.weixin.qq.com/s/O_KQxKLFUpJrDXw244nEfQ

Spark资源调优

https://mp.weixin.qq.com/s/gp9MTKWbgHQ7b7QR5pNSnA

Apache Spark中的全新流式引擎Structured Streaming

https://mp.weixin.qq.com/s/g-HgfQ77ExpS0d9QrRcvlg

Python大数据处理库PySpark实战——使用PySpark处理文本多分类问题

http://blog.csdn.net/xiaomin1991222/article/details/50982579

使用Mahout实现协同过滤Spark

https://mp.weixin.qq.com/s/dYCtth0r2Gme5iGSviVmBQ

基于Spark的机器学习痛点，风控和模型优化案例分析！

https://mp.weixin.qq.com/s/8ZEUNIXHu7iF1hHk7e0gdw

Spark机器学习的加速器：Spark on Angel

https://mp.weixin.qq.com/s/KPTM02-ICt72_7ZdRZIHBA

苏宁基于Spark Streaming的实时日志分析系统实践

https://mp.weixin.qq.com/s/6UlkU56GJFPOhhNBn7NUOg

基于Apache Spark的深度学习

# Apache Kylin

Apache Kylin是一个开源的分布式分析引擎，最初由eBay开发贡献至开源社区。它提供Hadoop之上的SQL查询接口及多维分析（OLAP）能力以支持大规模数据，能够处理TB乃至PB级别的分析任务，能够在亚秒级查询巨大的Hive表，并支持高并发。

官网：

http://kylin.apache.org/

参考：

http://d.xiumi.us/board/v5/39rut/82854193

老司机带路系列：多维交叉分析引擎-Kylin

# 多维数组的行优先和列优先

这里以numpy为工具，介绍一下多维数组的行优先和列优先的概念。

首先我们生成一个3x4的数组：

`arr = np.arange(12).reshape(3,4)`

它的形状是这样的：

![](/images/article/arr_3x4.png)

如果我们按照C语言的方式存储它，也就是行优先存储的话，那么在内存中，它的形状是这样的：

![](/images/article/arr_3x4_C.png)

这种存储方式又被称作C contiguous array。

另一派存储方式，也就是列优先存储，它的代表是Fortran语言。上面的数组在内存中的形状就是这样的了：

![](/images/article/arr_3x4_Fortran.png)

这种存储方式又被称作Fortran contiguous array。

numpy对这两种方式都支持，而且还巧妙的利用了两者之间的差异，对运算进行了简化。

`arr2 = arr.T`

比如上述转置操作，你以为numpy真的做了转置运算吗？其实不然。

{% highlight python %}
>>>arr.flags.f_contiguous
False
>>>arr2.flags.f_contiguous
True
{% endhighlight %}

看到没，这里仅仅设置了一个标志而已。

C和Fortran的这种差异，实际上是上世纪60年代，两大IT巨头AT&T和IBM之间战争的结果，并深远的影响了后来的软件。比如在通用计算领域，主要采用C格式，而数值计算领域，则多采用Fortran格式。

典型的例子是Matlab。它最早是作为一些Fortran数学库的封装而存在的，因此很自然的采用了Fortran格式。OpenGL、OpenVX之类的接口，实际上也沿袭了这种路径依赖。

Fortran作为最早的高级语言（1957年），至今仍有很强的生命力，这主要归功于：

1.对数组、复数等数值计算的原生支持。这些语法糖，对于非程序员的科技人员很友好。

2.没有指针等复杂特性。这一点既降低了上手的门槛，又对于编译器优化（尤其是现在比较流行的并行计算优化）很有好处。普通科技人员即使没有经过特殊的程序训练，也可以写出非常高效的程序。

# 大数据平台参考资源

https://mp.weixin.qq.com/s/uMj3JEhgyYw4CaIhP1-GTQ

阿里巴巴为什么不用ZooKeeper做服务发现？

http://www.cnblogs.com/rjzheng/p/8994962.html

分布式之消息队列复习精讲

https://mp.weixin.qq.com/s/Mcg5rj3QrgVj3wyY4xttnQ

关于商业部署机器学习，这有一篇详尽指南
