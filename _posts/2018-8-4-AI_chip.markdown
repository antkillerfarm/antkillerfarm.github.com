---
layout: post
title:  AI Chip（一）
category: Chip 
---

* toc
{:toc}

# AI Chip

![](/images/img2/AI_Chips.png)

https://basicmi.github.io/AI-Chip/

A list of ICs and IPs for AI, Machine Learning and Deep Learning.

![](/images/img4/AI_chip.png)

## NN计算的硬件设计

NN计算问题的瓶颈主要包括两类：

1.数学运算的速度。NN运算主要以乘加为主，实现这类加速功能的硬件单元一般被称为NN Processor。这也是第一代AI芯片主要解决的问题。

再细分的话，又有矩阵派和卷积派两种。

矩阵派的通用性好，且FC运算速度快于卷积派。

而卷积派由于针对Conv的Kernel数据不变这一特点进行优化，Conv速度极快。

2.IO问题，也称带宽问题。早期的NN由于算子有限，基本只有FC、Conv、Pooling、Activation等少数几种算子。但现在的NN模型算子可就多了，且有相当部分算子属于非计算类的搬运数据算子，比如permute等。针对这类运算，一般采用被称作Tensor Processor的硬件单元进行加速。

## DEEPHi

2018.8

深鉴科技是一家AI Chip公司。成立于2016年3月，2018年7月被Xilinx收购。

深鉴科技与云天励飞、寒武纪和地平线共同被称为“天寒地鉴”的中国AI芯片四小龙。

官网：

http://www.deephi.com/

它最近出了一套深度学习SDK：

http://www.deephi.com/zh-cn/dnndk.html

---

如果说2017年以前的AI Chip领域，主要解决的是芯片有无的问题的话，那么2018年的重点就聚焦在如何更好的使用上了。

性能方面各家各有千秋，即使不考虑功耗、面积等约束，也没有哪家在所有运算上，都比别人快，因此产品只要不是全面落伍，就还有的混。但易用性方面差距就比较大了。

1.CPU+NN混合编程。深鉴这方面做的还不错，似乎一套工具链就可以搞定，就是不知道自动化程度如何。有的友商连这一步都没做好，两套工具链+手动链接，把应用工程师折腾惨了。

2.模型压缩。Pruning方面由于有韩神的加持，确然做的很好，比我司强。Quantization方面，INT8量化算是最基本的量化了，不知道UINT8/INT16，他们做的如何。

3.Tensor Processor。深鉴这方面似乎是空白，这导致的一个结果就是AI Chip支持的运算非常有限，CPU负载过高，而AI Chip的负载相对就不行了。

4.模型导入。这方面深鉴只能说还不入流。虽然表面看来，它支持了Caffe和Tensorflow。然而它的支持方案是修改源代码。。。众所周知，pb文件的易用性是建立在通信双方使用同一套协议的基础之上。但目前AI领域魔改成风，跑个开源模型，还必须要下载作者魔改版的Caffe。。。可以想见深鉴这方面的自动化程度一定不咋样，肯定有很多手工活要做。

那么正确的做法是什么呢？参见ONNX。我司的方案比ONNX略早，但思路基本一致。

5.Model Zoo。这个比较寒碜了，只有三个模型，而且还都是最简单的分类模型。不过从支持Inception v1来看，应该是掌握了加速分支网络的技巧。其他的Face Detection等只有视频，没有模型，似乎还处于实验室阶段，可能易用性还有待提升。

无耻的谈一下我司的Model Zoo。包含40+的模型，涵盖图像分类、目标检测、图像分割、人脸识别、超分辨率、OCR等。目前，主要往RNN、Attention方面发展。这里会遇到循环结构的问题，还没有做的太好。

目前的AI Chip战争，入局的玩家基本都解决了芯片有无的问题。体系结构的红利也吃的差不多了，在未来几年不大可能再保持目前的算力增速。因此，未来争夺的焦点将转向软件方面。实际上，今年以来，已经有客户拿友商产品性能来压我们。然而也就是压一下而已，让他弃用他肯定不干。原因无他，我司80%的功能都已经自动化，没人会和好用过不去。

---

2021.11

最近国内比较火的AI芯片初创公司已经换成了：

- 壁仞科技
- 摩尔线程
- 沐曦集成
- 燧原科技
- 瀚博半导体
- 登临科技
- 天数智芯

---

某牛点评：

做一个ASIC其实目前真没有什么大的门槛，不然你以为上海那么多家的ASIC公司是怎么来的，随便拉几个人都敢成立ASIC公司，还不是门槛不高，你让他就那几个人搞个CPU和GPU试试。但是要做一个好的ASIC，适配模型和场景丰富的ASIC，是非常不容易的。而且一旦模型场景丰富，你就不仅仅是在硬件领域所谓的PPA各种挣扎，你还需要在指令级别，或者说通用和性能做妥协，甚至架构上的一些妥协改变。

## Imagination

Imagination Technologies公司前身是一家名为Video Logic的公司，VideoLogic成立于1985年，主营业务是图形与音频加速等方面。后来选择了与ARM的类似盈利模式——授权IP核，并在1999年更名为Imagination Technologies。

在移动GPU市场上，Imagination的PowerVR GPU一度占有非常高的市场份额。苹果公司设计的各种供苹果手机使用的AP，比如A8、A9、A10等处理器都搭载了Imagination Technologies公司的PowerVR图像处理技术。

但在2017年4月，苹果宣布将不再使用其技术后，Imagination股价当天暴跌60%。后于2017年9月，被有中资背景的Canyon Bridge收购。

其AI Chip主要是：PowerVR Series2NX NNA和PowerVR Series3NX NNA。

Imagination目前主要的客户是：

- 汽车电子：Renesas

- 手机：MTK、紫光展锐

除此之外，由于Imagination已经全国资化了，因此很多研究所也对它的产品感兴趣。

从方案来看，Imagination采用的是GPU+NPU的模式。

这种模式的特点主要有：

- NPU专注NN计算，其实主要是CNN计算。

- GPU作为通用计算的兜底，以应付一些不常见的op。GPU支持各种数学计算，单纯从计算的角度是完全可以替代CPU的。GPU的局限主要在于它没有CPU那样的逻辑控制的能力。

- GPU的主频一般低于CPU，因此如果算法的并行性很差的话，效果并没有CPU好。但这种情况并不多见。

- 最近高通和华为CPU的超大核设计，应该对于提升串行运算性能很有帮助。毕竟CPU核再多，还能有GPU/NPU的核多吗？如果碰到就需要单挑能力的场合该怎么办呢？

综上，GPU+NPU的模式可以将NN运算基本承接过来，这样CPU的负载相对就比较小了。

从商业的角度讲，Imagination的核心产品还是GPU，NPU只是一个添头而已。它的目的应该还是利用NPU，来多卖一些GPU。

摩尔线程的GPU是基于Imagination的IMG BXT-32-1024 MC4。

官网：

https://www.imgtec.com/vision-ai/

参考：

https://mp.weixin.qq.com/s/W7GNhEq-em18V0YjCZ7MBw

被苹果抛弃的芯片供应商，现状如何？

https://zhuanlan.zhihu.com/p/436515863

PowerVR系列GPU架构的演进（一）

https://zhuanlan.zhihu.com/p/491131559

PowerVR系列GPU架构的演进（二）

https://zhuanlan.zhihu.com/p/492651331

PowerVR系列GPU架构的演进（三）

https://zhuanlan.zhihu.com/p/493240867

PowerVR系列GPU架构的演进（四）

---

2020.1

苹果自己研发受阻，重新延续imagination授权。

https://zhuanlan.zhihu.com/p/103597189

挣扎两年苹果重新向Imagination低头：自研GPU究竟难在何处？

## 寒武纪

https://www.zhihu.com/question/41469046

寒武纪神经网络处理器效能如何？

## 壁仞

https://www.zhihu.com/question/547728200

如何评价壁仞科技发布的最大算力GPGPU BR100？

## Habana

Habana Labs是一家位于以色列特拉维夫和加州圣何塞的无晶圆厂半导体公司，创立于2016年。

Habana的产品线主要有：

- 用于Train的Gaudi系列芯片。

- 用于Inference的Goya系列芯片。这是一个基于PCI接口的板卡，所以还是数据中心的范畴，暂不能用于终端设备。

据说国内的数据中心相关的企业，对它的产品很感兴趣。

官网：

https://habana.ai

>2019.12 Habana被Intel收购。稍后，就传出Intel解散Nervana团队的事情。后者是2016年被Intel收购的一家AI芯片公司。

国外类似的企业还有：

- HAILO
- blaize

参考：

https://mp.weixin.qq.com/s/cnHQSmM89Sp92gke_F9T2Q

一窥Habana的推理和训练神经处理器

https://zhuanlan.zhihu.com/p/84562992

Goya from Habana Labs芯片与软件栈分析

## Qualcomm

![](/images/img4/Snapdragon_835.png)

SnapDragon = Kryo CPU + Adreno GPU + Hexagon DSP(include Hexagon Tensor Accelerator, HTA & Hexagon Vector eXtensions, HVX)

参考：

https://zhuanlan.zhihu.com/p/51727365

骁龙855细节曝光：引入张量加速器最亮眼

https://zhuanlan.zhihu.com/p/341328310

聊聊芯片技术趋势

## Huawei

Huawei的AI芯片项目大约启动于2016年底，算是布局比较晚的了，所以初期它们和寒武纪有不少合作。

官网：

https://ascend.huawei.com/home

Model Zoo：

https://github.com/Ascend/models

参考：

https://mp.weixin.qq.com/s/P381v0eXrwfzlLE79c8sGg

华为在hotchips详细介绍了达芬奇架构

## Cerebras

现在，计算芯片是越做越大，在早先的PC中，最大的芯片无疑是CPU了。但现在高端显卡芯片的面积已经超越CPU了。

Cerebras在这方面更为极端，它的芯片采用了一整张300mm晶圆，将40万个内核，1.2万亿个晶体管，46,225平方毫米的硅和18GB的片上存储器，全部集成在一个与整个晶圆一样大的芯片中，大到令人难以置信。

其实Nvidia的芯片也有越来越大的趋势：

![](/images/img3/nvidia_roadmap.png)

超大芯片主要有两个问题：

- 良品率问题。这个问题可以通过冗余设计来解决。比如Intel的i5、i7实际上都是同一批生产出来的。如果所有核都OK，那就是i7；否则的话，屏蔽不好的核，这就是i5，因此i5常有6核这样的奇怪数字出现。

- 散热问题。

参考：

https://mp.weixin.qq.com/s/Zsmvsy8I_qKZWrONj9Juuw

史上最大芯片正式推出世界最快AI计算机：1/30体积、1/5功耗、3倍性能！谷歌TPU V3在它面前就是“渣”

https://mp.weixin.qq.com/s/nGzDVR9dlF-jL4ZIkss0Ow

这家用一整块硅片做AI芯片的公司成功了？
