---
layout: post
title:  深度强化学习（九）——DRL参考资源（1）
category: DRL 
---

* toc
{:toc}

# 王者荣耀（续）

https://mp.weixin.qq.com/s/Mdq9fL10Zcjs_z3PeqtN9Q

腾讯AI单挑碾压王者荣耀职业玩家：人类15场只能赢1局，坚持不到8分钟

https://mp.weixin.qq.com/s/_Ze8C8UQV9UZXnSX6qq2GA

强化学习玩王者荣耀

https://mp.weixin.qq.com/s/mj8PG-wRqSbEIR38fongHA

用自己训练的AI玩王者荣耀是什么体验？

# 常见问题建模方法

![](/images/img4/DRL.jpg)

https://zhuanlan.zhihu.com/p/356166466

强化学习落地：计算机系统

# DRL和Robotics

虽然，DRL似乎生来就是为了Robotics，然而现实中的无人系统，目前基本还是使用传统的控制方法。

例如：

https://www.zhihu.com/question/50050401

如何看待百度无人车， 三千多个场景，一万多个if？

不止国内，就连业界标杆Boston Dynamics也是这样：

https://www.zhihu.com/question/29871410

波士顿动力Boston Dynamics的大狗Big Dog用的了哪些控制、估计等算法？

直到最近才终于有了改观：

https://mp.weixin.qq.com/s/xSODAGf3QcJ3A9oq6xP11A

真的超越了波士顿动力！深度强化学习打造的ANYmal登上Science子刊

此外，还有一些论文：

《Learning to Drive in a Day》

---

强化学习和模仿学习，本质都是在任务层面的（Task-level Control），而传统的机器人控制都是在动作级（Action-level）和伺服级（Servo-level）。

https://www.zhihu.com/question/504142198

现有的控制器已经能完成对于机械臂的控制了，将深度强化学习应用到机械臂的控制上还有什么实际意义吗？

---

参考：

https://zhuanlan.zhihu.com/p/59197798

那些个端到端的自动驾驶研发系统

https://mp.weixin.qq.com/s/yU-6r-7l50y5msw8gUWnUQ

美团技术部解析：无人车端到端驾驶模型概述

# Model Predictive Control

MPC（Model Predictive Control）+WBC (Whole-Body Control)是典型的做腿足类机器人用的算法。

机械臂+灵巧手+移动小车，一般被称为AMR（Autonomous Mobile Robot）。

教程：

http://cse.lab.imtlucca.it/~bemporad/mpc_course.html

Model Predictive Control

https://www.syscop.de/teaching/ss2021/model-predictive-control-and-reinforcement-learning

Model Predictive Control and Reinforcement Learning

http://web.mit.edu/dimitrib/www/LessonsfromAlphazero.pdf

Lessons from AlphaZero for Optimal, Model Predictive, and Adaptive Control

参考：

https://mp.weixin.qq.com/s/pMnbVWDDVgIdFpzkfSUd5Q

时延MPC自主车辆协同控制算法与仿真

https://mp.weixin.qq.com/s/UAPbNq_KNWCFd7p8U8HnYQ

模型预测控制（MPC）

https://zhuanlan.zhihu.com/p/99409532

模型预测控制简介（model predictive control）

https://zhuanlan.zhihu.com/p/507623074

Model Based + MPC + Planning + RL相关

https://mp.weixin.qq.com/s/BFNaEBa8KwvRBK_mSunXjw

MPC与LQR比较

https://www.zhihu.com/question/424186342

模型预测控制（MPC）和基于模型的强化学习（Model-based RL）之间的联系是什么？

# DRL参考资源

https://mp.weixin.qq.com/s/ruAAQEjPIDPWPiuPepKU6Q

Deep Reinforcement Learning: An Overview

https://mp.weixin.qq.com/s/FjmlXqlpaRVLdAbjqspOJA

这是一份你必须学习的强化学习算法清单

https://mp.weixin.qq.com/s/GISY-FvV1Vml3CNLInjgYg

Tensorflow2.0实现29种深度强化学习算法大汇总

https://mp.weixin.qq.com/s/lfXQqllfFPtuNIrQZiD-NQ

深度强化学习十大原则

https://mp.weixin.qq.com/s/I8IwPCY6-zocJKFXMr6rUg

深度强化学习的18个关键问题

https://mp.weixin.qq.com/s/_lmz0l1vP_CQ6p6DdFnHWA

谷歌大脑工程师的深度强化学习劝退文

https://zhuanlan.zhihu.com/p/39999667

强化学习路在何方？

https://zhuanlan.zhihu.com/p/25239682

深度强化学习（Deep Reinforcement Learning）入门

https://mp.weixin.qq.com/s/Ns5AUGfDoTeTwnBD-pYdLA

详解强化学习当前进展及未来方向

https://mp.weixin.qq.com/s/VIMX63zBaZ5ji70UmHHajg

强化学习入门知识超全梳理

https://mp.weixin.qq.com/s/e6QOz-MQSn7n53EPtpw64w

DeepMind强化学习综述：她可以很快，但快从慢中来

https://zhuanlan.zhihu.com/p/72642285

基于模型的强化学习论文合集

https://zhuanlan.zhihu.com/p/77976582

强化学习并行训练论文合集

https://mp.weixin.qq.com/s/sHP03DAeZvdBxwVPuSNRPg

如何丝滑地入门神经网络？写个AI赛车游戏，只训练4代就能安全驾驶

https://mp.weixin.qq.com/s/1SZKhG1ZbD1pl-3YQD_umg

6行代码搞定基本的RL算法，速度围观Reddit高赞帖

https://mp.weixin.qq.com/s/6n5HawyR4AgH8Dq0gJMw2g

强化学习的基本概念与代码实现

https://mp.weixin.qq.com/s/S2eGPTON3XmfN830m4vaaA

腾讯AI Lab：可自适应于不同环境和任务的强化学习方法

https://mp.weixin.qq.com/s/dlOFM7LuOF2npDP_EaITvg

效率提高50倍！谷歌提出从图像中学习世界的强化学习新方法（PlaNet）

https://mp.weixin.qq.com/s/3qWN6DjuGUZgCpxH7XF4fg

谷歌重磅开源RL智能体Dreamer，仅靠图像学习从机器人到Atari的控制策略，样本效率暴增20倍

https://mp.weixin.qq.com/s/Maoy2feVWj5hpn4Ysh_47A

你追踪，我逃跑：一种用于主动视觉跟踪的对抗博弈机制

https://mp.weixin.qq.com/s/4w3wIyy4H0UGeqOGhNcIbA

强化学习落地！京东等发布综述《深度强化学习在搜索，推荐和在线广告中的应用》

https://mp.weixin.qq.com/s/F_GsfAJRFJ_o8PETqUL35g

谷歌大脑AI飞速解锁雅达利，训练不用两小时：预测能力“前所未有”

https://mp.weixin.qq.com/s/6wPtb9Qdhr9FiMk15xrUsQ

强化跨模态匹配和自监督模仿学习

https://mp.weixin.qq.com/s/lU3_ONAIGDUv_AVv2Xn14w

仅需2小时学习，基于模型的强化学习方法可以在Atari上实现人类水平

https://mp.weixin.qq.com/s/w0_g5FlC6vx2MRAhADPq2g

深度强化学习在智能对话上的应用

https://mp.weixin.qq.com/s/4SZ1NN5hUUcO_dSe4Bv0NQ

利用鲁棒控制实现深度强化学习驾驶策略的迁移

https://mp.weixin.qq.com/s/rwqtw5b2Nap5UPU9DWBXqg

强化学习与文本生成

https://mp.weixin.qq.com/s/VPCtsv2Q73qVcNAa4Xufag

从虚拟到现实，北大等提出基于强化学习的端到端主动目标跟踪方法

https://mp.weixin.qq.com/s/6Sj2QIELQvI28Rpp7A39Fg

如何通过结构化智能体完成物理构造任务？

https://mp.weixin.qq.com/s/lR6BSa_pJzcinkSaSWsM2A

伯克利提出强化学习新方法，可让智能体同时学习多个解决方案

https://mp.weixin.qq.com/s/P-iSI80IVmb5s-Q15Re2HQ

All In!我学会了用强化学习打德州扑克

https://zhuanlan.zhihu.com/p/36322095

最前沿：从虚拟到现实，DRL让小狗机器人跑起来了！

https://mp.weixin.qq.com/s/xr-2cNoSYpCftLI3dV6zEw

如何使用深度强化学习帮助自动驾驶汽车通过交叉路口？

https://mp.weixin.qq.com/s/R_pfTXDMaLHmiCaSV2t_YA

英特尔Nervana发布强化学习库Coach：支持多种价值与策略优化算法

https://mp.weixin.qq.com/s/AyW7oOC7yxVtmswaMT1DGQ

腾讯AI Lab获得计算机视觉权威赛事MSCOCO Captions冠军

https://mp.weixin.qq.com/s/4aENmxUMEEPVPnexLKrg7Q

新型强化学习算法ACKTR

https://mp.weixin.qq.com/s/5PzTiPoXPC1gH3xszzT2dQ

邓力等人提出BBQ网络：将深度强化学习用于对话系统

https://mp.weixin.qq.com/s/pM8oykHmtu5O5jYJBZjO_w

伯克利研究人员使用内在激励，教AI学会好奇

https://mp.weixin.qq.com/s/3WI3QgfHXcrCPbvmHWOEkg

强化学习在生成对抗网络文本生成中的作用

https://mp.weixin.qq.com/s/IvR0O6dpz2GJCG7UQb5kUQ

清华大学冯珺：基于强化学习的关系抽取和文本分类

https://zhuanlan.zhihu.com/p/31579144

让我们从零开始做一个机械手臂(强化学习)

https://mp.weixin.qq.com/s/FiR_GRYqJYpJRO-2p44-Cg

伯克利强化学习新研究：机器人只用几分钟随机数据就能学会轨迹跟踪

https://mp.weixin.qq.com/s/_dHjZQ_7_7H34PHhV_lC3w

全新强化学习算法详解，看贝叶斯神经网络如何进行策略搜索

https://mp.weixin.qq.com/s/YCPXkFzYdC1gMfnprZsVXg

如何让机器人多技能？通过最大熵强化学习

https://mp.weixin.qq.com/s/dbtdNsT3nvLt4UKsrNsn_Q

量化深度强化学习算法的泛化能力

https://mp.weixin.qq.com/s/K-z_dX2-NepkEHbr45QlvQ

微软研究院开源项目TextWorld：可用于强化学习训练的文本游戏

https://mp.weixin.qq.com/s/K2DW_ntSWrlySpxgorF9dA

Python强化学习实战，Anaconda公司的高级数据科学家讲解

https://zhuanlan.zhihu.com/p/32089849

概要：NIPS 2017 Deep Learning for Robotics Keynote

https://mp.weixin.qq.com/s/CCQOHRCAolsorm8FEPdjoQ

什么时候强化学习未必好用？

https://mp.weixin.qq.com/s/Ctn1Wr68lph1UK_wjfCY1Q

策略梯度搜索：不使用搜索树的在线规划和专家迭代

https://mp.weixin.qq.com/s/78ir-Z4ch8_aVpjC6aCPGg

DeepMind综述深度强化学习中的快与慢，智能体应该像人一样学习

https://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&mid=2247494226&idx=1&sn=a96ea0ad8961ec3698301cf0c4514843

以YouTube论文学习如何在推荐场景应用强化学习

https://mp.weixin.qq.com/s/SpCorsAiTWGYGiohT_gZtg

如何训练智能体Agent玩毁灭战士ViZDoom？

https://mp.weixin.qq.com/s/ewC2_8O29Gg0blxK7mHsYA

比TD、MC、MCTS指数级快，性能超越A3C、DDQN等模型，这篇RL算法论文在Reddit上火了

https://mp.weixin.qq.com/s/Q9QzXo_M3jYKjBWSsLYwgQ

强化学习+树搜索：一种新型程序合成方法

https://mp.weixin.qq.com/s/l46yJdRaftMlwr6odiSiHg

Yoshua Bengio团队基于深度强化学习打造聊天机器人MILABOT

https://mp.weixin.qq.com/s/6_cW22DCzSw3DpUDrLXLcA

OpenAI提出强化学习近端策略优化，可替代策略梯度法

http://mp.weixin.qq.com/s/S4jhpNKYZP5YQWaiiOQGFA

DeepMind：“预测地图”海马体催生强化学习新算法

https://mp.weixin.qq.com/s/KZHidOi5KYgg393R_JspBA

DeepMind都拿不下的游戏，刚刚被OpenAI玩出历史最高分

https://mp.weixin.qq.com/s/aVWHlwOmNIqOlu3025_RXQ

DeepMind提出多任务强化学习新方法Distral

https://mp.weixin.qq.com/s/gFHbLF-q91sddMAX1CRbEQ

俞扬：“审时度势”的高效强化学习

https://mp.weixin.qq.com/s/lstCIiNs_qA6k7GCYUBv2w

阿尔伯塔大学提出新型多步强化学习方法，结合已有TD算法实现更好性能

https://mp.weixin.qq.com/s/ybyZpaHr-JJg7CCdXGOl5A

Seq2seq强化学习实战

https://mp.weixin.qq.com/s/vYDb1rTdPxO1sIS38VX5xA

DeepMind的AI学会了画画，利用强化学习完全不需人教：SPIRAL

https://mp.weixin.qq.com/s/rpPN2rgru6krRz2fr1RhsQ

模拟世界的模型：谷歌大脑与Jürgen Schmidhuber提出“人工智能梦境”

https://mp.weixin.qq.com/s/AelAD57G4GOh7qm-_rvYsg

伯克利提出DeepMimic：使用强化学习练就18般武艺
